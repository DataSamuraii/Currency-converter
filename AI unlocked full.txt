WEBVTT


00:00:00.000 --> 00:00:08.800
всем привет еще народ будет подключаться мы потихоньку будем начинать меня зовут даня я веду

00:00:08.800 --> 00:00:15.360
канал стартов наично 12 человек а я думаю мы со многими уже виделись у нас сегодня вторая

00:00:15.360 --> 00:00:22.960
встреча с андреем вальшуером сегодня мы поговорим про advanced prompt engineering что

00:00:22.960 --> 00:00:32.360
мне кажется очень актуальным релимансы на сегодня к тому же андрея больше про себя расскажет

00:00:32.360 --> 00:00:38.480
но из нашего как бы с ним общение тому что он мне показывал что мне очень как привлекает и вызывает

00:00:38.480 --> 00:00:45.160
доверие то что на ежедневной основе пользуется всеми этими инструментами вот я для себя понял что

00:00:45.160 --> 00:00:51.720
я сам как бы я не хотел быть early adopter им не являюсь то есть как бы я уже обычно пользуюсь

00:00:51.720 --> 00:00:56.760
плодами работы на работах других людей вот анри как раз в этой сфере такой человек который сам там

00:00:56.760 --> 00:01:03.800
всякие штуки пробует следит там за всеми самыми новыми вещами которые там постятся в сети

00:01:03.800 --> 00:01:10.920
twitter где меня лично тоже нет вот поэтому думаю будет интересно вот я передаю микрофон андрею и

00:01:10.920 --> 00:01:18.880
сам с экрана наверное пропаду сейчас да спасибо спасибо даниил ребята привет как вы как у вас

00:01:18.880 --> 00:01:27.240
настроение пишите что-нибудь в чат а я попробую его найти он куда-то пропал а вот он

00:01:27.240 --> 00:01:37.280
привет семен привет на кенте привет а диана привет виктор привет

00:01:40.080 --> 00:01:44.880
так ну что хорошо хорошо давайте да давайте постепенно начинать у нас

00:01:44.880 --> 00:01:49.960
у него очень много материала как обычно но не волнуйтесь я не буду я постараюсь вас не

00:01:49.960 --> 00:01:54.160
переутомить поэтому в какой-то момент если мы поймем что мы выдохлись у нас закончились

00:01:54.160 --> 00:02:01.240
когнитивные ресурсы у всех вместе коллективно всех нас то мы скажем и кей здесь мы поставим

00:02:01.240 --> 00:02:09.480
точку или запятую это мы как уже с вами решим так я надеюсь сейчас появилась моя презентация

00:02:09.480 --> 00:02:15.720
по крайней мере она и в хорошем тоне зума всегда спросить видите ли вы мои слайды

00:02:15.720 --> 00:02:19.720
Хотя за три года мы уже должны были привыкнуть, что их видно.

00:02:19.720 --> 00:02:24.720
Да, давайте начинать. Действительно, сегодня у нас будет лекция по Advanced Prompt Engineering.

00:02:24.720 --> 00:02:29.720
Я немножко расскажу вам про себя и вообще из какого, как бы, из какой перспективы

00:02:29.720 --> 00:02:34.720
я буду вам про это рассказывать. У меня есть три каких-то области компетенции,

00:02:34.720 --> 00:02:41.720
которые я активно развиваю и в которых мне AI, разный, разного типа AI, помогает.

00:02:41.720 --> 00:02:45.720
Первая, это моя самая основная компетенция, это коммерческий рисотч.

00:02:45.720 --> 00:02:49.720
То есть я занимаюсь исследованием для компаний. Я помогаю им понять лучше аудиторию,

00:02:49.720 --> 00:02:54.720
понять лучше тренды, разобраться в собственном продукте и так далее.

00:02:54.720 --> 00:03:00.720
И, соответственно, я очень много применяю AI для того, чтобы обрабатывать данные,

00:03:00.720 --> 00:03:04.720
для того, чтобы генерировать отчеты, для того, чтобы делать какие-то вещи,

00:03:04.720 --> 00:03:07.720
которые называются pre-research, то есть когда мы не делаем рисотч,

00:03:07.720 --> 00:03:12.720
мы пытаемся найти какую-то структуру, дать ее контрагенту и сказать,

00:03:12.720 --> 00:03:16.720
дружище, вот тебе такая система, ты сможешь принять на основании этого решение.

00:03:16.720 --> 00:03:18.720
И часто человек говорит, я не знаю, что мне делать, а это значит,

00:03:18.720 --> 00:03:24.720
что исследование не нужно. И тут мы переходим уже ко второму кругу моей компетенции,

00:03:24.720 --> 00:03:30.720
это принятие решений, это называется в науке decision science и problem solving.

00:03:30.720 --> 00:03:35.720
Этим я занимаюсь как консультант, то есть я помогаю компаниям принимать грамотные решения.

00:03:35.720 --> 00:03:39.720
Я не хочу говорить правильные, потому что правильные решения – это такой очень сложный термин,

00:03:39.720 --> 00:03:43.720
как мы знаем, что в любом решении есть какое-то количество удачи и факторов,

00:03:43.720 --> 00:03:46.720
которых мы учесть не можем, но грамотные решения, принимать решения.

00:03:46.720 --> 00:03:48.720
И решать сложные проблемы.

00:03:48.720 --> 00:03:53.720
И вот это, наверное, самое интересное с точки зрения AI и способности в первую очередь

00:03:53.720 --> 00:03:56.720
языковых моделей помогать нам решать сложные проблемы.

00:03:56.720 --> 00:03:58.720
Этому у нас сегодня будет посвящен в первую очередь стрим.

00:03:58.720 --> 00:04:01.720
То есть на примере problem solving кейсов я буду рассказывать вам,

00:04:01.720 --> 00:04:06.720
как использовать advanced prompt engineer. Ну и последняя моя зона компетенции –

00:04:06.720 --> 00:04:10.720
это управление информацией, большими объемами информации и управление знаниями.

00:04:10.720 --> 00:04:13.720
Естественно, это все связано, невозможно принимать решения,

00:04:13.720 --> 00:04:16.720
если у тебя недостаточной информации и исследования.

00:04:16.720 --> 00:04:19.720
В общем-то, по сути, это процесс генерации новой информации,

00:04:19.720 --> 00:04:21.720
новых знаний о чем-то, о каком-то домене.

00:04:21.720 --> 00:04:27.720
И здесь я тоже использую AI. Если мы дойдем до этого, если у нас останется время,

00:04:27.720 --> 00:04:30.720
я покажу вам, что такое structural output. Это очень интересно.

00:04:30.720 --> 00:04:32.720
Но если не найдем, то…

00:04:32.720 --> 00:04:35.440
подумаем, что с этим делать.

00:04:35.440 --> 00:04:40.240
Давайте теперь двинемся прямо к нашему домену,

00:04:40.240 --> 00:04:41.240
к нашей истории.

00:04:41.240 --> 00:04:43.560
Единственное, что я стараюсь всегда начинать разговор

00:04:43.560 --> 00:04:45.440
об AI, Artificial Intelligence.

00:04:45.440 --> 00:04:48.880
Я думаю, что все знают, что такое Artificial Intelligence.

00:04:48.880 --> 00:04:52.160
Но часто бывают проблемы, что мы не можем вместе

00:04:52.160 --> 00:04:54.600
договориться, что такое Intelligence вообще.

00:04:54.600 --> 00:04:57.560
Я поэтому стараюсь всегда начинать все свои лекции

00:04:57.560 --> 00:05:00.120
по Artificial Intelligence вообще с определения интеллекта.

00:05:00.120 --> 00:05:02.800
И определение интеллекта вот такое.

00:05:02.800 --> 00:05:06.120
Это не строгое определение, но это то, к чему я пришел,

00:05:06.120 --> 00:05:09.240
и эта модель мне кажется полезной.

00:05:09.240 --> 00:05:11.200
Интеллект – это способность видеть паттерны.

00:05:11.200 --> 00:05:15.080
И вообще, если так вот все пытаться упростить, то

00:05:15.080 --> 00:05:16.920
любая языковая модель – это штука, которая просто

00:05:16.920 --> 00:05:19.360
из одних паттернов выводит другие паттерны.

00:05:19.360 --> 00:05:20.360
Вот и все.

00:05:20.360 --> 00:05:22.800
То есть он видит паттерн в промте, она, точнее, модель

00:05:22.800 --> 00:05:26.640
видит паттерн в промте и дает вам некий ответ.

00:05:26.640 --> 00:05:28.120
Следующая – это способность строить модели.

00:05:28.120 --> 00:05:31.480
Это уже более сложная какая-то структура.

00:05:31.480 --> 00:05:34.040
То есть какие-то модели, которые мы держим в своей

00:05:34.040 --> 00:05:36.720
кратковременной или долговременной памяти.

00:05:36.720 --> 00:05:38.960
И последняя – это способность предсказывать.

00:05:38.960 --> 00:05:39.960
То есть предсказывать что?

00:05:39.960 --> 00:05:42.000
Модель может предсказывать следующий токен, а мы с

00:05:42.000 --> 00:05:44.160
вами можем предсказывать какие-то более сложные

00:05:44.160 --> 00:05:45.880
комплексные явления в мире.

00:05:45.880 --> 00:05:48.400
Давайте теперь немножко про это поговорим.

00:05:48.400 --> 00:05:50.400
Про паттерны здесь вроде более-менее все понятно.

00:05:50.400 --> 00:05:53.240
Если вы проходили тест на IQ, то вы помните, что

00:05:53.240 --> 00:05:55.200
это всегда паттерны.

00:05:55.200 --> 00:05:57.160
То есть задача любого теста на IQ – дать вам большое

00:05:57.160 --> 00:05:59.720
количество таких задачек и понять, насколько хорошо

00:05:59.720 --> 00:06:01.680
у вас работает механизм паттерн и когнишн.

00:06:01.680 --> 00:06:05.200
Если у вас работает хорошо, классно, у вас высокий IQ,

00:06:05.200 --> 00:06:06.200
то есть высокий интеллект.

00:06:06.200 --> 00:06:09.480
По сути IQ коррелирует с интеллектом, хотя, естественно,

00:06:09.480 --> 00:06:11.000
он не может сдавать полностью интеллект.

00:06:11.000 --> 00:06:14.040
Но если мы возьмем более сложные социальные взаимодействия,

00:06:14.040 --> 00:06:16.040
например, наверняка вы слышали про эмоциональный

00:06:16.040 --> 00:06:18.560
интеллект или музыкальный интеллект и другие типы

00:06:18.560 --> 00:06:19.560
интеллекта.

00:06:19.560 --> 00:06:21.320
То есть эмоциональный интеллект – это, по сути, способность

00:06:21.320 --> 00:06:23.240
распознавать паттерны в другом человеке.

00:06:23.240 --> 00:06:24.760
То есть если вы видите, что другому человеку как-то

00:06:24.760 --> 00:06:30.000
плохо или вы способны считывать его состояние, исходя из

00:06:30.000 --> 00:06:33.440
какого-то его поведения, вербального, невербального,

00:06:33.440 --> 00:06:35.080
то можно сказать, что у вас высокий эмоциональный

00:06:35.080 --> 00:06:36.080
интеллект.

00:06:36.080 --> 00:06:37.880
Наоборот, люди с низким эмоциональным интеллектом

00:06:37.880 --> 00:06:40.160
вообще игнорируют других людей и не видят, какие

00:06:40.160 --> 00:06:41.920
эмоции и какие чувства они переживают.

00:06:41.920 --> 00:06:43.120
То же самое с музыкой.

00:06:43.120 --> 00:06:45.840
Если вы способны видеть какие-то сложные паттерны

00:06:45.840 --> 00:06:48.000
в музыкальных произведениях, это значит, что у вас высокий

00:06:48.000 --> 00:06:49.000
эмоциональный интеллект.

00:06:49.000 --> 00:06:55.320
Если вы когда-то видели музыку, вы нашли и Fight

00:06:55.320 --> 00:06:56.320
crossfire.

00:06:56.320 --> 00:07:01.120
Увеличервонная музыка – это очень важно, потому

00:07:01.120 --> 00:07:08.320
что именно тогда вы заслуживаете этого б Prefer

00:07:08.320 --> 00:07:11.740
– kontinue или freakin' reach forward.

00:07:11.740 --> 00:07:13.600
Вы же есть.

00:07:13.600 --> 00:07:18.140
Вы продумали в Дискок bonds про всех этих тегов и

00:07:18.140 --> 00:07:22.900
музыкальный интеллект. Вот, то есть, по сути, интеллект – это, в первую очередь, пропад.

00:07:22.900 --> 00:07:27.220
В вторую очередь, это про способность строить модели. Я всегда здесь привожу такой пример.

00:07:27.220 --> 00:07:32.540
Вот представьте себе, есть велосипед. Каждый из нас знаком с этой сущностью, и у каждого из нас

00:07:32.540 --> 00:07:38.500
есть в голове модель велосипеда. И, соответственно, что мы можем сделать? Мы можем попросить,

00:07:38.500 --> 00:07:43.060
то есть я могу попросить вас, а теперь, пожалуйста, нарисуйте мне велосипед вот так, исходя из той

00:07:43.060 --> 00:07:47.180
ментальной модели, то есть той модели, которая у вас есть в голове. И часто удивительно, что люди

00:07:47.180 --> 00:07:51.380
с этим не справляются. Вот мы видим вот такие эксперименты, когда людей попросили нарисовать

00:07:51.380 --> 00:07:56.060
велосипед, и видите, непонятно, что это значит. Это значит, модель плохая. Модель в голове у человека

00:07:56.060 --> 00:08:00.300
не соответствует тому, как реально велосипед работает. Велосипед – это очень примитивная сущность,

00:08:00.300 --> 00:08:04.860
важно помнить. Понятно, что мы с вами оперируем с гораздо более сложными сущностями, и, соответственно,

00:08:04.860 --> 00:08:11.420
мы работаем внутри нашей когниции, внутри нашего мозга, со сложными моделями.

00:08:11.420 --> 00:08:17.940
Artificial intelligence делает то же самое. Он строит какие-то модели мира, и на основании этого он пытается

00:08:17.940 --> 00:08:25.100
нам что-то про этот мир рассказать или сделать на основании этого какие-то, как сказать,

00:08:25.100 --> 00:08:30.340
какие-то суждения об этом мире. Ну и последнее – это способность к предсказанию. Если вы

00:08:30.340 --> 00:08:36.180
выводите машину, вы наверняка вспомните такой момент, когда вы куда-то ехали, и увидите, что впереди

00:08:36.180 --> 00:08:41.620
автомобиль начинает как-то себя странно вести, и вы такие, окей, кажется, сейчас этот человек будет

00:08:41.620 --> 00:08:47.220
делать какую-то ерунду. Лучше я остановлюсь, перестрой с другой ряд и постараюсь с ним держаться

00:08:47.220 --> 00:08:51.900
от него подальше. Вот. Это три вещи, которые нам сегодня лучше помогут понять вообще, с какими…

00:08:51.900 --> 00:08:56.940
то есть, как мы работаем с моделями. Потому что промптинг – это работа с моделями, это все это

00:08:56.940 --> 00:09:02.540
взаимодействие с моделями. Если мы понимаем, что модель обладает интеллектом, а интеллектом в контексте

00:09:02.540 --> 00:09:07.020
вот этих трех компонентов, то есть она умеет видеть паттерны, замечать паттерны, она умеет строить

00:09:07.020 --> 00:09:12.220
модели, и она… да, модель умеет строить модели, такой мета-уровень, и она умеет предсказывать что-то,

00:09:12.220 --> 00:09:17.780
то, соответственно, хорошо. Значит, она обладает неким интеллектом. Мы еще с вами попозже поговорим,

00:09:17.780 --> 00:09:22.820
что это за интеллект и как он проявляется. И я сразу скажу, что мы с вами сегодня будем говорить

00:09:22.820 --> 00:09:27.780
в первую очередь про большой языковые модели, естественно, в первую очередь про GPT-4, как самую

00:09:27.780 --> 00:09:34.820
продвинутую модель, которая доступна всем нам по совсем небольшой подписке или вашем

00:09:34.820 --> 00:09:38.460
по API. Естественно, есть другие модели, есть модель

00:09:38.460 --> 00:09:41.640
Клод от Antropic, есть модели от Google, их целые, да, целое

00:09:41.640 --> 00:09:44.320
там какое-то количество. Есть модели open-source, языковые

00:09:44.320 --> 00:09:48.860
модели, которые тоже, в общем-то, уже не такие плохие,

00:09:48.860 --> 00:09:51.120
то есть они уже много чего умеют. Вот языковых моделей

00:09:51.120 --> 00:09:54.260
очень много, и способ коммуникации, способ взаимодействия

00:09:54.260 --> 00:09:56.900
с ними довольно похож. Теперь, когда мы с вами

00:09:56.900 --> 00:10:01.620
обсудили интеллект, извините за такое долгое теоретическое

00:10:01.620 --> 00:10:06.100
вступление, но нам оно необходимо, чтобы потом просто мы, когда

00:10:06.100 --> 00:10:09.580
я вам буду рассказывать про промтинг, чтобы у вас

00:10:09.580 --> 00:10:11.840
эти знания не накладывались на какое-то теоретическое

00:10:11.840 --> 00:10:13.580
представление, потому что если я вам просто буду давать

00:10:13.580 --> 00:10:15.940
бесконечное количество промтов, вы просто ничего

00:10:15.940 --> 00:10:19.300
не научитесь. Поэтому, сори за такое, за немного

00:10:19.300 --> 00:10:23.460
теории, немного занудства. Вот, еще один небольшой

00:10:23.460 --> 00:10:26.220
теоретический блок про то, вообще с кем мы разговариваем,

00:10:26.220 --> 00:10:29.500
потому что то, что я часто замечаю, да, я много общаюсь

00:10:29.500 --> 00:10:32.580
с людьми, которые коммуницируют с разного рода artificial

00:10:32.580 --> 00:10:35.500
intelligence, и люди совершенно по-разному для себя эту

00:10:35.500 --> 00:10:38.980
сущность концептуализируют. Есть модели на самом деле

00:10:38.980 --> 00:10:41.580
не самые удачные. То есть, если вы неправильно представляете

00:10:41.580 --> 00:10:43.620
своего собеседника, то есть у вас неправильная модель

00:10:43.620 --> 00:10:46.380
вашего собеседника, вы, скорее всего, будете неэффективно

00:10:46.380 --> 00:10:48.980
с ним общаться. Поэтому очень важно для вас, как

00:10:48.980 --> 00:10:52.700
для сущности, обладающей интеллектом и умеющей строить

00:10:52.700 --> 00:10:55.860
модели, построить правильную модель вот этой сущности,

00:10:55.860 --> 00:10:57.860
с которой вы общаетесь, да, с которой вы коммуницируете.

00:10:57.860 --> 00:10:59.860
Я вам дам три ментальные модели, которые мне кажутся

00:10:59.860 --> 00:11:04.140
удачными. Первая, да, вот, собственно, ментальная

00:11:04.140 --> 00:11:08.340
модель. Первая ментальная модель – это лингвистический

00:11:08.340 --> 00:11:11.700
интерфейс. Что это такое? То есть язык – это самый

00:11:11.700 --> 00:11:15.980
понятный и, пожалуй, наверное, один из самых древних интерфейсов

00:11:15.980 --> 00:11:19.420
взаимодействия. Человек с человеком и человека

00:11:19.420 --> 00:11:23.460
с миром, да, если говорить про физику. И это очень

00:11:23.460 --> 00:11:26.500
удобный способ, это очень удобный интерфейс, очень

00:11:26.500 --> 00:11:30.180
удобный, и поэтому, когда сейчас мы видим такой огромный

00:11:30.180 --> 00:11:35.420
рост способностей модели и интереса к ним, и возможности

00:11:35.420 --> 00:11:39.740
их, мы понимаем, что, в том числе, почему это произошло,

00:11:39.740 --> 00:11:41.940
потому что это язык. Язык для нас очень-очень нативный

00:11:41.940 --> 00:11:45.700
способ взаимодействия с миром. Поэтому очень важно

00:11:45.700 --> 00:11:48.820
для себя здесь понять, что модель – это некий языковой

00:11:48.820 --> 00:11:52.460
интерфейс доступа ко всему, ко всем, что происходит

00:11:52.460 --> 00:11:59.780
информации, которые есть в мире. Если, например, раньше мы что-то гуглили, и мы не могли просто

00:11:59.780 --> 00:12:05.660
сказать Гуглу, помнишь, я смотрел вот такой сериал в таком-то году, и там был такой интересный

00:12:05.660 --> 00:12:11.700
персонаж, который делал вот это. Вчера буквально Сэм Альтман написал такой твит. И Гугл вас,

00:12:11.700 --> 00:12:15.700
скорее всего, не понял. Вам бы пришлось сделать какое-то количество ухищрений, делать какие-то

00:12:15.700 --> 00:12:21.020
там специальные поиски, искать там по сериалам и так далее, и так далее, и так далее. Здесь модель

00:12:21.020 --> 00:12:24.980
вас поймет, и она вам скажет, а это был вот этот персонаж, или это был вот этот исполнитель,

00:12:24.980 --> 00:12:30.740
или все что угодно. Поэтому языковой интерфейс для нас очень натилен, и очень важно понимать,

00:12:30.740 --> 00:12:35.900
что это в первую очередь интерфейс, а не какая-то база знаний. Потому что мы с вами помним,

00:12:35.900 --> 00:12:41.100
что языковые модели, они хотя и обучены на бесконечном огромном количестве текстов,

00:12:41.100 --> 00:12:46.260
и не только текстов, они склонны галлюцинировать и давать вам какую-то ерунду. Просто потому,

00:12:46.260 --> 00:12:52.180
что это не база данных, это не Гугл, а это именно интерфейс языкового взаимодействия.

00:12:52.180 --> 00:12:57.820
Еще одна ментальная модель, которая очень важна и которая для меня является самой-самой главной и

00:12:57.820 --> 00:13:03.940
самой полезной. Потому что то, чем я занимаюсь, вот если все, я вам вначале немножко про себя

00:13:03.940 --> 00:13:08.900
рассказал, то есть и решение проблем, и исследование, и работа со знанием, это в первую очередь

00:13:08.900 --> 00:13:14.980
про рассуждение, про ризнинг. То есть все, что я делаю, в большей степени это вот такой ризнинг.

00:13:14.980 --> 00:13:19.860
Я пытаюсь думать на тему каких-то концепций, как-то их соединять, как-то их систематизировать,

00:13:19.860 --> 00:13:24.660
структурировать. И по сути, вот это на самом деле самая большая эволюция, революция, даже,

00:13:24.660 --> 00:13:29.500
наверное, правильно сказать, это то, что нам доступен действительно сегодня инструмент,

00:13:29.500 --> 00:13:34.860
который умеет рассуждать. И в этом смысле есть огромное количество споров на эту тему,

00:13:34.860 --> 00:13:40.060
что на самом деле, как же он умеет рассуждать, ведь если вы знакомы с тем, как работает вообще

00:13:40.060 --> 00:13:45.060
machine learning, с тем, как работают языковые модели в частности, вы знаете, что на самом деле модель не

00:13:45.060 --> 00:13:50.820
рассуждает, она имитирует человеческое рассуждение. То есть она делает так, что поскольку она обучена

00:13:50.820 --> 00:13:55.260
на большом количестве текстов, она думает, что если бы я был вот таким человеком, я бы сказал вот это.

00:13:55.260 --> 00:13:59.980
Ну, в смысле, она, конечно, так не думает, но я имею в виду принцип такой. И здесь очень классная аналогия

00:13:59.980 --> 00:14:08.140
с аэропланом братьев Райт и птицей. На самом деле долгое время люди думали, это, кстати, не моя

00:14:08.140 --> 00:14:10.140
аналогия. Это...

00:14:10.140 --> 00:14:17.900
сказал, как его зовут, Макс Тегмарк, это его аналогия,

00:14:17.900 --> 00:14:19.740
мне она очень понравилась, что долгое время люди думали,

00:14:19.740 --> 00:14:22.660
что на самом деле, чтобы научиться летать, нужно

00:14:22.660 --> 00:14:23.980
создать искусственную птицу.

00:14:23.980 --> 00:14:26.300
И представляете, искусственную птицу действительно создали,

00:14:26.300 --> 00:14:29.020
но буквально совсем недавно, буквально 10 лет назад она

00:14:29.020 --> 00:14:31.140
появилась, есть еще такой известный TED Talk, где эту

00:14:31.140 --> 00:14:33.820
птицу выпускают, она летает, и все такие «Вау!

00:14:33.820 --> 00:14:34.820
Настоящая птица!».

00:14:34.820 --> 00:14:37.340
Но на самом деле люди летают уже очень давно, больше 100

00:14:37.340 --> 00:14:39.900
лет, потому что братья Райт решили, да не нужно создавать

00:14:39.900 --> 00:14:43.180
искусственную птицу, нужно просто сделать две рейки,

00:14:43.180 --> 00:14:45.660
запихнуть туда мощный двигатель, и эта херня полетит.

00:14:45.660 --> 00:14:46.660
И она действительно полетела.

00:14:46.660 --> 00:14:50.580
Вот на самом деле с GPT случилась ровно такая же история.

00:14:50.580 --> 00:14:53.340
Мы взяли довольно простую модель трансформера, запихнули

00:14:53.340 --> 00:14:55.380
в нее весь интернет, и «Вау!»

00:14:55.380 --> 00:14:57.060
она научилась как-то рассуждать.

00:14:57.060 --> 00:14:58.060
Очень похожая история.

00:14:58.060 --> 00:15:00.540
Наверняка в какой-то момент, может быть через 100 лет,

00:15:00.540 --> 00:15:04.380
может быть раньше, мы создадим некую систему, которая

00:15:04.380 --> 00:15:06.420
будет рассуждать так же, как человек.

00:15:06.420 --> 00:15:08.420
Может быть это будет какой-то пирологический компьютер

00:15:08.420 --> 00:15:09.940
или что-то похожее.

00:15:09.940 --> 00:15:12.180
Но сейчас нам это не нужно, потому что сейчас мы создали

00:15:12.180 --> 00:15:16.380
вот такой первый… ну, в смысле не мы, хотя может

00:15:16.380 --> 00:15:19.780
быть кто-то из вас участвовал, я не участвовал в создании

00:15:19.780 --> 00:15:20.780
языковых моделей.

00:15:20.780 --> 00:15:27.420
Но люди из OpenAI, из DeepMind и других похожих лабораторий

00:15:27.420 --> 00:15:32.020
создали вот такую вот штуку, которая очень похожа на

00:15:32.020 --> 00:15:34.140
первый-первый самолет, который сделали братья Райт, и он

00:15:34.140 --> 00:15:35.140
полетел.

00:15:35.140 --> 00:15:37.660
И эта штука тоже полетела и полетела ого-го как.

00:15:37.660 --> 00:15:41.860
Если мы посмотрим на формальные критерии того, умеет ли

00:15:41.860 --> 00:15:44.180
сущность рассуждать, мы можем взять экзамены, которые

00:15:44.180 --> 00:15:46.500
проходят студенты.

00:15:46.500 --> 00:15:50.020
Это экзамены вербальные, такие как GIE, General Requirement

00:15:50.020 --> 00:15:53.300
Exam, это экзамены по биологии, по математике и так далее.

00:15:53.300 --> 00:15:55.860
И мы видим, что вот синим кружочком здесь показано

00:15:55.860 --> 00:15:56.860
GPT-4.

00:15:56.860 --> 00:15:59.980
И мы видим, что GPT-4 по многим экзаменам находится в

00:15:59.980 --> 00:16:01.620
десятом проценте.

00:16:01.620 --> 00:16:05.580
То есть она сдает экзамены так же, как топ-10 процентов

00:16:05.580 --> 00:16:06.580
студентов.

00:16:06.580 --> 00:16:08.260
То есть самые лучшие 10 процентов студентов.

00:16:08.260 --> 00:16:11.700
В каких-то, естественно, областях она еще, модель

00:16:11.700 --> 00:16:14.780
еще тормозит, но дадим ей немножко времени, она не

00:16:14.780 --> 00:16:15.780
так давно появилась.

00:16:15.780 --> 00:16:20.540
И третья, последняя ментальная модель, про которую можно

00:16:20.540 --> 00:16:22.460
думать, это персональный консультант.

00:16:22.460 --> 00:16:24.860
То есть у вас у каждого есть персональный консультант,

00:16:24.860 --> 00:16:44.860
очень умный и очень продуктивный.

00:16:44.860 --> 00:16:49.500
гораздо продуктивнее, чем мы с вами. Эта штука может все время что-то выдавать, о чем-то думать

00:16:49.500 --> 00:16:54.980
и совершенно не вставать в отличие от нас. Но как и с любым консультантом, очень важно не доверять

00:16:54.980 --> 00:17:00.820
ему полностью. Если вы полностью будете доверять какому-то консультанту, то, по сути, если консультант

00:17:00.820 --> 00:17:06.180
что-то про вас не понял, то он даст вам не тот совет, он даст вам не ту какую-то подсказку и приведет

00:17:06.180 --> 00:17:11.140
вас в какую-то катастрофу. Поэтому всегда очень полезно получать инпут от консультанта, но верифицировать

00:17:11.140 --> 00:17:15.460
его, думать про то, насколько он действительно актуален, насколько консультант хорошо работает,

00:17:15.460 --> 00:17:21.500
насколько я правильно его забрифовал, насколько я дал ему хороший бриф. Вот про такие вещи важно

00:17:21.500 --> 00:17:26.140
думать. Поэтому три метальные модели. Машинный рассуждение, языковой интерфейс и персональный

00:17:26.140 --> 00:17:31.580
консультант. Если будете думать о языковой модели в этих трех концепциях, то здорово.

00:17:31.580 --> 00:17:37.100
У вас сразу появится очень хорошее понимание, чего от нее можно ждать, а чего от нее ждать, наверное,

00:17:37.100 --> 00:17:42.500
не стоит. Ну и, собственно, как с любым консультантом, нужно уметь с ней общаться. И этот язык общения

00:17:42.500 --> 00:17:48.700
называется Prompt Engineering. По сути, это создание промптов, таких подсказок, направлений для модели,

00:17:48.700 --> 00:17:54.980
которые помогают ей выдать вам тот ответ, который вы от нее ожидаете, который для вас будет полезен.

00:17:54.980 --> 00:18:02.420
У Prompt Engineering есть три важные компоненты, которые я выбил, исходя из своего опыта. Первое,

00:18:02.420 --> 00:18:08.260
это очень важно понимать ограничения модели. Когда вы пишете промпт, очень важно понимать,

00:18:08.260 --> 00:18:14.140
на каком тренинг-сете была модель обучена, что это предиктивная модель, что ее задача

00:18:14.140 --> 00:18:21.100
предсказывать следующий токен, а не в том, чтобы… То есть она на самом деле не рассуждает,

00:18:21.100 --> 00:18:25.980
она просто предсказывает, она думает и она пытается сымитировать поведение какого-то

00:18:25.980 --> 00:18:30.380
человека или какого-то максимально среднего человека, который пишет тексты в интернете. И она

00:18:30.380 --> 00:18:35.420
склонна к галлюцинациям, то есть она может выдать вам какую-то полную ерунду, которую она сама

00:18:35.420 --> 00:18:39.700
придумает. Это важный пункт. Это вот такие ограничения. Просто когда мы с ней взаимодействуем,

00:18:39.700 --> 00:18:43.940
мы должны помнить, что у модели есть множество ограничений. Второй – это рации. Очень часто

00:18:43.940 --> 00:18:48.180
хороший промпт получается путем проб и ошибок. Вы пробуете что-то, получаете output, пробуете что-то,

00:18:48.180 --> 00:18:53.020
получаете output, смотрите на паттерны, которые возникают, сами учитесь вместе с моделью.

00:18:53.020 --> 00:18:59.140
Такой степ-вай-степ обучение. И третий – это контекст. Очень важно давать модели максимум деталей

00:18:59.140 --> 00:19:01.580
про вашу задачу. Эти детали.

00:19:01.580 --> 00:19:07.580
должны быть тоже систематизированы. Важно давать множество примеров. И, соответственно, важно помнить,

00:19:07.580 --> 00:19:13.020
что у модели есть долговременная и кратковременная память. И она склонна, особенно кратковременная

00:19:13.020 --> 00:19:19.420
память, склонна стираться. Долговременная память склонна иногда не подключаться. Про это тоже важно

00:19:19.420 --> 00:19:23.100
помнить. Но сейчас мы про это поговорим, пока это просто такое в формате интро.

00:19:23.100 --> 00:19:30.540
Ну, теперь, собственно, давайте перейдем к промптам. 15 минут я возгрузил теорию, теперь давайте по

00:19:30.540 --> 00:19:37.220
хардкору пойдем. Что вообще такое промпт? Промпт – это, как я уже сказал, некое сообщение,

00:19:37.220 --> 00:19:42.220
некий запрос, можно сказать, к модели. То есть вы создаете какой-то промпт в какой-то структуре,

00:19:42.220 --> 00:19:46.740
отправляете его модели, и модель вам дает какой-то результат в виде опыта. И вот хороший промпт,

00:19:46.740 --> 00:19:51.780
по моему опыту, я посмотрел большое количество разных структур, промптов, мне кажется,

00:19:51.780 --> 00:19:57.700
что хороший промпт состоит из 6 компонентов. Это роль, в которой модель выступает в данной задаче,

00:19:57.700 --> 00:20:02.660
это контекст, который вы ей даете, то есть может быть это ваши данные, может быть это подробное

00:20:02.660 --> 00:20:07.580
описание задачи, это инструкция, что в итоге нужно сделать, это стиль и тон, в котором вы ожидаете

00:20:07.580 --> 00:20:12.020
ответ, это формат, в котором вы ожидаете ответ, ну, то есть буквально это может быть текст,

00:20:12.020 --> 00:20:16.420
это может быть CSV, это может быть XML, это может быть какой-то очень странный список,

00:20:16.420 --> 00:20:21.020
или это может быть специальный формат какого-то инструмента, в который вы потом хотите вставить.

00:20:21.020 --> 00:20:25.780
И отдельно это примеры. Примеры могут быть чего угодно. Примеры могут быть формата, стиля,

00:20:25.780 --> 00:20:31.500
то есть примеры могут помогать модели дообучиться на этом промпте. Это называется

00:20:31.500 --> 00:20:37.620
future learning, далее future prompt. Чем больше вы даете примеров, тем легче модели сделать,

00:20:37.620 --> 00:20:44.260
понять, что вы вообще от нее хотите. Давайте мы с вами поговорим про кейс. Я вам дам сначала

00:20:44.260 --> 00:20:51.220
такой немножко странный кейс, вам может показаться. Это кейс из бизнес-школы, его дают в нескольких

00:20:51.220 --> 00:20:56.380
американских бизнес-школах, и он проверяет, насколько человек умеет в целом решать проблемы.

00:20:56.380 --> 00:21:05.060
Проблема выглядит так. Вы SEO Нью-Йоркского зоопарка. Ситуация. В Африке был обнаружен последний

00:21:05.060 --> 00:21:09.700
в мире динозавр. Это вот самый-самый последний динозавр, как-то он там сохранился,

00:21:09.700 --> 00:21:14.620
многого мы про него не знаем, да вот только что его нашли. Естественно, динозавр его кто-то должен

00:21:14.620 --> 00:21:21.620
купить, его выставляют на продажу. Должны ли мы его купить?

00:21:21.620 --> 00:21:27.180
купить динозавра, хорошее ли это решение. Вот такой вот кейс, это реальный кейс бизнес-школы,

00:21:27.180 --> 00:21:32.020
а еще его используют в приеме на работу в McKinsey и в похожей большой консалтинговой

00:21:32.020 --> 00:21:36.140
компании. Опять-таки он показывает, насколько у человека хорошо существует. Давайте теперь

00:21:36.140 --> 00:21:42.340
мы этот с вами кейс преобразуем в промпт, вот по нашей структуре. Роли. Ну, если нам нужен консультант

00:21:42.340 --> 00:21:46.460
McKinsey, то почему бы и нет, давайте прямо возьмем консультанта McKinsey. Да, смотрите, сейчас у нас

00:21:46.460 --> 00:21:50.500
будет базовый промптинг, это вот все, что я вам сейчас расскажу, это базовый промптинг, но это буквально

00:21:50.500 --> 00:21:54.700
займет у нас 5 минут, чтобы мы немножко синхронизировались, потом мы пойдем. Я вижу, что у вас

00:21:54.700 --> 00:22:03.260
немножко такие лица, такие «о, фак, мы это уже знаем». Но не переживайте, сейчас будет пожочь.

00:22:03.260 --> 00:22:07.180
Просто нам нужно всем синхронизироваться, потому что у всех, естественно, разный уровень работы с моделями.

00:22:07.180 --> 00:22:13.620
Поэтому немножко потерпите, если вы и так все это знаете. Следующий – это контекст. Контекст,

00:22:13.620 --> 00:22:19.140
то есть это по сути в чем заключается задача. Мы говорим, что вот я – это представитель этого

00:22:19.140 --> 00:22:25.380
зоопарка, а ты – Колумбу-Зу, это, кстати, зоопарк самый большой в Америке, он, помню, не в Нью-Йорке

00:22:25.380 --> 00:22:31.180
находится, но не важно, это два разных кейса, два разных типа кейса, смысл один и тот же.

00:22:31.180 --> 00:22:36.220
Я твой клиент, и, соответственно, я описываю полностью ситуацию, что вот динозавр был найден в Африке,

00:22:36.220 --> 00:22:41.060
да, и это единственный динозавр в последнем оставшем мире. Дальше я говорю инструкцию, пожалуйста, помоги мне

00:22:41.060 --> 00:22:46.260
понять, насколько хорошим решением является покупка этого динозавра. Дальше я говорю про формат,

00:22:46.260 --> 00:22:53.100
дай мне пять преимуществ того, что купить динозавр – это хорошее решение, и дай мне пять

00:22:53.100 --> 00:22:57.580
потенциальных проблем, которые мне этот динозавр может принести как представитель зоопарка.

00:22:57.580 --> 00:23:02.620
И дальше я прошу provide reasoning behind all the benefits in Dropbox, то есть расскажи мне, почему это хорошо

00:23:02.620 --> 00:23:08.340
и почему это плохо. И дальше я прошу его сделать это в определенном стиле, в очень формальный тон,

00:23:08.340 --> 00:23:12.900
потому что, видимо, я потом буду использовать это в своей презентации своему менеджеру,

00:23:12.900 --> 00:23:17.580
да, и, соответственно, пожалуйста, используем максимум бизнес-лексикон, чтобы это выглядело как

00:23:17.580 --> 00:23:23.300
настоящий такой бизнес-кейс. Вот такой промпт. Я могу сказать, что поскольку я много занимаюсь

00:23:23.300 --> 00:23:29.060
теорией принятия решений, я использую этот кейс на студентах часто, и я очень хорошо знаю его решения,

00:23:29.060 --> 00:23:33.620
множество решений. Я могу сказать, что модель исправилась потрясающе. Я не буду сейчас показывать

00:23:33.620 --> 00:23:37.900
вам output, я покажу вам output более сложных кейсов, но могу просто вам сказать, если хотите, естественно,

00:23:37.900 --> 00:23:43.900
попробуйте.

00:23:43.900 --> 00:23:47.660
попробуйте, я поширю с вами ссылки на все эти промпты в виде GitHub.

00:23:47.660 --> 00:23:51.180
И, соответственно, вы можете все это попробовать, посмотреть, как это работает.

00:23:51.180 --> 00:23:52.820
Вот, модель справилась потрясающе.

00:23:52.820 --> 00:23:55.660
То есть качество этого аутпута, оно очень хорошее.

00:23:55.660 --> 00:23:58.620
И опять-таки в формате итерации что тут важно сказать?

00:23:58.620 --> 00:24:01.180
Что один компонент модель все-таки не нашла.

00:24:01.180 --> 00:24:05.060
И я спросил ее, может быть, у тебя есть какие-то blind spots,

00:24:05.060 --> 00:24:07.100
то есть какие-то серые зоны, которых ты не охватил.

00:24:07.100 --> 00:24:11.060
GPT сказал, я языковая модель, я абсолютно гений, я все знаю.

00:24:11.060 --> 00:24:14.500
Но возможно, я не охватил вот эти компоненты.

00:24:14.500 --> 00:24:17.660
И действительно, там был фактор очень-очень значимый, который он не охватил.

00:24:17.660 --> 00:24:19.140
Поэтому, как я вам говорил, итерация.

00:24:19.140 --> 00:24:21.340
То есть если вы пробуете решить какую-то проблему,

00:24:21.340 --> 00:24:24.180
если вам кажется, что вдруг чего-то там не хватает,

00:24:24.180 --> 00:24:25.500
или вам в целом хочется проверить,

00:24:25.500 --> 00:24:29.700
вот сделайте такое, что типа спросите модель, а ничего ли ты не забыл?

00:24:29.700 --> 00:24:30.940
Ничего ли ты не забыла?

00:24:30.940 --> 00:24:36.620
Не знаю, как правильно общаться с моделью, она, он, мы по-разному.

00:24:36.620 --> 00:24:40.620
В зависимости, наверное, от роли, который модель исполняет.

00:24:40.620 --> 00:24:43.220
Вот, а теперь про примеры.

00:24:43.220 --> 00:24:45.780
Смотрите, я не нашел какого-то простого примера из своих кейсов.

00:24:45.780 --> 00:24:47.580
Я не хочу вас грузить сложными примерами.

00:24:47.580 --> 00:24:51.700
У меня в основном примеры или фьюш от обучения, оно про разные форматы.

00:24:51.700 --> 00:24:56.540
Чтобы вас не грузить моими форматами, я вам покажу очень простой кейс примера.

00:24:56.540 --> 00:24:59.100
Видите, это вот такой вот промпт.

00:24:59.100 --> 00:25:01.260
This is awesome negative, this is bad positive.

00:25:01.260 --> 00:25:03.340
Видите, никакой дополнительной инструкции нет.

00:25:03.340 --> 00:25:07.140
То есть часто можно выводить логику, то есть модель сама может вывести здесь логику.

00:25:07.140 --> 00:25:09.100
Как вы видите, здесь логика очень простая.

00:25:09.100 --> 00:25:15.940
Модель очень быстро распознала паттерн, что нужно просто оценить отзыв на какой-то сентимент.

00:25:15.940 --> 00:25:17.340
То есть он позитивный или негативный.

00:25:17.340 --> 00:25:20.460
И видите, она оценила следующий сентимент как негативный.

00:25:20.460 --> 00:25:21.140
Очень просто.

00:25:21.140 --> 00:25:23.660
То есть часто нам вообще не нужно писать инструкции.

00:25:23.660 --> 00:25:26.340
Не часто, сори, иногда нам вообще не нужно писать никакие инструкции.

00:25:26.340 --> 00:25:28.060
Мы просто делаем фьюш от леарнинга.

00:25:28.060 --> 00:25:30.420
То есть мы даем некоторое количество примеров.

00:25:30.420 --> 00:25:32.700
Модель сама на них как бы дообучается.

00:25:32.700 --> 00:25:36.940
И, соответственно, почему я в кавычках показываю, потому что там не совсем все так просто.

00:25:36.940 --> 00:25:39.780
Мы сейчас не будем уходить в нюансы машинного обучения.

00:25:39.780 --> 00:25:45.980
Скорее просто важно понимать, что модель использует эти примеры для того,

00:25:45.980 --> 00:25:49.940
чтобы спровоцировать в себе некое правильное поведение.

00:25:49.940 --> 00:25:53.420
И она говорит, что правильное поведение здесь это сказать негатив, что это отзыв негатив.

00:25:53.420 --> 00:25:57.660
И мы это получаем, как видите, никакого промптинга здесь помимо примеров нет.

00:25:57.660 --> 00:26:07.660
Поэтому вот такая структура.

00:26:07.660 --> 00:26:09.660
Ну, давайте пойдем в более сложный кейс.

00:26:09.660 --> 00:26:11.660
С простыми вроде разобрались,

00:26:11.660 --> 00:26:13.660
теперь давайте пойдем прям по хардкору.

00:26:13.660 --> 00:26:15.660
Сейчас будет более интересно.

00:26:15.660 --> 00:26:17.660
Вообще, откуда идет некий

00:26:17.660 --> 00:26:19.660
rational к этому?

00:26:19.660 --> 00:26:21.660
Как я уже говорил, я занимаюсь много

00:26:21.660 --> 00:26:23.660
консалтингом и я занимаюсь

00:26:23.660 --> 00:26:25.660
решением сложных проблем. Сложных в

00:26:25.660 --> 00:26:27.660
контексте, что я

00:26:27.660 --> 00:26:29.660
исследую какие-то большие-большие домены

00:26:29.660 --> 00:26:31.660
и пытаюсь понять, как компании

00:26:31.660 --> 00:26:33.660
себя в этих доменах вести.

00:26:33.660 --> 00:26:35.660
И эти домены, они

00:26:35.660 --> 00:26:37.660
становятся с каждым днем

00:26:37.660 --> 00:26:39.660
сложнее, с каждым месяцем точно. Например,

00:26:39.660 --> 00:26:41.660
давайте возьмем домен финансовой системы.

00:26:41.660 --> 00:26:43.660
Финансовая система очень-очень сложная. Я имею в виду глобальная

00:26:43.660 --> 00:26:45.660
мировая финансовая система. Она включает в себя большое-большое

00:26:45.660 --> 00:26:47.660
количество компонентов, монетарная политика,

00:26:47.660 --> 00:26:49.660
соответственно,

00:26:49.660 --> 00:26:51.660
фьючерсы, банды,

00:26:51.660 --> 00:26:53.660
центр банки, комодити маркет,

00:26:53.660 --> 00:26:55.660
сток маркет и так далее, и так далее, и так далее.

00:26:55.660 --> 00:26:57.660
И это все не список, это все

00:26:57.660 --> 00:26:59.660
компоненты, это система, которые друг с другом

00:26:59.660 --> 00:27:01.660
вот так вот взаимодействуют.

00:27:01.660 --> 00:27:03.660
И, соответственно, все это получается вот в такую

00:27:03.660 --> 00:27:05.660
сложную-сложную штуку.

00:27:05.660 --> 00:27:07.660
Ну, если брать это не в формате, да, не в формате

00:27:07.660 --> 00:27:09.660
списка, а в формате такой карты,

00:27:09.660 --> 00:27:11.660
это вот карта obesity,

00:27:11.660 --> 00:27:13.660
да, obesity это как-то, так сказать, ожирение,

00:27:13.660 --> 00:27:15.660
да, проблема с ожирением, проблема с лишним весом,

00:27:15.660 --> 00:27:17.660
которая характерна для Америки, да,

00:27:17.660 --> 00:27:19.660
и, соответственно, вот это вот попытка

00:27:19.660 --> 00:27:21.660
американских исследователей понять,

00:27:21.660 --> 00:27:23.660
какие причины у этого, у этой проблемы

00:27:23.660 --> 00:27:25.660
есть, у этой социальной проблемы есть. Почему я

00:27:25.660 --> 00:27:27.660
показываю вам этот кейс, потому что мы к вам, с вами

00:27:27.660 --> 00:27:29.660
сегодня к нему еще вернемся. Это такой

00:27:29.660 --> 00:27:31.660
довольно неплохой кейс, потому что он хорошо

00:27:31.660 --> 00:27:33.660
собран, и на его примере можно смотреть

00:27:33.660 --> 00:27:35.660
некоторое количество разных подходов.

00:27:35.660 --> 00:27:37.660
Ну, если мы здесь немножко зазумим, видите,

00:27:37.660 --> 00:27:39.660
у obesity есть много разных

00:27:39.660 --> 00:27:41.660
факторов. Это социальный фактор, это социальное

00:27:41.660 --> 00:27:43.660
давление, это проблема

00:27:43.660 --> 00:27:45.660
существ того, что слишком много еды в целом

00:27:45.660 --> 00:27:47.660
доступна, да, это стресс,

00:27:47.660 --> 00:27:49.660
да, это отсутствие или наоборот

00:27:49.660 --> 00:27:51.660
чрезмерный родительский контроль

00:27:51.660 --> 00:27:53.660
и так далее, и так далее, и так далее. Все это огромное количество

00:27:53.660 --> 00:27:55.660
политических, социальных, экономических, культурных

00:27:55.660 --> 00:27:57.660
факторов, которые вот друг с другом вступают

00:27:57.660 --> 00:27:59.660
в игру и делают эту проблему

00:27:59.660 --> 00:28:01.660
максимально сложной. Да, и вот моя задача

00:28:01.660 --> 00:28:03.660
по сути решать вот такие сложные проблемы.

00:28:03.660 --> 00:28:05.660
И в этом смысле искусственный интеллект

00:28:05.660 --> 00:28:07.660
мне очень сильно помогает.

00:28:07.660 --> 00:28:09.660
Но даже не такие сложные проблемы

00:28:09.660 --> 00:28:11.660
сегодня требуют сложных решений.

00:28:11.660 --> 00:28:13.660
Да, например, я здесь привел

00:28:13.660 --> 00:28:15.660
вопросы, которые, ну, на первый взгляд, кажутся

00:28:15.660 --> 00:28:17.660
очень простыми. Стоит ли арендовать

00:28:17.660 --> 00:28:19.660
жилье или покупать? Работают

00:28:19.660 --> 00:28:21.660
ли антидепрессанты? Нужно ли

00:28:21.660 --> 00:28:23.660
нам воспитывать детей дома и обучать

00:28:23.660 --> 00:28:29.660
детей дома?

00:28:29.660 --> 00:28:35.100
или отдавать их в школу? Насколько веганство более здоровый способ питания,

00:28:35.100 --> 00:28:41.420
чем как это, когда мы едим всё, едим мясо или там едим рыбу, в общем, когда мы не веганы?

00:28:41.420 --> 00:28:46.460
И вот какое-то количество таких вопросов, которые раньше нам казались довольно очевидными,

00:28:46.460 --> 00:28:51.140
ну или в целом, да, в целом у людей не было какой-то проблемы принять решение вот по такому вопросу.

00:28:51.140 --> 00:28:54.980
Сегодня мы видим, насколько сложны эти вопросы, насколько много факторов в них,

00:28:54.980 --> 00:28:59.140
и по сути они ничем не отличаются с точки зрения многофакторности вот тех проблем,

00:28:59.140 --> 00:29:04.580
которые я вам озвучил до этого. И именно здесь нам вступает в игру, с нами вступает в игру

00:29:04.580 --> 00:29:09.180
та самая модель reasoning машин. То есть машины, которая помогает нам рассуждать,

00:29:09.180 --> 00:29:12.900
машины, которая помогает нам думать, машины, которая помогает нам заниматься тем,

00:29:12.900 --> 00:29:16.860
что называется sense making. Sense making — это когда мы пытаемся понять, что вообще происходит,

00:29:16.860 --> 00:29:20.860
и из разрозненных кусочков информации собрать цельную картинку, в которой мы будем с вами

00:29:20.860 --> 00:29:26.980
принимать решение. И вот здесь вот языковые модели очень круто работают. Есть несколько подходов

00:29:26.980 --> 00:29:31.540
к решению сложных проблем. Сейчас мы с вами переходим в домен проблем-солвинга,

00:29:31.540 --> 00:29:37.260
и я покажу вам несколько подходов. Есть, естественно, прямой подход, то есть когда мы даем

00:29:37.260 --> 00:29:42.420
input модели и просим от нее какой-то output. Вариация этого подхода — это когда мы делаем

00:29:42.420 --> 00:29:49.500
какое-то количество итераций, я вам уже об этом сказал. Дальше, когда, наверное, появился

00:29:49.500 --> 00:29:53.180
чат GPT, вот мне кажется, или может быть даже, ну, наверное, да, примерно в это время,

00:29:53.180 --> 00:29:57.620
большое количество исследователей по всему миру стало думать о какой оптимальный подход

00:29:57.620 --> 00:30:02.900
prompting. И сначала появился подход, который называется chain of thoughts. То есть, по сути,

00:30:02.900 --> 00:30:07.220
когда модель решает какую-то проблему и представляет нам решение итоговое, мы говорим,

00:30:07.220 --> 00:30:12.260
воу-воу-воу, подожди, давай степ-бай-степ, расскажи мне, как ты пришел к этому решению,

00:30:12.260 --> 00:30:16.820
степ-бай-степ, шаг за шаг. Это вот chain of thoughts. И модель раскладывает свое рассуждение

00:30:16.820 --> 00:30:21.820
на такие шаги. Сейчас пример я вам покажу. Еще более продвинутый способ, который называется

00:30:21.820 --> 00:30:26.620
по-разному, но я его называю smart GPT, потому что он был в статье smart GPT, недавно вышла статья

00:30:26.620 --> 00:30:32.380
академическая, которая так и называлась, smart GPT. И smart GPT заключается в том, что мы берем

00:30:32.380 --> 00:30:37.900
некую проблему и мы разделяем ее на три стрима. Мы можем дать эту проблему трем разным экспертам.

00:30:37.900 --> 00:30:42.340
Мы можем дать эту проблему одной и той же модели, но с тремя разными температурами.

00:30:42.340 --> 00:30:52.340
А температура — это параметры языковой модели, которые мы делаем.

00:30:52.340 --> 00:30:56.820
отвечать за рандомность выхода, то есть рандомность

00:30:56.820 --> 00:30:57.820
отпыта.

00:30:57.820 --> 00:31:00.140
Если мы поставим температуру ближе к нулю, то результат

00:31:00.140 --> 00:31:01.540
будет максимально предсказуем.

00:31:01.540 --> 00:31:03.580
Если мы поставим температуру больше, то, соответственно,

00:31:03.580 --> 00:31:06.900
он будет… ну, потому что мы это называем креативным.

00:31:06.900 --> 00:31:10.820
Для модели это просто менее статистически… ну, то есть

00:31:10.820 --> 00:31:11.820
менее вероятность.

00:31:11.820 --> 00:31:15.580
То есть в том количестве текстов это продолжение

00:31:15.580 --> 00:31:18.740
фразы, оно было не так частотно, как вот другое.

00:31:18.740 --> 00:31:21.980
Ну, пример там «мой любимый цвет» или «мое любимое

00:31:21.980 --> 00:31:23.860
цвет»… Если мы поставим температуру на 0, то она

00:31:23.860 --> 00:31:24.860
скорее всего скажет «собака».

00:31:24.860 --> 00:31:28.340
А если мы поставим температуру на 9, то он может сказать,

00:31:28.340 --> 00:31:31.420
что это «дракон» или какое-нибудь мифическое существо или

00:31:31.420 --> 00:31:32.420
всю штуку.

00:31:32.420 --> 00:31:34.700
Фёдор говорит «trio of thoughts».

00:31:34.700 --> 00:31:37.220
Нет, «trio of thoughts» – это будет следующий наш подход.

00:31:37.220 --> 00:31:39.940
Это пока еще не «trio of thoughts», но хорошо, что ты правильно

00:31:39.940 --> 00:31:42.140
знаешь, сейчас мы как раз к этому перейдем.

00:31:42.140 --> 00:31:45.380
Ты прям предвосхитил мой следующий слайд.

00:31:45.380 --> 00:31:48.940
«Trio of thoughts» – это еще более продвинутый подход, который

00:31:48.940 --> 00:31:50.980
появился вообще относительно недавно.

00:31:50.980 --> 00:31:54.980
Буквально, наверное, недели три или четыре назад вышла

00:31:54.980 --> 00:31:58.700
статья, которая рассказывает про этот подход.

00:31:58.700 --> 00:32:01.660
И этот подход, он очень интересный тем, что, по сути,

00:32:01.660 --> 00:32:04.740
идея в том, что мы отправляем модель в такой лес, и она

00:32:04.740 --> 00:32:09.380
ходит по разным тропинкам, исследует их, смотрит, что

00:32:09.380 --> 00:32:12.260
будет, если пойти туда, и собирает некую цельную

00:32:12.260 --> 00:32:14.500
картину этого леса и понимает, куда лучше ходить, куда

00:32:14.500 --> 00:32:15.500
лучше не ходить.

00:32:15.500 --> 00:32:17.780
Ну, это вот такая красивая визуализация.

00:32:17.780 --> 00:32:20.020
Если брать более прагматичную, то это выглядит вот так.

00:32:20.020 --> 00:32:22.940
Она тыкается в разные ветки рассуждения, находит там

00:32:22.940 --> 00:32:25.620
что-то хорошее, нехорошее, ну, в смысле, хорошее, нехорошее,

00:32:25.620 --> 00:32:27.900
релевантное, нерелевантное, и дальше это продолжается

00:32:27.900 --> 00:32:28.900
и заканчивается.

00:32:28.900 --> 00:32:32.020
Теперь давайте на примерах с вами поговорим.

00:32:32.020 --> 00:32:38.860
Вот классический пример «Trio of thoughts», дерево мысли,

00:32:38.860 --> 00:32:41.580
наверное, нужно перевести.

00:32:41.580 --> 00:32:44.940
Обычно вообще все эти продвинутые подходы, их проблема в том,

00:32:44.940 --> 00:32:47.340
что, как правило, исследователи используют очень-очень

00:32:47.340 --> 00:32:49.340
примитивные примеры.

00:32:49.340 --> 00:32:51.780
Ну, типа решение какой-нибудь задачки, что у меня там

00:32:51.780 --> 00:32:54.180
было два ведра воды, мне дали третье ведро, а сколько

00:32:54.180 --> 00:32:55.420
у меня там в итоге воды?

00:32:55.420 --> 00:32:57.980
Или там я купил одно яблоко, я сейчас не утрирую, это

00:32:57.980 --> 00:32:58.980
именно такие примеры.

00:32:58.980 --> 00:33:01.860
У меня было 10 яблок, я отдал одно другу, одно продал,

00:33:01.860 --> 00:33:04.180
еще купил 5, сколько у меня яблок?

00:33:04.180 --> 00:33:07.780
Удивительно, что было какое-то такое одно время пренебрежения

00:33:07.780 --> 00:33:21.780
физико-моделя, но больше.

00:33:21.780 --> 00:33:26.100
какая-то же глупая штука, она не умеет даже решать эти проблемы с яблоками.

00:33:26.100 --> 00:33:32.380
Но удивительно, буквально за несколько, наверное, недель или месяцев модель научилась решать эти примеры очень легко.

00:33:32.380 --> 00:33:35.100
Ее просто потребовалось чуть-чуть дообучить и чуть-чуть донастроить.

00:33:35.100 --> 00:33:41.900
Вот прямо есть кейс разбора, что сначала модель это не умела делать, нужно было делать три thoughts,

00:33:41.900 --> 00:33:49.980
то есть нужно было говорить, окей, давай разберем чуть-чуть, шаг за шагом, вот у тебя было три яблока,

00:33:49.980 --> 00:33:55.540
она говорит, окей, у меня было три яблока, одно я отдала, одно я отдала, значит осталось сколько? Два, ну и так далее, как с ребенком.

00:33:55.540 --> 00:33:58.460
Сейчас модель сама это делает очень легко, без какой-либо проблемы.

00:33:58.460 --> 00:34:07.180
А учитывая, что еще появился плагин, который называется Wolfram, который подключает chat.gpt по сути к вычислительной базе Wolfram,

00:34:07.180 --> 00:34:13.420
модель способна на очень-очень сложные вычисления, я это проверял, ну какой-то сложный, насколько ям для меня сложный.

00:34:13.420 --> 00:34:19.420
Наверное, для кого-то они могут показаться простыми, но это вычисления всяких номинальных распределений, рисков и так далее,

00:34:19.420 --> 00:34:23.300
это действительно очень хорошо срабатывает, я опять все это проверял.

00:34:23.300 --> 00:34:26.620
Но давайте вернемся к нашему примеру дерева рассуждений.

00:34:26.620 --> 00:34:33.700
Видите, вот такой вот пример, у нас есть Боб, который находится в living room, то есть комнате, в жилой комнате, в спальне,

00:34:33.700 --> 00:34:39.980
он выходит на кухню, потом держит кружку, то есть происходит какое-то количество действий с этим Бобом.

00:34:39.980 --> 00:34:45.340
Проблема была сначала, что модель не могла понять, где в итоге находится шаг.

00:34:45.340 --> 00:34:54.260
То есть, видите, идея в том, что задача этой задачи запутать модель, то есть увести ее куда-то, и действительно она хорошо с этим справлялась.

00:34:54.260 --> 00:34:57.860
Поэтому был придуман вот такой вот промпт, промпт внизу.

00:34:57.860 --> 00:35:01.940
Представьте трех разных экспертов, которые отвечают на этот вопрос.

00:35:01.940 --> 00:35:08.540
Каждый эксперт дает по одному шагу, то есть в этом смысле это продолжение истории с Chain of Thoughts.

00:35:08.540 --> 00:35:10.340
Один шаг в одном единстве времени.

00:35:10.340 --> 00:35:13.780
И потом делят с этим шагом с группой.

00:35:13.780 --> 00:35:20.300
Вот это гениально, я когда это читал, думал, блин, вот люди додумались до этого, это очень креативно на самом деле.

00:35:20.300 --> 00:35:27.500
И соответственно, дальше группа эвалирует, то есть группа дает этому рассуждению какой-то evaluation.

00:35:27.500 --> 00:35:29.300
И дальше они продолжают вот так вот.

00:35:29.300 --> 00:35:34.140
То есть эти три эксперта пытаются решить вот эту, казалось бы, не очень сложную для нас, для людей, проблему.

00:35:34.140 --> 00:35:36.860
И представьте себе, они ее решают.

00:35:36.860 --> 00:35:43.860
Вот здесь вот приведем полный аут.

00:35:43.860 --> 00:35:51.660
Вот видите, сначала он говорит, окей, шарик в спальне, шарик на кухне, шарик в...

00:35:51.660 --> 00:35:56.660
Точнее, living room – это что у нас? Это гостиная. В гостиной, на кухне, в спальне.

00:35:56.660 --> 00:36:01.660
Bob carries the cup to the bedroom. Ok, so the ball must be in the cup.

00:36:01.660 --> 00:36:04.860
И второй эксперт, видите, говорит, о, я ошибся, я понял.

00:36:04.860 --> 00:36:10.060
То есть они начинают, эти два, как бы три эксперта, делиться друг с другом кусочками информации,

00:36:10.060 --> 00:36:13.460
да, и друг друга верифицировать. Да, и это очень круто.

00:36:13.460 --> 00:36:16.260
И это на самом деле хорошо работает на более сложных проблемах.

00:36:16.260 --> 00:36:20.060
Естественно, что удивительно, что, естественно, большое количество кейсов –

00:36:20.060 --> 00:36:23.460
это вот такие довольно простые проблемы, которые запутывают модель.

00:36:23.460 --> 00:36:27.460
Но на самом деле этот же подход очень круто работает на настоящих проблемах,

00:36:27.460 --> 00:36:32.060
которые мы с вами уже решаем либо в своей какой-то персональной жизни,

00:36:32.060 --> 00:36:34.460
либо в нашей бизнес-жизни.

00:36:34.460 --> 00:36:36.060
Сейчас мы с вами перейдем к такой проблеме.

00:36:36.060 --> 00:36:39.460
Единственное, что я, наверное, сейчас включу свет, чтобы меня было лучше видно,

00:36:39.460 --> 00:36:43.060
то поскольку солнышко село, я возьму у вас минутку.

00:36:43.060 --> 00:36:45.660
А вы можете пока задать мне какие-нибудь вопросы, если они появились.

00:37:13.060 --> 00:37:21.660
Так гораздо лучше, теперь я не исчезаю во тьме.

00:37:21.660 --> 00:37:23.660
Давайте посмотрим, есть ли у вас вопросы.

00:37:23.660 --> 00:37:26.660
Такой алгоритм реализуется с помощью AutoGPT?

00:37:26.660 --> 00:37:28.660
Да, можно реализовать с помощью AutoGPT.

00:37:28.660 --> 00:37:32.660
Да, да, да. То есть можно это запрограммировать с помощью лангчейна.

00:37:32.660 --> 00:37:38.660
Лангчейн – это библиотека для бетона, которая позволяет вам просто работать с разными исковыми моделями.

00:37:38.660 --> 00:37:45.660
Можно это делать в лангчейне, можно это делать в других средах, которые позволяют так называемый мультитреддинг,

00:37:45.660 --> 00:37:50.660
то есть запускать сразу модели в нескольких тредах, в нескольких ветках вычислений.

00:37:50.660 --> 00:37:58.660
Можно это же делать в AutoGPT, просто это чуть более геморройно, но в принципе результат будет точно такой же.

00:37:58.660 --> 00:38:08.660
Так, кажется никаких больших проблем.

00:38:08.660 --> 00:38:10.660
вопросов у нас нет, далее они спаси за вопрос.

00:38:12.660 --> 00:38:13.660
Давайте тогда продолжать.

00:38:13.660 --> 00:38:15.660
Давайте я вам дам настоящую проблему.

00:38:15.660 --> 00:38:18.660
Ну как настоящая, это тоже настоящая проблема, но вряд ли кто-то из вас

00:38:18.660 --> 00:38:21.660
страдает с тем, чтобы понять в какой комнате находится шарик.

00:38:22.660 --> 00:38:24.660
Наверняка у нас с вами проблемы более сложные.

00:38:24.660 --> 00:38:25.660
Вот вам ситуация.

00:38:25.660 --> 00:38:28.660
Ситуация, опять-таки, очень типичная, очень интересная.

00:38:28.660 --> 00:38:31.660
Эта ситуация, этот кейс, который я вывел для, опять-таки,

00:38:31.660 --> 00:38:36.660
для своей программы по принятию решений, и он реально очень хороший

00:38:36.660 --> 00:38:39.660
с точки зрения того, что он показывает сложность вообще принятия решений

00:38:39.660 --> 00:38:42.660
в каких-то современных условиях, в переизбытке или, наоборот,

00:38:42.660 --> 00:38:43.660
недостатке информации.

00:38:43.660 --> 00:38:45.660
Значит, в чем заключается кейс?

00:38:45.660 --> 00:38:46.660
У нас есть Джек.

00:38:46.660 --> 00:38:49.660
Джек работает разработчиком большой корпорации.

00:38:49.660 --> 00:38:52.660
В какой-то момент Джек переключился на удаленную работу.

00:38:52.660 --> 00:38:53.660
Почему этот кейс такой подробный?

00:38:53.660 --> 00:38:55.660
Потому что здесь очень-очень много факторов.

00:38:56.660 --> 00:38:59.660
У Джека есть семья в виде жены и дочки, и, соответственно,

00:38:59.660 --> 00:39:02.660
в последнее время Джек у нас страдает депрессивными эпизодами.

00:39:02.660 --> 00:39:07.660
Собственно, для этого он и переместился в загород.

00:39:07.660 --> 00:39:10.660
И это перемещение ему не помогло.

00:39:10.660 --> 00:39:13.660
Он переместился в загород, а все равно депрессия продолжается.

00:39:13.660 --> 00:39:17.660
Джек посетил трех докторов, двух психиатров и одного психолога.

00:39:18.660 --> 00:39:21.660
Наоборот, двух психологов и одного психиатра.

00:39:21.660 --> 00:39:26.660
И, соответственно, один из докторов, который самый продвинутый,

00:39:26.660 --> 00:39:30.660
самый опытный, прописал ему небольшую дозу антидепрессанта,

00:39:30.660 --> 00:39:32.660
которая называется Estolpro.

00:39:32.660 --> 00:39:36.660
Другие два доктора сказали, что лучше пока сохраняться

00:39:36.660 --> 00:39:39.660
на уровне терапии, не медикаментозной.

00:39:40.660 --> 00:39:42.660
У Джека, естественно, есть сомнения.

00:39:42.660 --> 00:39:45.660
Это, кстати, очень частая ситуация, когда доктора дают совершенно

00:39:45.660 --> 00:39:48.660
разные картины, разные диагнозы, и в итоге решение нужно принимать нам с вами.

00:39:49.660 --> 00:39:52.660
Если раньше можно было делегировать доктору, и нам казалось,

00:39:52.660 --> 00:39:53.660
что, вау, конечно, доктор разбирается.

00:39:53.660 --> 00:39:56.660
Но учитывая, как быстро меняется научная картина,

00:39:56.660 --> 00:40:01.660
буквально в 2022 году вышло очень большое исследование по эффективности

00:40:01.660 --> 00:40:04.660
антидепрессантов, которое, в общем, in essence показало,

00:40:04.660 --> 00:40:07.660
что антидепрессанты в каких-то кейсах работают хуже, чем плацебо.

00:40:07.660 --> 00:40:09.660
То есть они работают, но плацебо работает лучше.

00:40:10.660 --> 00:40:12.660
Это удивительный кейс.

00:40:12.660 --> 00:40:15.660
Там много нюансов, я сейчас очень упрощаю, но идея в этом.

00:40:15.660 --> 00:40:20.660
Поэтому Джек очень сомневается, что стоит ли ему принимать эти медикаменты.

00:40:20.660 --> 00:40:23.660
И он сам прошел тест-бэк.

00:40:23.660 --> 00:40:25.660
Тест-бэк показывает уровень депрессии.

00:40:25.660 --> 00:40:28.500
Человек – это простой довольно тест, который по определенной

00:40:28.500 --> 00:40:30.820
шкале показывает, какой уровень депрессии у человека

00:40:30.820 --> 00:40:31.820
есть.

00:40:31.820 --> 00:40:33.300
19 – это вот такое пограничное состояние.

00:40:33.300 --> 00:40:37.380
И Джек на самом деле хочет, чтобы у него была качественная

00:40:37.380 --> 00:40:41.900
жизнь высокая, и он переживает, что будут ли какие-то сайтефекты

00:40:41.900 --> 00:40:43.420
вот этой медикаментозной терапии.

00:40:43.420 --> 00:40:46.940
И он пришел, допустим, к нам, как к нашему консультанту,

00:40:46.940 --> 00:40:50.380
и спрашивает нас, что же нам с этим делать.

00:40:50.380 --> 00:40:53.060
Видите, это фактически промпт, то есть это промпт, который

00:40:53.060 --> 00:40:56.900
я дал Джипити смотреть, что сказал Джипити.

00:40:56.900 --> 00:40:59.500
Он сказал, что Джек находится в сложной ситуации.

00:40:59.500 --> 00:41:02.900
Спасибо, что ты признал сложность этой проблемы.

00:41:02.900 --> 00:41:06.100
Мне нравится, что вообще модель очень эмпатичная.

00:41:06.100 --> 00:41:07.700
Она умеет сказать, что на самом деле… Ну, то есть

00:41:07.700 --> 00:41:09.700
она не сразу тебя выплевывает ответом, она говорит, что

00:41:09.700 --> 00:41:11.740
вот на самом деле вы находитесь в сложной ситуации, то есть

00:41:11.740 --> 00:41:12.740
подумайте об этом.

00:41:12.740 --> 00:41:15.780
Да, и соответственно модель выдала какое-то количество

00:41:15.780 --> 00:41:17.580
довольно неплохих рекомендаций.

00:41:17.580 --> 00:41:22.140
Follow up the doctor, то есть можно сказать доктору, что у меня

00:41:22.140 --> 00:41:24.140
есть concern, я переживаю.

00:41:24.140 --> 00:41:25.820
В принципе, это неплохой совет.

00:41:25.820 --> 00:41:29.460
Можно поискать другое мнение, еще четвертое мнение,

00:41:29.460 --> 00:41:32.140
сказать еще к одному доктору, но это будет уже, наверное,

00:41:32.140 --> 00:41:34.140
перебор, потому что это мнение тоже непонятно,

00:41:34.140 --> 00:41:35.140
как его эвалировать.

00:41:35.140 --> 00:41:37.820
Если три мнения сложно эвалировать, четыре мнения эвалировать

00:41:37.820 --> 00:41:38.820
еще сложнее.

00:41:38.820 --> 00:41:41.660
Дальше, в общем-то, это какая-то альтернативная терапия,

00:41:41.660 --> 00:41:44.660
например, когнитивно-поведенческая терапия, и это какие-то изменения

00:41:44.660 --> 00:41:45.660
образа жизни.

00:41:45.660 --> 00:41:48.300
Это я 4 вам здесь привел, я вам дал гораздо больше,

00:41:48.300 --> 00:41:49.300
там около 8.

00:41:49.300 --> 00:41:53.500
Это прикольно, но проблему это не решает, вроде как

00:41:53.500 --> 00:41:54.500
непонятно, что делать.

00:41:54.500 --> 00:41:56.660
Если бы я представил себя в роли Джеккарс, то у меня

00:41:56.660 --> 00:42:00.380
есть много разных рутов, а что с этим делать, в итоге

00:42:00.380 --> 00:42:01.380
непонятно.

00:42:01.380 --> 00:42:03.420
Поэтому давайте мы попробуем использовать подход, который

00:42:03.420 --> 00:42:04.420
называется…

00:42:04.420 --> 00:42:06.220
Но это такой гибрид на самом деле.

00:42:06.220 --> 00:42:09.620
Это гибрид, который я увидел у чувака, который называется

00:42:09.620 --> 00:42:12.460
в YouTube All About AI, очень крутой канал, вам советую, у него

00:42:12.460 --> 00:42:14.620
на самом деле очень много интересного всего там происходит.

00:42:14.620 --> 00:42:17.500
Я вам, естественно, follow up, пришлю все эти ссылки.

00:42:17.500 --> 00:42:19.180
Смотрите, какой промп, гениально, он придумал.

00:42:19.180 --> 00:42:22.020
Он, по сути, объединяет в себя два подхода, даже

00:42:22.020 --> 00:42:23.020
три подхода.

00:42:23.020 --> 00:42:27.020
Он объединяет в себя Chain of Thoughts, Trio of Thoughts и Smart GPT.

00:42:27.020 --> 00:42:29.500
Значит, первый шаг, мы говорим, окей, вот у меня есть такая

00:42:29.500 --> 00:42:32.300
проблема, она связана вот с этой проблемной зоной.

00:42:32.300 --> 00:42:35.420
Можешь мне найти три разных решения, чтобы они были

00:42:35.420 --> 00:42:38.500
абсолютно разные, чтобы они не пересекались, и учитывай

00:42:38.500 --> 00:42:39.500
большое количество фактов.

00:42:39.500 --> 00:42:49.500
Дальше мы в геоминвиде выдаем факты.

00:42:49.500 --> 00:42:53.540
Вот мы сделали первую интеракцию, дальше модель выдала нам 3 этих решений.

00:42:53.540 --> 00:42:54.820
Дальше что мы делаем?

00:42:54.820 --> 00:42:58.100
Дальше мы говорим, окей, теперь для всех трех этих решений,

00:42:58.100 --> 00:43:02.740
сам оцени или сама оцени их потенциал.

00:43:02.740 --> 00:43:07.340
Все за, все против, насколько это сложно, какие могут быть осложнения,

00:43:07.340 --> 00:43:08.740
какие могут быть проблемы.

00:43:08.740 --> 00:43:13.260
И, соответственно, каким-то образом оцени вероятность успеха решения нашей проблемы

00:43:13.260 --> 00:43:15.220
и у каждого из этих трех решений.

00:43:15.220 --> 00:43:18.060
А дальше начинается третий шаг, он на самом деле самый интересный.

00:43:18.060 --> 00:43:23.980
Он заключается в том, что теперь для каждого решения углуби свой процесс.

00:43:23.980 --> 00:43:26.340
То есть интересно сказать, модель, ты на самом деле мыслишь поверхностно,

00:43:26.340 --> 00:43:27.540
теперь углуби свой процесс.

00:43:27.540 --> 00:43:31.260
Генерируй потенциальный сценарий, стратегии имплементации

00:43:31.260 --> 00:43:38.060
и нужных партнеров для того, чтобы это решение проблемы можно было реализовать.

00:43:38.060 --> 00:43:41.700
Подумай про препятствия, это как раз про дерево.

00:43:41.700 --> 00:43:45.220
То есть теперь модель уходит в тот самый лес и смотрит,

00:43:45.220 --> 00:43:48.740
о, вот такие есть сценарии, вот такие есть нюансы и так далее.

00:43:48.740 --> 00:43:50.940
Здесь, правда, эти три сценария не взаимодействуют,

00:43:50.940 --> 00:43:52.700
потому что здесь сложно придумать взаимодействие.

00:43:52.700 --> 00:43:54.220
Я думал над этим, но получается, что это ерунда.

00:43:54.220 --> 00:43:56.220
У меня есть те, где они взаимодействуют, это еще круче.

00:43:56.220 --> 00:43:57.980
Но, к сожалению, не могу показать.

00:43:57.980 --> 00:44:03.020
Но можно подумать даже, как здесь вот эти три пути, три треда сделать так,

00:44:03.020 --> 00:44:04.740
чтобы они друг с другом еще взаимодействовали.

00:44:04.740 --> 00:44:08.260
То есть тоже, например, дать трех экспертов, один эксперт будет психолог,

00:44:08.260 --> 00:44:11.940
другой психиатр, третий какой-нибудь лайфстайл, в целом такой терапевт.

00:44:11.940 --> 00:44:14.340
И подумать, как они друг с другом могут поспорить.

00:44:14.340 --> 00:44:17.260
Тут есть очень много интересного и тут есть что поискать.

00:44:17.260 --> 00:44:20.060
Но давайте сейчас возьмем вот это решение.

00:44:20.060 --> 00:44:26.900
А соответственно, также рассмотри разные потенциальные проблемы и какие-то нюансы.

00:44:26.900 --> 00:44:28.900
А дальше зачем мы это делаем?

00:44:28.900 --> 00:44:30.740
Поскольку мы друг с другом их никак не мэчим,

00:44:30.740 --> 00:44:33.660
казалось бы, что это даст нам больше информации.

00:44:33.660 --> 00:44:34.900
Но дальше начинается интересно.

00:44:34.900 --> 00:44:36.660
Последний этап, он тоже очень интересный.

00:44:36.660 --> 00:44:40.820
Потому что когда теперь модель расширила для себя поле возможных вариантов,

00:44:40.820 --> 00:44:42.460
у нее появилось гораздо больше информации.

00:44:42.460 --> 00:44:46.100
И на основании этой информации модель может лучше сделать эволюцию.

00:44:46.100 --> 00:44:50.100
То есть она может сделать реэволюцию этих сценариев,

00:44:50.100 --> 00:44:52.900
которые помогут ей принять лучшее решение.

00:44:52.900 --> 00:44:54.780
И это вау, это работает очень круто.

00:44:54.780 --> 00:44:56.780
Давайте посмотрим, что из этого получилось.

00:44:56.780 --> 00:45:02.060
Во-первых, модель выдала вот такие три варианта решения для Джека.

00:45:02.060 --> 00:45:14.060
Первый вариант просто основан на когнитивно-поведенческой терапии.

00:45:14.060 --> 00:45:15.720
изменения в образе жизни.

00:45:15.720 --> 00:45:19.540
Второй вариант, он медикаментозный, то есть по сути попробовать

00:45:19.540 --> 00:45:21.220
принимать этот антидепрессант.

00:45:21.220 --> 00:45:23.940
И третий, он такой больше про погружение в семью и

00:45:23.940 --> 00:45:25.460
про поиск поддержки семьи.

00:45:25.460 --> 00:45:27.900
Ну действительно, эти три варианта, они очень разные

00:45:27.900 --> 00:45:30.700
сами по себе, что интересно.

00:45:30.700 --> 00:45:33.180
Теперь смотрите, мы берем первый подход, и вот смотрите,

00:45:33.180 --> 00:45:35.820
сколько всего интересного модель тут на Кенерио.

00:45:35.820 --> 00:45:38.940
Во-первых, она показала, что прямо из Кенерио сценарий,

00:45:38.940 --> 00:45:44.980
Джек начинает свои сессии терапии сначала онлайн,

00:45:44.980 --> 00:45:48.340
это кстати не как тема периодической терапии, это просто терапия,

00:45:48.340 --> 00:45:51.980
сначала онлайн, потом он переходит в in-person, потом

00:45:51.980 --> 00:45:55.900
он добавляет себе какие-то рутины, с этим уже можно

00:45:55.900 --> 00:45:56.900
работать.

00:45:56.900 --> 00:45:58.820
Если я был бы Джеком, мне бы уже понятно, сначала

00:45:58.820 --> 00:46:02.540
сделать, потом то, то есть появляется какая-то фактура,

00:46:02.540 --> 00:46:05.100
что очень важно вообще в исследованиях, это когда

00:46:05.100 --> 00:46:07.220
появляется какая-то фактура, когда мы не просто говорим,

00:46:07.220 --> 00:46:09.380
что слушайте, нам нужно идти туда, а когда у нас

00:46:09.380 --> 00:46:11.900
появляется картинка такая трехмерная, интересная,

00:46:11.900 --> 00:46:13.780
и мы понимаем, что на самом деле, почему нам нужно идти

00:46:13.780 --> 00:46:14.780
туда.

00:46:14.780 --> 00:46:19.700
Он начинает использовать разные приложения и так

00:46:19.700 --> 00:46:20.700
далее, и так далее.

00:46:20.700 --> 00:46:22.340
И здесь модель, видите, дает очень много разных фактур

00:46:22.340 --> 00:46:23.340
и стратегий.

00:46:23.340 --> 00:46:26.260
Более того, давайте посмотрим второе решение, которое

00:46:26.260 --> 00:46:28.180
медикаментозное, посмотрите вниз, вот здесь unexpected

00:46:28.180 --> 00:46:31.260
outcomes, здесь модель предусмотрела, что типа,

00:46:31.260 --> 00:46:37.340
медикейшн майт нот ворк, то есть медицина может вообще

00:46:37.340 --> 00:46:38.340
не сработать, не помочь.

00:46:38.340 --> 00:46:41.540
И, соответственно, в этом случае Джеку нужно еще

00:46:41.540 --> 00:46:44.260
раз проконсультироваться с врачом, который может

00:46:44.260 --> 00:46:45.260
показать ему другой способ.

00:46:45.260 --> 00:46:47.340
То есть видите, какое количество возможных сценариев, здесь

00:46:47.340 --> 00:46:48.340
уже модель рассмотрела.

00:46:48.340 --> 00:46:51.100
И это удивительно круто, потому что когда мы решаем

00:46:51.100 --> 00:46:53.220
настоящий бизнес-проблему, ну это тоже настоящая проблема,

00:46:53.220 --> 00:46:55.340
но это все-таки не бизнес, это такая, как бы сказать,

00:46:55.340 --> 00:46:56.340
жизненная проблема человека.

00:46:56.340 --> 00:46:58.900
Но в бизнесе, естественно, этих сценариев, этих возможностей,

00:46:58.900 --> 00:47:00.340
этих рисков еще больше.

00:47:00.340 --> 00:47:02.340
И это невероятно круто работает.

00:47:02.340 --> 00:47:04.540
То есть если раньше на решение таких проблем уходило,

00:47:04.540 --> 00:47:07.540
ну я могу сказать, что зависит, конечно, от контекста, но

00:47:07.540 --> 00:47:10.740
в разы больше времени, чтобы вот эти все вещи предусмотреть.

00:47:10.740 --> 00:47:13.740
Сейчас это сильно упростило все.

00:47:13.740 --> 00:47:16.340
И упростило не просто по времени, но и по качеству.

00:47:16.340 --> 00:47:18.340
Качество проработки этих веток очень крутое.

00:47:18.340 --> 00:47:22.340
А если мы добавим к этому вот эту историю с cross-опылением

00:47:22.340 --> 00:47:24.540
этих веток, то тут вообще может быть какой-то дикий

00:47:24.540 --> 00:47:25.540
взрыв мозга.

00:47:25.540 --> 00:47:28.860
Вот, так что видите, модель теперь все это предусмотрела.

00:47:28.860 --> 00:47:30.660
И дальше…

00:47:30.660 --> 00:47:34.460
она сделала вообще удивительную вещь, она упаковала все это в табличку

00:47:34.460 --> 00:47:35.980
и помогла нам принять решение.

00:47:35.980 --> 00:47:39.060
И для нас, помните, если мы вернемся к началу кейса,

00:47:39.060 --> 00:47:41.220
вспомните, что для нас очень важный критерий был safety,

00:47:41.220 --> 00:47:43.820
то есть Джек очень переживал, что что-то с ним случится.

00:47:43.820 --> 00:47:47.860
Видите, модель оценила все три варианта решений по параметру safety.

00:47:47.860 --> 00:47:52.460
И это очень хороший оценок, действительно терапевтический способ самый безопасный,

00:47:52.460 --> 00:47:53.660
модель ему дала 9.

00:47:53.660 --> 00:47:55.900
Ведикаминтозный, опять-таки, он не очень опасный,

00:47:55.900 --> 00:47:57.740
потому что это довольно проверенный антипрессант,

00:47:57.740 --> 00:48:01.340
и в целом никаких прям диких рисков там нет,

00:48:01.340 --> 00:48:03.860
ну то есть риски-то есть, но они минимальны.

00:48:03.860 --> 00:48:08.700
И, соответственно, третий подход, который получился, мне кажется, довольно таким спорным,

00:48:08.700 --> 00:48:12.980
но окей, она оценила его как 8, то есть он тоже довольно безопасный.

00:48:12.980 --> 00:48:15.820
И видите, модель помогла нам принять решение,

00:48:15.820 --> 00:48:17.780
модель помогла нам построить трек,

00:48:17.780 --> 00:48:20.940
модель помогла нам, если мы ее спросим, а как быть, если это не сработает,

00:48:20.940 --> 00:48:24.940
модель нам дорисует, что дальше делать, как переключаться между этими способами.

00:48:24.940 --> 00:48:28.940
И это, конечно, сильно-сильно потрясает, да, это очень круто.

00:48:28.940 --> 00:48:36.540
Вот, друзья, есть ли у вас вопросы про модель TRIO Thoughts или Chain of Thoughts,

00:48:36.540 --> 00:48:39.740
или Smart GPT, или мы можем двигаться дальше?

00:48:39.740 --> 00:48:48.020
Так, GPT охватывает материал, доступ к которому ограничен платным подписками и авторизацией,

00:48:48.020 --> 00:48:52.140
например, научные статьи, value которых может быть существенно выше для применных запросов.

00:48:52.140 --> 00:48:59.380
Если вы используете плагин, например, Talk to my PDF, да, или как он называется?

00:48:59.380 --> 00:49:04.260
Psy, я забыл, как он называется, но он самый такой популярный.

00:49:04.260 --> 00:49:05.300
Что вы можете сделать?

00:49:05.300 --> 00:49:09.300
Вы можете взять этот PDF, научные статьи, загрузить его на их сайт,

00:49:09.300 --> 00:49:12.140
как правило, лучше всего работает, и дальше модель будет с ним взаимодействовать.

00:49:12.140 --> 00:49:14.940
Я сейчас вам покажу, как это делается и каким результатом это привело.

00:49:14.940 --> 00:49:16.540
У меня есть такой кейс чуть-чуть дальше.

00:49:16.540 --> 00:49:20.620
Так, Daniel спрашивает, а что насчет ограничений данных до 2021 года?

00:49:20.620 --> 00:49:24.580
Оно все еще актуально, к примеру, про ту статью об антидепрессантах.

00:49:24.580 --> 00:49:25.500
Да, офигенный вопрос.

00:49:25.500 --> 00:49:28.340
Дальше я дал модели вот эту новую статью.

00:49:28.340 --> 00:49:32.620
То есть я опять-таки с помощью Ask my PDF дал ей новую статью,

00:49:32.620 --> 00:49:34.220
и модель поменял свое решение.

00:49:34.220 --> 00:49:37.340
Я просто не стал здесь показывать, потому что это было уже, ну как сказать,

00:49:37.340 --> 00:49:40.020
она немножко вот этот второй способ чуть-чуть настроила.

00:49:40.020 --> 00:49:44.340
То есть по сути у модели есть способность, мы это в целях принятия решения называем

00:49:44.340 --> 00:49:47.620
Bias-Basic Update, то есть мы используем байас модель обновления.

00:49:47.620 --> 00:49:52.060
когда у нас поступает новая информация, мы как-то меняем свою рисковую модель.

00:49:52.060 --> 00:49:59.060
И модель, модель, модель, очень много слов, модель, в общем, чайпити поменял свою рисковую модель.

00:49:59.060 --> 00:50:03.460
И это было вау, это было очень круто. То есть я на самом деле, когда это сделал,

00:50:03.460 --> 00:50:09.860
я был в таком шоке, что долго еще потом рефлексировал. В этом смысле меня довольно забавляют

00:50:09.860 --> 00:50:13.900
люди, которые до сих пор ходят там по каким-то конференциям и говорят, ну, на самом деле,

00:50:13.900 --> 00:50:20.060
искусственный интеллект – это просто маркетинговый термин. И я такой, чувак, вообще в каких-то

00:50:20.060 --> 00:50:28.820
моментах эта штука будет поумнее тебя. Поэтому тут я бы еще поспорил, кто из вас маркетинговый термин.

00:50:28.820 --> 00:50:33.460
Поэтому есть такое, конечно, пренебрежительное отношение до сих пор к моделям, но действительно

00:50:33.460 --> 00:50:38.500
уже можно сказать, что это штука, которая демонстрирует все трети типа интеллекта, которые я вам

00:50:38.500 --> 00:50:46.420
рассказал. Потому что по сути все вот эти вот output – это по сути поиск паттернов, создание моделей и предсказание.

00:50:46.420 --> 00:50:53.940
Так, вопросы к Виктору. Как влияет, если в самом начале, в первом шаге попросить не три стратегии,

00:50:53.940 --> 00:50:59.820
а, например, 10 или просто several. Ну, several – это никогда не предсказуемо. Она может several делать 3,

00:50:59.820 --> 00:51:08.140
может быть 7, да, это все дело случай. 10 я, честно говоря, не пробовал. Но мне кажется,

00:51:08.140 --> 00:51:12.300
это будет какой-то перебор, с этим будет просто очень сложно работать. Хотя можно поэкспериментировать.

00:51:12.300 --> 00:51:18.180
Честно скажу, я не пробовал. Так, Марин спрашивает, а есть ли надо для решения проблемы, чтобы сама модель

00:51:18.180 --> 00:51:24.300
изучила все возможные способы, например, последние исследования, разные подходы. То есть не ты статью

00:51:24.300 --> 00:51:33.100
скармливаешь ей, а хочешь от нее добиться конкретной инфы. Ага, да. Тут есть нюанс. Значит, эти два шага

00:51:33.100 --> 00:51:38.700
нужно разделить. Первое – это поиск по исследованиям, научным статьям и так далее. Это, в принципе,

00:51:38.700 --> 00:51:44.140
разные инструменты умеют делать довольно неплохо. Например, есть такой инструмент Elicit, который

00:51:44.140 --> 00:51:50.620
очень хорошо ищет по научным статьям. Также в GPT есть такой плагин, который называется Scholar AI.

00:51:50.620 --> 00:51:57.540
Scholar AI умеет искать по научным статьям. То есть, в принципе, даже внутри чат GPT можно сделать

00:51:57.540 --> 00:52:04.540
такую среду. Если вы умеете пользоваться линкчейном, то есть через API,

00:52:04.540 --> 00:52:08.260
забирать разные статьи, искать их и так далее.

00:52:08.260 --> 00:52:09.660
Это можно сделать уже очень легко.

00:52:09.660 --> 00:52:11.380
Эта штука будет называться автономный агент.

00:52:11.380 --> 00:52:12.380
Что такое автономный агент?

00:52:12.380 --> 00:52:17.540
Это некий набор действий, то есть некий алгоритм,

00:52:17.540 --> 00:52:19.380
направленный на выполнение определенной задачи через

00:52:19.380 --> 00:52:20.380
набор действий.

00:52:20.380 --> 00:52:24.220
Написать такого автономного агента, который сам забирает

00:52:24.220 --> 00:52:26.740
научные статьи по определенной теме, анализирует их по

00:52:26.740 --> 00:52:28.860
определенному критерию.

00:52:28.860 --> 00:52:31.380
Более того, а сейчас мы тоже немножко про это поговорим,

00:52:31.380 --> 00:52:33.780
очень важно понимать, что у языковых моделей есть

00:52:33.780 --> 00:52:34.780
ограничение контекста.

00:52:34.780 --> 00:52:38.940
То есть сначала нужно эти статьи обработать.

00:52:38.940 --> 00:52:41.820
Есть разные модели, есть модель embedding, сейчас тоже

00:52:41.820 --> 00:52:45.580
не будем в это уходить, но идея в том, чтобы поместить

00:52:45.580 --> 00:52:48.540
эти статьи сначала в некоторые векторные хранилища, а

00:52:48.540 --> 00:52:49.540
дальше из них создать embedding.

00:52:49.540 --> 00:52:55.700
Кстати, недавно как раз-таки израильский стартап, Pinecone

00:52:55.700 --> 00:52:59.180
по-моему, это cross-векторная база данных, вот ровно для

00:52:59.180 --> 00:53:02.420
таких задач, он получил огромный раунд финансирования

00:53:02.420 --> 00:53:05.580
и это действительно большая-большая сейчас индустрия, и там

00:53:05.580 --> 00:53:08.260
много хайпа, ну и оправданного хайпа.

00:53:08.260 --> 00:53:10.980
Поэтому, возвращаясь к вопросу, наша задача первым шагом

00:53:10.980 --> 00:53:13.020
собрать эти статьи, то есть написать агента, который

00:53:13.020 --> 00:53:16.580
собирает эти статьи, вторым шагом написать среду, в

00:53:16.580 --> 00:53:18.620
которой эти статьи анализируются, собираются в векторные

00:53:18.620 --> 00:53:21.740
хранилища и третьим шагом сделать ровно то, что мы

00:53:21.740 --> 00:53:24.820
сейчас сделали, то есть дать модели правильные инструкции,

00:53:24.820 --> 00:53:27.060
чтобы она помогла нам решить эту проблему.

00:53:27.060 --> 00:53:30.180
То есть это просто чуть сложнее, это можно сделать

00:53:30.180 --> 00:53:32.740
внутри чат GPT, это можно сделать внутри автономного

00:53:32.740 --> 00:53:34.660
агента, но это задача решаемая.

00:53:34.660 --> 00:53:37.300
Так, вопрос Дмитрия Вышелилетел.

00:53:37.300 --> 00:53:40.140
Для таких сложных промотов часто непонятно, как оставаться

00:53:40.140 --> 00:53:43.060
в рамках короткой памяти модели, типа она продолжает

00:53:43.060 --> 00:53:44.940
удерживать контекст или уже нет.

00:53:44.940 --> 00:53:45.940
Как это проверить?

00:53:45.940 --> 00:53:48.300
Да, хороший вопрос на самом деле.

00:53:48.300 --> 00:53:51.780
Ну, на самом деле, вот то, что мы сейчас делали, оно

00:53:51.780 --> 00:53:55.420
не такое уж и большое, то есть в принципе в окно модели

00:53:55.420 --> 00:53:59.140
GPT-4, что 8000 токенов, что примерно, сколько это, это

00:53:59.140 --> 00:54:02.940
несколько страниц текста, по-моему, типа 3 или 4 страниц,

00:54:02.940 --> 00:54:03.940
что-то такое.

00:54:03.940 --> 00:54:06.860
Это в принципе все работает, здесь контекст не теряется.

00:54:06.860 --> 00:54:09.420
Но действительно в более сложных вещах, действительно,

00:54:09.420 --> 00:54:11.100
этот контекст может потеряться.

00:54:11.100 --> 00:54:15.140
Поэтому если действительно вы работаете с какими-то

00:54:15.140 --> 00:54:17.420
уже прям очень-очень емкими промотами, и вы боитесь,

00:54:17.420 --> 00:54:19.580
что контекст потерялся, уже нужно использовать

00:54:19.580 --> 00:54:20.580
долговременную память.

00:54:20.580 --> 00:54:21.580
То есть контекст не теряется.

00:54:21.580 --> 00:54:24.180
Текст это кратковременная память, она действительно может стереться после,

00:54:24.180 --> 00:54:26.940
ну в случае GPT это 8000 токенов.

00:54:26.940 --> 00:54:30.380
Есть GPT 32000 токенов в доступе через API.

00:54:30.380 --> 00:54:34.780
32 это примерно уже, это такая хорошая статья научная,

00:54:34.780 --> 00:54:36.420
которую нужно держать в памяти.

00:54:36.420 --> 00:54:40.340
Сейчас у меня есть слайд, в котором я развиваю токены на статьи,

00:54:40.340 --> 00:54:42.860
там еще от языка очень сильно зависит, сейчас мы про это поговорим.

00:54:42.860 --> 00:54:46.700
Но в целом да, как проверить, можно задать вопрос по теме,

00:54:46.700 --> 00:54:50.580
в каждом случае по-разному, очень сильно зависит от темы.

00:54:50.580 --> 00:54:54.100
Подумайте какой-нибудь интересный вопрос, который бы,

00:54:54.100 --> 00:54:57.140
если бы вы задали обычной модели в другом окне, например,

00:54:57.140 --> 00:54:59.140
она бы ответила на него определенным способом,

00:54:59.140 --> 00:55:02.180
а ваш, например, если бы вы запромтили модель как определенного эксперта,

00:55:02.180 --> 00:55:04.500
этот эксперт ответил бы по-другому.

00:55:04.500 --> 00:55:08.140
Но в каждом конкретном случае такой вопрос нужно искать отдельно,

00:55:08.140 --> 00:55:09.980
потому что каких-то универсальных решений нет.

00:55:09.980 --> 00:55:15.540
Если спросить в какой-то сейчас роли, может получиться что-то странное,

00:55:15.540 --> 00:55:17.180
хотя тоже можно попробовать.

00:55:17.180 --> 00:55:20.780
По-моему, я с чем-то таким экспериментировал, там результаты были неоднозначны.

00:55:20.780 --> 00:55:25.300
Поэтому экспериментируйте, пробуйте, пробуйте спрашивать модель,

00:55:25.300 --> 00:55:29.700
помнишь этот контекст, ну, не прям явно, хотя можно попробовать и явно спросить.

00:55:29.700 --> 00:55:33.820
Либо придумайте какие-то вопросы, которые можно просто таким АБТ-стом проверить.

00:55:33.820 --> 00:55:38.540
Так, от Стаса вопрос, автономные агенты вроде как игрушка,

00:55:38.540 --> 00:55:40.700
очень круто, но реальные проблемы не решит.

00:55:40.700 --> 00:55:46.540
Ну, почему нет, на самом деле есть бы уже какое-то количество автономных агентов,

00:55:46.540 --> 00:55:49.820
которые прям делают крутые вещи, особенно вот в части исследований,

00:55:49.820 --> 00:55:50.980
я могу про исследование сказать.

00:55:50.980 --> 00:55:58.060
Автономные агенты, которые экономят время исследователя иногда и решают исследователь работать.

00:55:58.060 --> 00:56:00.620
У меня был такой кейс, к сожалению, не могу рассказывать подробности,

00:56:00.620 --> 00:56:02.740
но это уже происходит.

00:56:02.740 --> 00:56:06.460
Вот я уже не говорю про какие-то более автоматизируемые профессии.

00:56:06.460 --> 00:56:10.780
Так, друзья, я вижу, есть еще несколько вопросов, давайте мы пойдем немножко дальше,

00:56:10.780 --> 00:56:13.740
а то мы сейчас подвиснем, а потом мы к вопросам вернемся.

00:56:13.740 --> 00:56:15.100
Мы остановились на вопрос от Марины.

00:56:15.100 --> 00:56:21.740
Мы еще когда вернемся, давайте, чтобы у нас был ритм какой-то, продолжим,

00:56:21.740 --> 00:56:23.500
потому что у меня есть еще какое-то качество материала.

00:56:23.500 --> 00:56:27.300
Давайте мы теперь с вами поговорим про то, что называется мегапромт.

00:56:27.300 --> 00:56:30.500
Мегапромт – это как раз в тему памяти.

00:56:30.500 --> 00:56:35.220
То есть мегапромт – это очень большой промт, ну или какой-то емкий промт,

00:56:35.220 --> 00:56:45.220
который апеллирует как кратковременный промт.

00:56:45.220 --> 00:56:46.900
в первую очередь памяти модели.

00:56:46.900 --> 00:56:51.140
Он позволяет модель превратить в какую-то не просто отвечательный вопрос

00:56:51.140 --> 00:56:53.860
или решатель проблем, а в какую-то структуру,

00:56:53.860 --> 00:56:56.020
то есть по сути запрограммировать модель,

00:56:56.020 --> 00:56:58.340
чтобы она определенным образом вам отвечала.

00:56:58.340 --> 00:57:02.460
В этом смысле мегапромты, они как раз-таки отвечают за…

00:57:02.460 --> 00:57:05.500
то есть для их работы необходима кратковременная память.

00:57:05.500 --> 00:57:08.780
Мы немножко уже обсудили кратковременную память.

00:57:08.780 --> 00:57:12.380
Сейчас я вам покажу какое-то количество кейсов на эту тему.

00:57:12.380 --> 00:57:15.460
И вот как раз тот самый слайд про контекст.

00:57:15.460 --> 00:57:18.060
Вот он контекст кратковременной памяти.

00:57:18.060 --> 00:57:21.860
То есть GPT-4 помнит 8000 токенов,

00:57:21.860 --> 00:57:25.580
то есть это примерно 15 страниц, да я ошибся, не 3 страниц,

00:57:25.580 --> 00:57:28.980
а 15 страниц текстовых документов на английском.

00:57:28.980 --> 00:57:34.100
GPT-4 32000 токенов помнит примерно 60 страниц.

00:57:34.100 --> 00:57:36.100
То есть это такой хороший емкий аналитический отчет.

00:57:36.100 --> 00:57:38.740
Есть CLOT. CLOT – это модель от Antropic.

00:57:38.740 --> 00:57:43.020
CLOT может работать с контекстом в 100 000 токенов.

00:57:43.020 --> 00:57:45.980
К сожалению, у меня так и не получилось получить доступ к CLOT,

00:57:45.980 --> 00:57:48.220
потому что он почему-то в Израиле недоступен для подписки,

00:57:48.220 --> 00:57:49.540
а работает он только на подписках.

00:57:49.540 --> 00:57:53.180
Он работает через сервис POOL, и там подписки на него нет.

00:57:53.180 --> 00:57:56.500
Вот. Это про кратковременную память модели.

00:57:56.500 --> 00:57:59.740
Про долговременную память мы с вами не будем говорить сегодня.

00:57:59.740 --> 00:58:01.980
Это вообще отдельная тема, но хочу вам сказать,

00:58:01.980 --> 00:58:06.140
что есть эксперименты, которые помогают нам,

00:58:06.140 --> 00:58:10.300
в общем-то, общаться с целыми книгами.

00:58:10.300 --> 00:58:13.460
То есть, используя долговременную память,

00:58:13.460 --> 00:58:15.740
используя векторное хранилище, используя эмбеддинги,

00:58:15.740 --> 00:58:19.740
мы можем делать так, что мы можем задавать вопросы,

00:58:19.740 --> 00:58:21.740
например, какому-то большому корпусу текста.

00:58:21.740 --> 00:58:25.340
То есть это уже не сотни страниц, а это могут быть даже тысячи страниц.

00:58:25.340 --> 00:58:28.700
Это реализуемый вопрос. Сегодня мы на этом с вами не будем останавливаться.

00:58:28.700 --> 00:58:30.700
Это тема отдельная, но тоже хотел про это сказать.

00:58:30.700 --> 00:58:33.140
А сегодня мы с вами поговорим про Omegaprompt.

00:58:33.140 --> 00:58:37.340
Единственное, что сейчас, подождите, у меня почему-то сломался второй экран.

00:58:37.340 --> 00:58:40.140
Сейчас я его попробую перезагрузить.

00:58:40.140 --> 00:58:43.140
Работает.

00:58:43.140 --> 00:58:48.140
Сейчас, секунду.

00:58:48.140 --> 00:58:51.140
У меня просто на втором экране следующий слайд показывается.

00:58:51.140 --> 00:59:03.140
Ну и переставка, кстати.

00:59:03.140 --> 00:59:05.140
Sorry за эту техническую заминку.

00:59:15.140 --> 00:59:17.140
О, отлично, теперь все работает.

00:59:17.140 --> 00:59:21.140
Это мегапромт профессора Джереми Нгуена.

00:59:21.140 --> 00:59:24.140
И я был очень сильно впечатлен тем, как он работает.

00:59:24.140 --> 00:59:26.140
В чем была идея Джереми?

00:59:26.140 --> 00:59:29.140
Наш аккорд затверднул, мы улетели.

00:59:29.140 --> 00:59:31.140
В чем была идея Джереми?

00:59:31.140 --> 00:59:34.140
Идея была в том, что Джереми создал виртуальную панель

00:59:34.140 --> 00:59:36.140
из самых умных людей планеты.

00:59:36.140 --> 00:59:40.140
Видите, у него за здоровье отвечает доктор Эндрю Уэлл,

00:59:40.140 --> 00:59:43.140
за отношения с миром у него отвечает Далай Лама,

00:59:43.140 --> 00:59:46.140
за карьеру у него отвечает Навал Равликан,

00:59:46.140 --> 00:59:49.140
за предназначение в жизни отвечает Эстер Дуффа,

00:59:49.140 --> 00:59:52.140
а еще у них у всех есть модератор.

00:59:52.140 --> 00:59:55.140
То есть на самом деле это очень круто.

00:59:55.140 --> 00:59:56.140
Почему это сработало?

00:59:56.140 --> 00:59:58.140
Потому что это люди, у которых тут важно понимать,

00:59:58.140 --> 00:59:59.140
что когда вы собираете такую панель,

00:59:59.140 --> 01:00:01.140
когда вы хотите собрать такую панель для себя,

01:00:01.140 --> 01:00:04.140
думайте про то, у кого есть большое количество текстов.

01:00:04.140 --> 01:00:06.140
Если эксперт, у которого очень-очень много текстов,

01:00:06.140 --> 01:00:09.140
скорее всего модель очень легко обживется в роли этого эксперта.

01:00:09.140 --> 01:00:11.140
Помните, вначале мы говорили про роль?

01:00:11.140 --> 01:00:13.140
Вы можете даже сначала это попробовать.

01:00:13.140 --> 01:00:15.140
Вы можете прямо сказать, что не просто веди себя как эксперт в чем-то,

01:00:15.140 --> 01:00:17.140
или как консультант МакКинз,

01:00:17.140 --> 01:00:22.140
а вы можете сказать, ты Далай Лам, или ты Навал Равликан.

01:00:22.140 --> 01:00:24.140
И модель возьмет на себя эту роль и попробует вам отвечать

01:00:24.140 --> 01:00:26.140
из роли Навала Равликана.

01:00:26.140 --> 01:00:27.140
Это очень интересно, такие эксперименты,

01:00:27.140 --> 01:00:29.140
они всегда очень сильно вдохновляют,

01:00:29.140 --> 01:00:31.140
и естественно, там видны какие-то грехи и ошибки,

01:00:31.140 --> 01:00:33.140
но в целом это работает невероятно круто.

01:00:33.140 --> 01:00:35.140
Но Джереми пошел дальше.

01:00:35.140 --> 01:00:37.140
Он вообще собрал целую менторскую панель

01:00:37.140 --> 01:00:40.140
и прописал, видите, целый сложный алгоритм,

01:00:40.140 --> 01:00:44.140
чтобы через пять шагов модель помогла ему сформулировать

01:00:44.140 --> 01:00:48.140
собственные принципы и какие-то собственные core values.

01:00:48.140 --> 01:00:50.140
То есть я сейчас вам пролистну этот промпт, он очень долгий,

01:00:50.140 --> 01:00:53.140
потом я вам обязательно пришлю, вы почитайте.

01:00:53.140 --> 01:00:55.140
Я вам просто какие-то хайлайты здесь сделал,

01:00:55.140 --> 01:00:58.140
чтобы вы понимали, какая невероятная это работа.

01:00:58.140 --> 01:01:00.140
То есть он дал, видите, все примеры,

01:01:00.140 --> 01:01:03.140
что спикер ведет себя так, спикер выражает мнение,

01:01:03.140 --> 01:01:05.140
показал, как это должно выглядеть,

01:01:05.140 --> 01:01:08.140
показал, как должен себя вести каждый участник панели,

01:01:08.140 --> 01:01:10.140
показал даже, видите, тон, как он должен говорить,

01:01:10.140 --> 01:01:12.140
вместо того, чтобы говорить «Doctor, we're here»,

01:01:12.140 --> 01:01:14.140
потому что модель часто говорит «Hey, I'm here»,

01:01:14.140 --> 01:01:16.140
просто говори, ну, типа «Doctor, well», и он говорит.

01:01:16.140 --> 01:01:18.140
То есть даже такие нюансы.

01:01:18.140 --> 01:01:25.140
Это самый подробный алгоритм, как себя должен ведь спикер.

01:01:25.140 --> 01:01:28.620
модератор, чтобы модерировать этих гениальных панелей, этих гениальных людей.

01:01:28.620 --> 01:01:33.060
Это был мега промпромпт, это был взрыв мозга. Я изучал его, наверное, пару дней,

01:01:33.060 --> 01:01:37.220
и это, конечно, гениальное произведение. Опять-таки, сейчас не будем на нем останавливаться,

01:01:37.220 --> 01:01:41.820
но просто хочу вам показать крутость. А я в итоге его превратил в очень простой промпт.

01:01:41.820 --> 01:01:46.020
Сейчас тоже проясну, нет, несколько еще экранов из него. Он огромный, на самом деле.

01:01:46.020 --> 01:01:53.380
Он занимает треть контекста, наверное, этих Т4. Я превратил его для себя в очень простой промпт.

01:01:53.380 --> 01:01:57.420
Я сейчас много занимаюсь своим здоровьем, и мне интересно было создать такую панель

01:01:57.420 --> 01:02:02.700
из трех экспертов по здоровью. Это доктор Эндрю Хуберман, доктор Питер Атиа и доктор Майкл Грегор.

01:02:02.700 --> 01:02:06.220
Почему эти три? Еще раз, потому что у них очень много контента в интернете.

01:02:06.220 --> 01:02:11.100
И у Хубермана, и у Атии просто безумное качество. Поэтому модель хорошо знает,

01:02:11.100 --> 01:02:14.420
как они себя могут вести. Опять-таки, помните, что модель может галлюцинировать

01:02:14.420 --> 01:02:18.620
и говорить всякую ерунду, поэтому относимся к этому, что называется with a grain of salt,

01:02:18.620 --> 01:02:25.180
но работает, это потрясающе. И я ему говорю, вот сейчас я буду давать тебе свои выборы,

01:02:25.180 --> 01:02:30.020
то есть какую-то диету, которую я хочу соблюдать, и твоя задача, челлендж от меня, твоя задача

01:02:30.020 --> 01:02:34.620
говорить мне, какие у меня могут быть здесь риски и на что я должен еще обратить внимание.

01:02:34.620 --> 01:02:39.620
И вот я, например, говорю, я хочу перейти на кето-диету, и моя цель здесь похудеть

01:02:39.620 --> 01:02:45.300
и получить больше энергии и больше фокуса для работы. И, соответственно, доктор Питер Атиа

01:02:45.300 --> 01:02:48.780
мне говорит, на самом деле кето-диета, у нее есть сразу несколько проблем.

01:02:48.780 --> 01:02:55.060
Во-первых, это, возможно, что кето-диета состоит, в первую очередь, из жиров,

01:02:55.060 --> 01:02:59.740
и, соответственно, жиры бывают полезные и не полезные. Но я сейчас опять-таки утрирую,

01:02:59.740 --> 01:03:03.220
Атиа сказал об этом более красиво и экспертно, поскольку я в этом не эксперт,

01:03:03.220 --> 01:03:08.340
я больше таким обывательским языком, наверное, выражаюсь, но идея, я думаю, понятна,

01:03:08.340 --> 01:03:14.220
что по сути есть полезные, есть не очень полезные жиры. Также важно, что сама по себе

01:03:14.220 --> 01:03:17.580
кето-диета может приводить довольно неприятным последствиям в виде этого,

01:03:17.580 --> 01:03:25.700
что называется, keto-flu, то есть такой keto-грипп, который может привести и к каким-то судорогам,

01:03:25.700 --> 01:03:30.740
и наоборот, к тому, что фокусироваться будет сложно, поэтому очень важно не забывать

01:03:30.740 --> 01:03:39.300
еще про здоровый вход в себя протеин. Ну и, естественно, электролиты и hydration тоже масла.

01:03:39.300 --> 01:03:44.300
Это очень круто. Я провел здесь несколько экспериментов.

01:03:44.300 --> 01:03:48.300
с разными доменами, и каждый раз я потом верифицировал, естественно, советы.

01:03:48.300 --> 01:03:51.300
Там были галлюцинации, но галлюцинаций было, на самом деле, очень мало.

01:03:51.300 --> 01:03:54.300
И на самом деле вот такой фидбэк от экспертов, он очень ценен.

01:03:54.300 --> 01:03:57.300
То есть представляете, что вы можете придумать любую идею,

01:03:57.300 --> 01:04:00.300
может быть, идею стартапа, может быть, еще что-то,

01:04:00.300 --> 01:04:03.300
может быть, про то, как вы будете думать, про то, как вы будете действовать,

01:04:03.300 --> 01:04:06.300
и вам, и получить фидбэк от самых-самых умных людей планеты.

01:04:06.300 --> 01:04:09.300
Абсолютно бесплатно. Единственное, что эти умные люди

01:04:09.300 --> 01:04:11.300
должны быть хорошо представлены в интернете.

01:04:11.300 --> 01:04:16.300
Это про мегапромты. Еще раз, мегапромты – это огромная-огромная структура,

01:04:16.300 --> 01:04:19.300
которая превращает модель в некий алгоритм.

01:04:19.300 --> 01:04:23.300
Мегапромты имеют смысл только если вы работаете с чатом GPT.

01:04:23.300 --> 01:04:26.300
Естественно, в структуре лангчейн мегапромты не имеют смысла,

01:04:26.300 --> 01:04:29.300
потому что там гораздо проще работать с тем, что называется chain of thoughts,

01:04:29.300 --> 01:04:32.300
просто language chain, там это называется.

01:04:32.300 --> 01:04:34.300
Ну, лангчейн, language chain.

01:04:34.300 --> 01:04:37.300
То есть там вот этот диалог, он интегрируется, и в таких средах

01:04:37.300 --> 01:04:42.300
его делать, конечно, гораздо проще, но это если вы обладаете навыками программирования.

01:04:42.300 --> 01:04:44.300
Если вы не обладаете навыками программирования,

01:04:44.300 --> 01:04:46.300
вы занимаетесь таким промпт-программированием,

01:04:46.300 --> 01:04:48.300
то есть лучше этого сделать, вот прям естественный язык,

01:04:48.300 --> 01:04:51.300
то, конечно, в этом смысле чат GPT гораздо проще.

01:04:51.300 --> 01:04:53.300
Вот, это про мегапромты.

01:04:53.300 --> 01:04:56.300
Ну и давайте последнюю на сегодня тему попробуем раскрыть.

01:04:56.300 --> 01:05:01.300
Она мне очень нравится. Она в первую очередь не про advanced prompting,

01:05:01.300 --> 01:05:05.300
а про то, чтобы научить модель новым фреймворкам.

01:05:05.300 --> 01:05:07.300
И это было для меня тоже огромным откровением.

01:05:07.300 --> 01:05:11.300
Когда я начал это делать, я был в шоке, потому что как консультант,

01:05:11.300 --> 01:05:14.300
как исследователь, я использую большое количество фреймворков.

01:05:14.300 --> 01:05:17.300
Ну, фреймворк – это какая-то структура, которая позволяет определенным образом

01:05:17.300 --> 01:05:20.300
упорядочить какую-то информацию или какую-то систему,

01:05:20.300 --> 01:05:23.300
какую-то систему принятия решений, систему рассуждений.

01:05:23.300 --> 01:05:26.300
И вот я подумал, блин, а как бы было круто научить модель разным фреймворкам,

01:05:26.300 --> 01:05:28.300
чтобы она мне помогала.

01:05:28.300 --> 01:05:30.300
И действительно, есть опять-таки здесь та же самая история,

01:05:30.300 --> 01:05:34.300
что есть фреймворки, которые очень хорошо описаны в интернете,

01:05:34.300 --> 01:05:36.300
и с ними модель работает гораздо лучше.

01:05:36.300 --> 01:05:38.300
Есть фреймворки, которые хуже описаны,

01:05:38.300 --> 01:05:42.300
а есть фреймворки, которые описаны неплохо, но они обновляются часто.

01:05:42.300 --> 01:05:47.300
То есть часто внутри модели находится устаревшая версия того или иного фреймворка.

01:05:47.300 --> 01:05:50.300
То есть какие-то фреймворки, они, естественно, обновляются.

01:05:50.300 --> 01:05:52.300
И вот сегодня мы с вами поговорим про фреймворк,

01:05:52.300 --> 01:05:55.300
который называется CLA или casual layer analysis.

01:05:55.300 --> 01:06:00.300
Его создал один из моих коллег, которого зовут Сахаил Нятова.

01:06:00.300 --> 01:06:06.300
И Сахаил придумал...

01:06:06.300 --> 01:06:09.020
Я придумал такой фреймворк, он используется в Strategic Foresight,

01:06:09.020 --> 01:06:16.700
то есть в домен по предвоззрению будущего, по сценарию планирования и так далее.

01:06:16.700 --> 01:06:20.500
Я очень люблю этот фреймворк, потому что он на самом деле такой глубокий.

01:06:20.500 --> 01:06:23.300
В чем его смысл? Давайте очень просто.

01:06:23.300 --> 01:06:28.580
Задача фреймворка – анализировать разные причины, разные типы причин.

01:06:28.580 --> 01:06:33.180
И вот Сахаев утверждает, что у каждого явления довольно сложного

01:06:33.180 --> 01:06:36.740
у него есть 4 типа причин. Какие это 4 типа?

01:06:36.740 --> 01:06:40.420
Это литаний, то есть это то, что происходит на поверхности.

01:06:40.420 --> 01:06:45.780
Это то, как причины описываются в газете.

01:06:45.780 --> 01:06:49.860
Случилось что-то, потому что кто-то не договорился.

01:06:49.860 --> 01:06:52.100
Как правило, это очень примитивный уровень причинности.

01:06:52.100 --> 01:06:56.020
Следующий уровень причинности более глубокий – это уровень системы.

01:06:56.020 --> 01:07:01.020
Это системное мышление, это анализ разных факторов и так далее.

01:07:01.020 --> 01:07:03.620
Это как раз то, что я вам показал в кейсе с Аписити.

01:07:03.620 --> 01:07:06.620
Помните, там было много-много факторов, которые друг с другом взаимодействуют.

01:07:06.620 --> 01:07:09.100
Это про причины, про систему.

01:07:09.100 --> 01:07:12.100
Третий уровень, еще более глубокий – это мировоззрение.

01:07:12.100 --> 01:07:18.300
Сахаев утверждает, что большое количество проблем утверждены

01:07:18.300 --> 01:07:23.380
или работают на уровне мировоззрения,

01:07:23.380 --> 01:07:28.300
то есть какого-то общего культурного поста, который люди разделяют.

01:07:28.300 --> 01:07:31.300
И самый-самый глубокий уровень – это уровень метафоры мифов.

01:07:31.300 --> 01:07:33.060
И вот это мне было интереснее всего,

01:07:33.060 --> 01:07:36.060
потому что когда я веду такие воркшопы, я веду воркшопы с клиентами.

01:07:36.060 --> 01:07:37.540
Я даю им этот фреймворк и говорю,

01:07:37.540 --> 01:07:41.540
слушайте, давайте мы с вами разберем ваши проблемы по этим четырем уровням причинности.

01:07:41.540 --> 01:07:45.300
И на самом деле люди очень хорошо справляются с системным анализом, как правило, бизнес.

01:07:45.300 --> 01:07:48.020
В бизнесе вообще все классно, они умеют рисовать с теограммами,

01:07:48.020 --> 01:07:52.060
они умеют всех конструктуировать, делать факторный анализ и так далее,

01:07:52.060 --> 01:07:53.060
кросс-факторный анализ.

01:07:53.060 --> 01:07:56.540
Когда мы переходим на уровень worldview, тут уже становится чуть сложнее.

01:07:56.540 --> 01:07:59.540
Здесь нужно уходить в какие-то более человеческие

01:07:59.540 --> 01:08:02.540
и такие более системные культурные факторы, и тут сложнее.

01:08:02.540 --> 01:08:05.540
На уровне метафоры мифов чаще всего самые большие проблемы.

01:08:05.540 --> 01:08:08.540
Не всегда так, но чаще всего самые большие проблемы.

01:08:08.540 --> 01:08:10.540
Поэтому, что мне было интересно в этом кейсе,

01:08:10.540 --> 01:08:14.540
мне было интересно, насколько модель справится с этим последним уровнем, уровнем метафоры мифов.

01:08:14.540 --> 01:08:17.540
Что я сделал? Я взял последнюю версию этого фреймворка,

01:08:17.540 --> 01:08:22.540
описанного, она есть вот прямо в таком хендбуке,

01:08:22.540 --> 01:08:26.740
и вот примерно, добавляя аналогичные доски.

01:08:26.740 --> 01:08:30.740
Если у玩ушки наvinex, три несколько шестимерных драконов,

01:08:30.740 --> 01:08:34.740
он до сих пор работает, то девушка announces an überzeug,

01:08:34.740 --> 01:08:35.860
что обошлось.

01:08:35.860 --> 01:08:41.640
И много кредитgic в принципеted writtenientesь до послед selfish кwei.

01:08:41.640 --> 01:08:44.960
Девушка TensorFlow 12 яуся.

01:08:44.960 --> 01:08:46.720
Ну, блокчейн.

01:08:46.720 --> 01:08:48.880
Сописанию членов Arenate.

01:08:48.880 --> 01:08:53.240
сам Сахарю написал, потому что внутри модели был не последний.

01:08:53.240 --> 01:08:59.240
Я буквально через AskMyPDF попросил модель обучиться этому фреймворку,

01:08:59.240 --> 01:09:01.040
сделать summary и описать его по шагам.

01:09:01.040 --> 01:09:04.960
Вот такими очень простыми промптами, видите, здесь совсем уже не advanced prompt.

01:09:04.960 --> 01:09:08.360
Write a detailed step-by-step instruction on how CLA framework.

01:09:08.360 --> 01:09:11.440
Просто напиши мне детальную инструкцию по тому, как этот фреймворк работает.

01:09:11.440 --> 01:09:13.920
Он на самом деле довольно неплохо алгоритмизируется.

01:09:13.920 --> 01:09:15.800
А теперь привести ее в диаграмму.

01:09:15.800 --> 01:09:18.880
И здесь я использовал плагин, который называется ShowMe,

01:09:18.880 --> 01:09:20.960
и он мне нарисовал такой диаграмм.

01:09:20.960 --> 01:09:25.240
Ну, вы скажете, что диаграмма некрасивая, я с вами не соглашусь.

01:09:25.240 --> 01:09:29.480
Но на самом деле удивительно, что эту диаграмму можно прайти естественным языком.

01:09:29.480 --> 01:09:31.240
То есть можно сказать, сделаю ее слева-направо,

01:09:31.240 --> 01:09:36.080
а дальше в специальном инструменте, который называется Calibri,

01:09:36.080 --> 01:09:40.720
как птица, ладно, не важно.

01:09:40.720 --> 01:09:46.600
По сути, эта диаграмма представлена в виде такого кода, в виде кода разметки.

01:09:46.600 --> 01:09:49.840
Вы там можете менять цвет, размер стрелочек и так далее.

01:09:49.840 --> 01:09:50.920
Это на самом деле очень удобно.

01:09:50.920 --> 01:09:53.480
То есть, по сути, вместо того, чтобы рисовать сложную диаграмму,

01:09:53.480 --> 01:09:55.320
вы просите GPT, нарисуй мне такую диаграмму,

01:09:55.320 --> 01:09:58.040
а дальше вы просто немножко ее тюните в специальном интерфейсе.

01:09:58.040 --> 01:10:02.800
Там пока нет интерфейса такого, что вы можете просто двигать какие-то блоки

01:10:02.800 --> 01:10:05.280
или делать их больше-меньше, но я уверен, что до этого они быстро дойдут.

01:10:05.280 --> 01:10:06.720
Пока это можно все иметь в коде.

01:10:06.720 --> 01:10:07.720
Это очень удобно.

01:10:07.720 --> 01:10:11.560
И GPT-модель нарисовала мне вот такую диаграмму по тому, как этот фреймворк работает.

01:10:11.560 --> 01:10:13.800
А дальше я просил ее, ну давай проанализируем,

01:10:13.800 --> 01:10:16.200
давай возьмем какой-нибудь кейс, и тот самый кейс с obesity,

01:10:16.200 --> 01:10:19.000
и расскажи мне, как разложить его по фреймворку.

01:10:19.000 --> 01:10:22.120
И вот она показала ли это не оффобисит, что это такое.

01:10:22.120 --> 01:10:25.680
Это, собственно, большие избыточные рейты оффобисит,

01:10:25.680 --> 01:10:26.680
но это, по сути, статистика.

01:10:26.680 --> 01:10:30.800
Это статистика в Соединенных Штатах, какое количество людей обисит.

01:10:30.800 --> 01:10:32.720
Дальше социальные причины.

01:10:32.720 --> 01:10:35.720
В последней версии фреймворка это называли social causes,

01:10:35.720 --> 01:10:37.720
а в предыдущей версии это называлось system analysis.

01:10:37.720 --> 01:10:38.720
Сейчас не буду вас грузить этим.

01:10:38.720 --> 01:10:41.720
Если вам интересно, я обязательно вам с вами поделюсь.

01:10:41.720 --> 01:10:43.720
Да, и здесь она тоже неплохо справилась.

01:10:43.720 --> 01:10:46.720
Видите, она сказала, что дальше это можно, естественно, развивать,

01:10:46.720 --> 01:10:49.720
что у этого явления есть сложные причины.

01:10:49.720 --> 01:10:53.720
Это и плохая диета, это и отсутствие физической активности,

01:10:53.720 --> 01:10:55.720
это и социально-экономический статус.

01:10:55.720 --> 01:10:57.720
И вот помните вот этот вот диаграмму безумный?

01:10:57.720 --> 01:11:00.720
По сути, там все эти компоненты тоже перечислены.

01:11:00.720 --> 01:11:01.720
А дальше уже интереснее.

01:11:01.720 --> 01:11:03.720
Дальше мы переходим на уровень worldview.

01:11:03.720 --> 01:11:05.720
Давайте даже, наверное, сразу пропустим и спустимся на уровень.

01:11:05.720 --> 01:11:08.720
на уровне метафоры мифов, потому что именно для этого был этот эксперимент.

01:11:08.720 --> 01:11:13.720
И видите, с мифом она справилась не очень хорошо, потому что она почему-то взяла миф американской мечты.

01:11:13.720 --> 01:11:19.720
Вообще, такой миф – это некая расхожая история, которая находится в том, что называется культурный бессознатель.

01:11:19.720 --> 01:11:23.720
То есть на самом деле в нашем мире очень много мифов, и их становится больше.

01:11:23.720 --> 01:11:26.720
Ювел Харари об этом хорошо описал в своих книжке «Сапиенс».

01:11:26.720 --> 01:11:31.720
То есть это какой-то такой культурный нератив, который часто устанавливается нам в голову

01:11:31.720 --> 01:11:36.720
на уровне общей культуры и часто довольно рано.

01:11:36.720 --> 01:11:38.720
И от этих мифов очень сложно избавиться часто.

01:11:38.720 --> 01:11:43.720
И вот смотрите, здесь он почему-то добавил миф «американская мечта»,

01:11:43.720 --> 01:11:46.720
хотя это не очень на самом деле релевантный миф.

01:11:46.720 --> 01:11:49.720
На самом деле «американская мечта» – это наоборот скорее здесь позитивный миф,

01:11:49.720 --> 01:11:55.720
который наоборот скорее препятствует тому, что вот этот самый фактор обидности развивался.

01:11:55.720 --> 01:11:58.720
Но ничего страшного. Я говорю, хорошо, давай мне другие метафоры и мифы.

01:11:58.720 --> 01:12:01.720
И здесь он справился потрясающе круто. Видите, какие мифы он дал?

01:12:01.720 --> 01:12:10.720
«Fast Food Nation» – то есть по сути метафора того, что фастфуд-индустрия задает американскую культуру,

01:12:10.720 --> 01:12:12.720
фастфуд-индустрия задает то, как американцы питаются.

01:12:12.720 --> 01:12:14.720
Это на самом деле довольно глубоко.

01:12:14.720 --> 01:12:21.720
Или «Super-sized culture» – метафора отражает то, что большие пропорции лучше, чем маленькие пропорции.

01:12:21.720 --> 01:12:23.720
Это на самом деле очень глубоко в американской культуре.

01:12:23.720 --> 01:12:26.720
Если вы были в Америке, приходите в дайнер, вам там дают огромную-огромную порцию

01:12:26.720 --> 01:12:32.720
и часто неудобно, что если дают такую порцию, не отказаться.

01:12:32.720 --> 01:12:35.720
И это уже глубоко. Это не самый-самый глубокий анализ.

01:12:35.720 --> 01:12:38.720
Я знаю этот кейс, я его разбирал.

01:12:38.720 --> 01:12:41.720
Я знаю нескольких моих коллег, которые его разбирали, этот феномен.

01:12:41.720 --> 01:12:44.720
Там можно копнуть еще глубже, но это точно интересно.

01:12:44.720 --> 01:12:49.720
И вот уровень метафор и уровень таких уже действительно глубоких культурных,

01:12:49.720 --> 01:12:52.720
бессознательных вещей – удивительно, но модель с этим справилась.

01:12:52.720 --> 01:12:56.720
Да не с первого раза, но вау.

01:12:56.720 --> 01:12:59.720
Я могу сказать, что далеко не все люди способны на такой уровень рассуждений,

01:12:59.720 --> 01:13:03.720
просто потому что у меня был опыт, да, я действительно пробовал этот фреймворк

01:13:03.720 --> 01:13:05.720
с довольно большим количеством людей.

01:13:05.720 --> 01:13:09.720
Я могу сказать, что вот такой уровень рассуждений метафорами и мифами – это очень сложно.

01:13:09.720 --> 01:13:13.720
Это нужно иметь определенный бэкграунд, ну или по крайней мере какую-то склонность к этому.

01:13:13.720 --> 01:13:15.720
И далеко не всех людей она есть.

01:13:15.720 --> 01:13:19.720
Вот, поэтому это меня очень сильно как-то поразило, когда модель с этим справилась.

01:13:19.720 --> 01:13:20.720
Справилась довольно плохо.

01:13:20.720 --> 01:13:22.720
Но дальше я стал уже ее...

01:13:22.720 --> 01:13:26.600
уже развивать эту тему и дальше мы вообще заполнили этот фреймворк потрясающе круто.

01:13:26.600 --> 01:13:29.960
Ну, с каким-то импутом от меня, то есть через какое-то количество итераций.

01:13:29.960 --> 01:13:33.240
Но даже, видите, с двух итераций модель справилась очень-очень хорошо.

01:13:33.240 --> 01:13:39.560
Так, хорошо, давайте здесь поставим паузу, и я еще попробую поотвечать на ваши вопросы.

01:13:39.560 --> 01:13:41.720
Может быть, у вас еще больше появилось.

01:13:41.720 --> 01:13:44.720
Так, мы остановились на вопросы от Марины.

01:13:44.720 --> 01:13:50.360
У меня была проблема для решения, нужны были методики разных тренеров,

01:13:50.360 --> 01:13:55.120
книги, исследователи, статьи и тому подобное, источники по нетрадиционной медицине.

01:13:55.120 --> 01:13:57.440
То есть очень разнонародные источники.

01:13:57.440 --> 01:14:00.560
То есть этот шаг все равно пока самому. Нет, почему?

01:14:00.560 --> 01:14:03.680
Ты можешь собрать эти источники по какому-то критерию.

01:14:03.680 --> 01:14:08.600
То есть ты можешь попросить, допустим, ChargeBT, собрать тебе эти источники из интернета.

01:14:08.600 --> 01:14:15.640
Или из, ну здесь нетрадиционной медицины, наверное, из науки, я так предполагаю, вряд ли, но из интернета.

01:14:15.640 --> 01:14:19.000
Дальше у тебя будет body этих текстов, body of knowledge,

01:14:19.000 --> 01:14:22.800
и дальше уже ты эти тексты используешь в качестве контекста,

01:14:22.800 --> 01:14:26.120
ну или какие-то выкладки, как сказать, фрагменты из этих текстов.

01:14:26.120 --> 01:14:29.360
И уже у тебя появляется какое-то с ним взаимодействие.

01:14:29.360 --> 01:14:31.080
То есть это тоже уже можно автоматизировать.

01:14:31.080 --> 01:14:34.160
Сбор информации уже тоже можно автоматизировать.

01:14:34.160 --> 01:14:37.480
Это не так просто, но это можно сделать.

01:14:37.480 --> 01:14:42.280
Как я уже сказал, самый эффективный способ – это написать такого автономного агента,

01:14:42.280 --> 01:14:44.360
который будет ходить по интернету.

01:14:44.360 --> 01:14:47.440
Чуть менее эффективный способ – это всякие Bing, AI.

01:14:47.440 --> 01:14:51.200
Есть такой еще инструмент Preplexity, который тоже довольно неплохо ищет информацию.

01:14:51.200 --> 01:14:53.040
Ну и собственно плагинчат GPT-Bing.

01:14:53.040 --> 01:14:59.960
Так, Виктор Перминов, сколько шагов за раз можно провернуть в уме модели для получения output?

01:14:59.960 --> 01:15:04.240
Слушай, мне кажется, тут нет какого-то ограничения.

01:15:04.240 --> 01:15:07.160
То есть сколько ты хочешь, сколько ты скажешь, ты можешь говорить,

01:15:07.160 --> 01:15:08.840
дай мне еще один шаг, дай мне еще один шаг.

01:15:08.840 --> 01:15:10.600
Или ты можешь сказать, дай мне миллион шагов.

01:15:10.600 --> 01:15:12.840
Я не знаю, я не проводил такие эксперименты,

01:15:12.840 --> 01:15:15.000
но мне кажется, с точки зрения модели это вообще не важно.

01:15:15.000 --> 01:15:18.840
Модель может подстроиться, мне кажется, под любой промпт.

01:15:18.840 --> 01:15:23.080
Вопрос здесь уже всегда как такого ее арт-директора,

01:15:23.080 --> 01:15:27.360
как ее куратора, чтобы ты помог ей как-то правильно это сделать.

01:15:27.360 --> 01:15:31.560
Поэтому с точки зрения модели я не думаю, что у нее есть какие-то ограничения по количеству шагов.

01:15:31.560 --> 01:15:34.280
Можно количество шагов, естественно, задать.

01:15:34.280 --> 01:15:37.960
Опять-таки не всегда получится так, что модель сделает это количество шагов точности,

01:15:37.960 --> 01:15:45.400
но вариант будет такой.

01:15:45.400 --> 01:15:49.840
Так, Руби спрашивает, ого, круто, а где был анонс этой штуковины?

01:15:49.840 --> 01:15:51.600
А что ты имеешь в виду под анонсом штуковины?

01:15:51.600 --> 01:15:54.560
Напиши, пожалуйста.

01:15:54.560 --> 01:16:02.000
Так, может ли модель осознать свою собственную галлюцинацию?

01:16:02.000 --> 01:16:03.200
Да, может.

01:16:03.200 --> 01:16:07.760
И как раз для этого есть инструменты проверки, верификации аутопута.

01:16:07.760 --> 01:16:11.360
И они на самом деле очень похожи на вот эти системы Trio of Thoughts и так далее.

01:16:11.360 --> 01:16:14.000
То есть можно попросить модель верифицировать саму себя.

01:16:14.000 --> 01:16:18.600
Я могу показать научную работу, где-то, ну, уже, наверное, поделюсь этим в материалах, но это делается.

01:16:18.600 --> 01:16:23.800
Да, да, да. То есть на самом деле верификация аутопута модели сейчас уже гораздо лучше решена.

01:16:23.800 --> 01:16:30.040
Ну, опять-таки, когда у GPT появился доступ в интернет через плагин, это решилось довольно неплохо.

01:16:30.040 --> 01:16:38.400
Но и до этого, естественно, когда мы использовали API, мы могли верифицировать, да, используя просто, ну, то есть напрямую запрашивая какие-то источники.

01:16:38.400 --> 01:16:43.520
Но сейчас есть система промтов, которые позволяют тебе верифицировать модель.

01:16:43.520 --> 01:16:47.680
То есть как бы вот разные тренды модели друг друга верифицировать. Это тоже очень круто работает.

01:16:47.680 --> 01:16:52.080
Так, еще один вопрос. О трубе. Стоит ли делать эти личности тулами?

01:16:52.080 --> 01:16:56.160
Ну, как бы вопрос, как часто ты с ними обращаешься.

01:16:56.160 --> 01:16:59.520
Можно прямо сделать отдельного бота, который будет такой личностью.

01:16:59.520 --> 01:17:01.240
Можно делать целую панель личностью.

01:17:01.240 --> 01:17:04.240
Да, то есть здесь все очень индивидуально и все зависит от задачи.

01:17:04.240 --> 01:17:08.040
Так, Марина. Конкретно про Ати и Хьюпермана.

01:17:08.040 --> 01:17:11.160
Ати – книга и подкаст у Хьюпермана подкаст.

01:17:11.160 --> 01:17:13.360
Текст модели – это транскрибирование подкаста.

01:17:13.360 --> 01:17:15.200
Да, да, да, так и есть.

01:17:15.200 --> 01:17:17.400
То есть на самом деле модели обучены не только на текстах,

01:17:17.400 --> 01:17:20.360
но и в том числе на большом количестве YouTube роликов и подкаст.

01:17:20.360 --> 01:17:24.200
Да, все это транскрибировано, естественно, и использовалось в качестве обучающей выборки.

01:17:24.200 --> 01:17:26.920
Можно сделать фактчекинг.

01:17:26.920 --> 01:17:28.920
Да, фактчекинг можно делать.

01:17:28.920 --> 01:17:31.920
Опять-таки фактчекинг можно автоматизировать, а можно сделать вручную.

01:17:31.920 --> 01:17:36.120
Так, по моему опыту подкасты недоступны в GPT, Амир пишет.

01:17:36.120 --> 01:17:40.600
Ну, интересно. И насколько я знаю, как раз подкасты использовались в обучении.

01:17:40.600 --> 01:17:43.080
Но мы можем этот вопрос подвесить и еще раз проверить.

01:17:43.080 --> 01:17:45.520
Так, продолжаем.

01:17:45.520 --> 01:17:52.080
Алексей спрашивает, какое минимальное количество примеров стоит предоставлять для Fushion Prompting?

01:17:52.080 --> 01:17:53.400
Нет такого ограничения.

01:17:53.400 --> 01:17:55.680
Ну, то есть Fushion – это 2 и более.

01:17:55.680 --> 01:18:00.240
Дальше просто надо смотреть, если модель поняла паттерн, который вы хотите от нее получить,

01:18:00.240 --> 01:18:01.720
то значит сработало.

01:18:01.720 --> 01:18:13.720
Но для Fushion поможет еще одна модель, которая стоит в среднем 2-3 миллиона долларов.

01:18:13.720 --> 01:18:15.720
Она не стоит в среднем в 5-6 миллионах.

01:18:15.720 --> 01:18:17.720
Она стоит в 6-7 миллионах.

01:18:17.720 --> 01:18:19.720
Она стоит в 7-8 миллионах.

01:18:19.720 --> 01:18:21.720
Она стоит в 7-8 миллионах.

01:18:21.720 --> 01:18:23.720
Она стоит в 7-8 миллионах.

01:18:23.720 --> 01:18:25.720
Она стоит в 7-8 миллионах.

01:18:25.720 --> 01:18:27.720
Она стоит в 7-8 миллионах.

01:18:27.720 --> 01:18:29.720
Она стоит в 7-8 миллионах.

01:18:29.720 --> 01:18:31.320
не поняла, значит надо больше.

01:18:31.320 --> 01:18:33.960
Few-shot это 2+, есть еще one-shot-promising,

01:18:33.960 --> 01:18:37.560
это часто модель может понять вообще с одного,

01:18:37.560 --> 01:18:40.120
просто один пример и модель понимает,

01:18:40.120 --> 01:18:41.120
чего от нее хотеть.

01:18:41.120 --> 01:18:45.520
Так, и есть ли какое-то видимо число примеров,

01:18:45.520 --> 01:18:47.200
после которых дальнейшие примеры не увеличивают

01:18:47.200 --> 01:18:48.200
точность ответа?

01:18:48.200 --> 01:18:50.880
Все зависит от кейса, универсальных ответов здесь нет.

01:18:50.880 --> 01:18:54.880
Все всегда зависит от кейса, насколько сложный кейс,

01:18:54.880 --> 01:18:56.920
из какого он домена, может быть это математический

01:18:56.920 --> 01:18:59.240
кейс, может быть кейс просто переформатирования чего-то.

01:18:59.240 --> 01:19:01.200
То есть универсальных ответов здесь нет,

01:19:01.200 --> 01:19:03.200
просто пробуйте, смотрите.

01:19:03.200 --> 01:19:05.720
Опять-таки модель требует вас, как человека, который

01:19:05.720 --> 01:19:07.960
смотрит на опыт и говорит, ты правильно делаешь,

01:19:07.960 --> 01:19:08.960
а ты неправильно.

01:19:08.960 --> 01:19:09.960
Так, второй вопрос.

01:19:09.960 --> 01:19:13.240
Я заметил, что иногда слишком большое количество инструкций

01:19:13.240 --> 01:19:15.560
в промте не улучшает результат, а ухудшает.

01:19:15.560 --> 01:19:17.840
Есть ли какие-то гайдлайны на выбор количества инструкций?

01:19:17.840 --> 01:19:21.520
Да, бывает такое, потому что если вы слишком сузите,

01:19:21.520 --> 01:19:24.760
здесь же идея в том, что чем больше инструкций,

01:19:24.760 --> 01:19:28.360
тем более узкое поведение вы вызываете.

01:19:28.360 --> 01:19:33.600
И по этой ветке поведения может быть просто мало информации,

01:19:33.600 --> 01:19:35.080
и модель начинает либо додумывать, либо вообще

01:19:35.080 --> 01:19:37.680
что-то… ну, типа, давай не так много информации.

01:19:37.680 --> 01:19:40.680
Есть ли какие-то гайдлайны?

01:19:40.680 --> 01:19:45.360
Сейчас я попробую вспомнить, попадалось ли мне что-то

01:19:45.360 --> 01:19:46.360
такое.

01:19:46.360 --> 01:19:48.360
Я попробую поискать.

01:19:48.360 --> 01:19:51.960
Вообще, опять-таки, это все про взаимное обучение.

01:19:51.960 --> 01:19:53.720
То есть часто, когда ты много работаешь с моделями,

01:19:53.720 --> 01:19:57.440
ты часто понимаешь, что стоит давать, а что не стоит.

01:19:57.440 --> 01:19:59.000
Или просто понимаешь, если не понимаешь, то просто

01:19:59.000 --> 01:20:00.000
экспериментируешь.

01:20:00.000 --> 01:20:03.640
Но, по-моему, какой-то гайдлайн на эту тему у меня был.

01:20:03.640 --> 01:20:06.520
Давай я попробую себе записать.

01:20:06.520 --> 01:20:09.560
Или лучше, если ты мне когда-нибудь напишешь.

01:20:09.560 --> 01:20:12.040
Ну, давай, ладно, я запишу себе, чтобы не забыть.

01:20:12.040 --> 01:20:23.080
Так, а, я имел в виду этот ивент, спасибо, что не скинул.

01:20:23.080 --> 01:20:25.080
Окей, окей.

01:20:25.080 --> 01:20:27.680
А какой вопрос был по ивенту?

01:20:27.680 --> 01:20:28.680
Давай вернемся.

01:20:28.680 --> 01:20:31.680
А, был ли анонс ивента, да-да-да.

01:20:31.680 --> 01:20:35.400
Анонс ивента был в сообществе 12 чеков.

01:20:35.400 --> 01:20:38.400
Вот, подписывайся, все там будет.

01:20:38.400 --> 01:20:39.400
Так, продолжаем.

01:20:39.400 --> 01:20:43.280
С моделью можно работать на разных языках.

01:20:43.280 --> 01:20:45.400
Как зависит от языка результат.

01:20:45.400 --> 01:20:46.400
Если использовать, например, русский язык, то это будет

01:20:46.400 --> 01:20:47.400
очень сложно.

01:20:47.400 --> 01:20:50.680
русский язык для работы с моделью, будет ли она использовать источники на других языках?

01:20:51.280 --> 01:20:56.040
Сложный вопрос. Я попробую на него ответить, исходя из того, как я это понимаю.

01:20:57.360 --> 01:20:59.960
Значит, есть дефолтовый язык английский.

01:21:00.160 --> 01:21:04.040
Английский — это, как это сказать, это такой язык-камертон.

01:21:04.240 --> 01:21:06.560
То есть на этом языке модель работает лучше всего.

01:21:06.760 --> 01:21:10.200
Это очевидно, потому что больше всего текстов на английском в целом в интернете.

01:21:10.840 --> 01:21:14.560
Есть первый тир языков, на которых текстов очень много.

01:21:14.560 --> 01:21:18.400
И да, модель обучена на текстах разных языков, в том числе на русском.

01:21:18.600 --> 01:21:19.800
Да, она использует это.

01:21:20.000 --> 01:21:22.520
То есть, условно, если вы задаете какой-то промпт на русском,

01:21:22.720 --> 01:21:25.080
это не значит, что модель переведет его на английский,

01:21:25.280 --> 01:21:27.760
потом, значит, прогонит, ну, в смысле даст там ответ,

01:21:27.960 --> 01:21:29.360
и потом обратно переведет его на русский.

01:21:29.560 --> 01:21:31.600
Но это и не значит, что так не будет.

01:21:31.800 --> 01:21:33.880
Вот это самое удивительное.

01:21:34.080 --> 01:21:37.200
Эта область, она довольно unclear.

01:21:37.400 --> 01:21:39.840
То есть, как работает перевод с разных языков?

01:21:39.840 --> 01:21:45.280
Бывает так, что модель полностью использует те параметры,

01:21:45.480 --> 01:21:48.200
которые у нее находятся, ну, условно, в зоне обучения этому языку.

01:21:48.400 --> 01:21:50.400
Бывает так, что модель делает какой-то перевод.

01:21:50.600 --> 01:21:53.520
Какого-то четкого, естественно, вот…

01:21:53.720 --> 01:21:56.480
Я уверен, кстати, что у обе на это тоже не всегда знают, как это работает.

01:21:56.680 --> 01:21:58.240
Просто потому что модель – это черный ящик.

01:21:58.440 --> 01:22:02.120
Внутри просто это такая огромная, ну, условно, если себе представить,

01:22:02.320 --> 01:22:05.720
это не очень корректная аналогия, но это огромная формула, гигантская,

01:22:05.920 --> 01:22:08.760
которая каждый раз считается, исходя из определенного input.

01:22:08.760 --> 01:22:12.680
Вот, и, соответственно, не все, ну, в смысле, люди не знают,

01:22:12.880 --> 01:22:14.080
как она на самом деле работает.

01:22:14.280 --> 01:22:15.880
Мы все больше и больше узнаем об этом,

01:22:16.080 --> 01:22:21.080
как это технологии работают, GPT, Generative Pre-trained Transformer.

01:22:21.280 --> 01:22:23.680
И мы больше узнаем, как в целом работает машинное обучение.

01:22:23.880 --> 01:22:25.880
Но в целом модели – это черный ящик.

01:22:26.080 --> 01:22:29.040
Поэтому, если отвечать на этот вопрос кратко,

01:22:29.240 --> 01:22:30.800
то лучше всего работает английский язык.

01:22:31.000 --> 01:22:32.200
Другие языки тоже работают.

01:22:32.400 --> 01:22:36.120
Всегда есть вероятность, что другой язык сработает хуже.

01:22:36.120 --> 01:22:41.120
Когда он сработает хуже, насколько хуже, никто не знает.

01:22:41.320 --> 01:22:44.520
Но если вы хотите идеальный output, используйте английский.

01:22:44.720 --> 01:22:47.120
Это точно можно сказать.

01:22:47.320 --> 01:22:49.520
Потом просто переведете на любой другой язык.

01:22:49.720 --> 01:22:54.440
Так, Руби, я не совсем объяснил по поводу тулов, это сложно текстом.

01:22:54.640 --> 01:22:57.120
Окей, потом с тобой спишемся, обсудим.

01:22:57.320 --> 01:23:00.840
Так, Мадес спрашивает, Андрей, где можно почитать теорию промтов

01:23:01.040 --> 01:23:02.440
и о логике работы с ними?

01:23:02.640 --> 01:23:04.040
Для начала в общих чертах ознакомительно.

01:23:04.040 --> 01:23:07.200
Есть офигенный курс на Курсере, я вам скину на него ссылку.

01:23:07.200 --> 01:23:09.120
Он потрясающий, он бесплатный.

01:23:09.120 --> 01:23:12.000
Я вообще удивлен, как мало людей про него знают.

01:23:12.000 --> 01:23:14.200
Я на самом деле до всего доходил сам, ну как сам,

01:23:14.200 --> 01:23:17.400
естественно, я читал большое количество документаций,

01:23:17.400 --> 01:23:18.400
всяких статей.

01:23:18.400 --> 01:23:20.240
Но когда я посмотрел этот курс, я такой подумал, блин,

01:23:20.240 --> 01:23:21.240
а чего я так мучился?

01:23:21.240 --> 01:23:23.920
На самом деле там очень хорошо все объяснено.

01:23:23.920 --> 01:23:27.280
Вот поэтому, если ты прям хочешь какие-то…

01:23:27.280 --> 01:23:29.440
Ну там на самом деле есть более продвинутые вещи.

01:23:29.440 --> 01:23:32.840
В общем, курс очень хороший, мы, естественно, вам его скинем.

01:23:32.840 --> 01:23:37.280
Так, в моем опыте изменение порядка слов влияло на результат.

01:23:37.280 --> 01:23:40.880
Другими словами, если перенести предложение из конца промта

01:23:40.880 --> 01:23:43.880
в начало, при этом не меняя контекст, то результат может

01:23:43.880 --> 01:23:46.880
кардинально измениться даже при температуре 0.

01:23:46.880 --> 01:23:48.880
Как с этим бороться?

01:23:48.880 --> 01:23:49.880
Никак с этим нельзя бороться.

01:23:49.880 --> 01:23:53.880
То есть в смысле это просто специфика языковой модели.

01:23:53.880 --> 01:23:55.920
Языковая модель, у нее есть элемент случайности.

01:23:55.920 --> 01:23:58.080
То есть бывает так, что даже ты можешь попробовать

01:23:58.080 --> 01:24:00.200
следующее сделать, ты можешь просто взять один и тот

01:24:00.200 --> 01:24:02.960
же промт, если он довольно сложный, то даже в двух-трех

01:24:02.960 --> 01:24:04.960
случаях ты получишь разный ответ.

01:24:04.960 --> 01:24:07.480
Я уж не говорю, если это попробовать, например,

01:24:07.480 --> 01:24:09.400
не с языковой модели, а с какой-нибудь графической

01:24:09.400 --> 01:24:11.160
моделью типа Major.

01:24:11.160 --> 01:24:13.760
Ты можешь просто вставлять один и тот же промт и получать

01:24:13.760 --> 01:24:15.760
ну радикально разные результаты.

01:24:15.760 --> 01:24:17.760
Просто потому что это статистическая модель.

01:24:17.760 --> 01:24:20.760
То есть она никогда тебя не посчитает своим способом.

01:24:20.760 --> 01:24:23.760
В ней есть всегда элемент случайности.

01:24:23.760 --> 01:24:25.760
Поэтому это первый ответ.

01:24:25.760 --> 01:24:29.760
Второй, действительно, порядок слов влияет на качество.

01:24:29.760 --> 01:24:32.760
И есть какие-то очень странные слова маркеры типа let's.

01:24:32.760 --> 01:24:35.760
Вот есть прям целое исследование, которое говорит let's ведет

01:24:35.760 --> 01:24:37.760
к лучшему албу.

01:24:37.760 --> 01:24:39.760
Почему, мы не знаем.

01:24:39.760 --> 01:24:42.760
Наверное, есть какие-то гипотезы, но мы не знаем.

01:24:42.760 --> 01:24:45.760
Поэтому действительно, поэтому часто очень хорошо

01:24:45.760 --> 01:24:48.760
использовать несколько шотов.

01:24:48.760 --> 01:24:50.760
То есть можно попробовать сделать один промт, можно

01:24:50.760 --> 01:24:52.760
чуть-чуть его поменять, сравнить результаты.

01:24:52.760 --> 01:24:55.760
То есть я как и говорил в начале, это всегда итеративная работа.

01:24:55.760 --> 01:24:57.760
То есть никогда это не вот что-то, что мы сделали

01:24:57.760 --> 01:24:59.760
и это не все.

01:24:59.760 --> 01:25:01.760
Так, Марина.

01:25:01.760 --> 01:25:03.760
Да, в общем, отвечаю на вопрос коротко.

01:25:03.760 --> 01:25:05.760
Никак с этим не бороться.

01:25:05.760 --> 01:25:07.760
Просто это надо принять и адаптироваться к этому.

01:25:07.760 --> 01:25:11.760
Так, что-то толковое выходило по поводу внутренней логики

01:25:11.760 --> 01:25:13.760
работы моделей или по-прежнему сами?

01:25:13.760 --> 01:25:14.760
Нет, почему?

01:25:14.760 --> 01:25:16.760
Есть интересные статьи.

01:25:16.760 --> 01:25:18.760
Есть интересные статьи, например, на тему того,

01:25:18.760 --> 01:25:28.760
что исследователи рассматривали...

01:25:28.760 --> 01:25:30.960
сковыряли прямо векторную базу внутри модели.

01:25:30.960 --> 01:25:34.280
Это было, по-моему, старая модель GPT-2, если я ничего не путаю.

01:25:34.280 --> 01:25:38.840
И они научились, то есть они сделали так, что модель отвечала им на вопрос,

01:25:38.840 --> 01:25:41.680
где находится Эфилеева башня, и модель отвечала в Лондоне.

01:25:41.680 --> 01:25:43.960
То есть они буквально подкрутили ей мозги.

01:25:43.960 --> 01:25:46.640
Это очень крутая работа, я прям тогда прочитал.

01:25:46.640 --> 01:25:49.640
Это, если вы вспомните фильм «Космическое Одиссея»,

01:25:49.640 --> 01:25:52.560
когда главный герой вытаскивал у Хала мозги,

01:25:52.560 --> 01:25:57.840
и Хал начинал говорить всякую ерунду, вот мне сразу эта работа напомнила.

01:25:57.840 --> 01:26:02.600
Действительно, поскольку с точки зрения Академии сейчас это очень продуктивная среда,

01:26:02.600 --> 01:26:05.080
то есть там много хайпа, там много интереса, туда дают гранты,

01:26:05.080 --> 01:26:07.320
очень много интересных работ на эту тему выходит.

01:26:07.320 --> 01:26:10.680
Это одна из них, я могу поделиться еще несколькими.

01:26:10.680 --> 01:26:15.280
Но опять-таки я не скажу, что я прям за всей Академией стяжу,

01:26:15.280 --> 01:26:17.480
но то, что у меня есть, опять-таки с радостью поделюсь.

01:26:17.480 --> 01:26:21.840
Давайте тоже себе за скриншоте этот вопрос и поделюсь с вами.

01:26:21.840 --> 01:26:28.120
Так, почему Сэм Альтман просит государство об этической регуляции LLM?

01:26:28.120 --> 01:26:31.280
Это вопрос более сложный, да, это уже более…

01:26:31.280 --> 01:26:33.200
Ну, давайте я попробую на него ответить, как я его понимаю.

01:26:33.200 --> 01:26:36.800
Есть такой феномен, который называется молох,

01:26:36.800 --> 01:26:40.360
то есть люди делают что-то, то есть теория игры выстроена так,

01:26:40.360 --> 01:26:44.680
что каждая компания делает что-то и боится,

01:26:44.680 --> 01:26:48.920
что если она это перестанет делать, то конкуренты сделают это быстрее.

01:26:48.920 --> 01:26:53.680
Поэтому с точки зрения Сэма Альтмана он не может просто прекратить исследование

01:26:53.680 --> 01:26:57.080
в определенной области, потому что это будет бессмысленно.

01:26:57.080 --> 01:26:59.840
Он просто потеряет рынок, а это сделает его конкуренты.

01:26:59.840 --> 01:27:03.600
Точно так же не может и другая компания.

01:27:03.600 --> 01:27:05.480
То есть у DeepMind то же самое проблема,

01:27:05.480 --> 01:27:07.880
у какого-нибудь там Antropic та же самая проблема.

01:27:07.880 --> 01:27:11.000
И в целом у Америки та же самая проблема,

01:27:11.000 --> 01:27:13.640
потому что они говорят, окей, сейчас мы перестанем, а китайцы все сделают.

01:27:13.640 --> 01:27:15.560
И в этом смысле это называется молох.

01:27:15.560 --> 01:27:18.040
Все идут к какой-то катастрофе, но никто не может остановиться.

01:27:18.040 --> 01:27:21.320
Поэтому если государство скажет, слушайте, мы запрещаем это делать,

01:27:21.320 --> 01:27:24.080
если и китайское государство скажет, что мы запрещаем это делать,

01:27:24.080 --> 01:27:26.960
есть идея того, что они как-то притормозятся.

01:27:26.960 --> 01:27:30.080
Но вот согласно тому же Techmark нужно всего лишь полгода,

01:27:30.080 --> 01:27:35.040
полгода на то, чтобы то, что называется AI safety research, догнали текущие технологии.

01:27:35.040 --> 01:27:38.080
И мы как раз с вами лучше бы понимали, как эта штука внутри работает,

01:27:38.080 --> 01:27:40.880
и как, если что, ее можно остановить.

01:27:40.880 --> 01:27:44.960
Конечно, там не все так просто, но как сделать так,

01:27:44.960 --> 01:27:49.280
как температуринно реагировать, то есть как придерживать большей船,

01:27:49.280 --> 01:27:53.640
enza мальчишек, заставлять их термонograph а тол sendo gone,

01:27:53.640 --> 01:28:00.240
или есть 1963 был очень важный момент от самый  ChangeThis.

01:28:00.240 --> 01:28:04.480
И я думаю, что это, наверное, то, что он изменил сейчас battery life

01:28:04.480 --> 01:28:07.680
того, что китайцы, особенно вопросом Sakuras,

01:28:07.680 --> 01:28:11.640
что разрешения получaient позудиться должны они самостоятельно

01:28:11.640 --> 01:28:15.640
чтобы она не нанесла человечеству большой вред.

01:28:15.640 --> 01:28:17.640
Согласно большому количеству исследователей, в том числе

01:28:17.640 --> 01:28:20.640
дико-дико гениальных типа Тегмарка, ну и всем, кто

01:28:20.640 --> 01:28:24.640
писал это письмо, сейчас недавно вышел целый консорциум

01:28:24.640 --> 01:28:28.640
AIethics, есть гипотеза, что это всего лишь полгода,

01:28:28.640 --> 01:28:30.640
то есть всего лишь на полгода надо затормозиться.

01:28:30.640 --> 01:28:33.640
Но ни одна компания не затормозит сама, потому что они будут

01:28:33.640 --> 01:28:35.640
думать, что их конкуренты сделают это быстрее.

01:28:35.640 --> 01:28:39.640
Поэтому здесь нужно регулирование государства.

01:28:39.640 --> 01:28:42.640
Блин, классно, что столько вопросов, ребят, спасибо.

01:28:42.640 --> 01:28:44.640
Все вопросы офигенные.

01:28:44.640 --> 01:28:46.640
Так, Евгений пишет.

01:28:46.640 --> 01:28:48.640
Можешь, пожалуйста, рассказать про плагины для GPT, которые

01:28:48.640 --> 01:28:50.640
используются для анализа данных, структурированных

01:28:50.640 --> 01:28:51.640
или не совсем?

01:28:51.640 --> 01:28:53.640
Например, можно ли подключить к модели баз данных или

01:28:53.640 --> 01:28:58.640
файлов и задавать к ним вопросы на естественном языке?

01:28:58.640 --> 01:29:03.640
Так, да, анализ данных, структурированных или не совсем.

01:29:03.640 --> 01:29:05.640
Ну давай начнем со структурированных.

01:29:05.640 --> 01:29:08.640
Для структурированных пока все равно лучше работает

01:29:08.640 --> 01:29:09.640
просто питон.

01:29:09.640 --> 01:29:12.640
Ну то есть условно ты просто даешь модели какие-то данные,

01:29:12.640 --> 01:29:15.640
просишь ее, поняла ли она эти данные, а дальше просишь

01:29:15.640 --> 01:29:18.640
ее написать код на питоне, чтобы эти данные проанализировать.

01:29:18.640 --> 01:29:21.640
Ну условно найти там какие-то корреляции, построить регрессию.

01:29:21.640 --> 01:29:23.640
Да, есть, я уже не знаю, какой тип анализ.

01:29:23.640 --> 01:29:26.640
Плагины на эту тему появляются, но насколько я знаю, они

01:29:26.640 --> 01:29:28.640
пока довольно плохо работают.

01:29:28.640 --> 01:29:30.640
Наверняка они со временем появятся лучше.

01:29:30.640 --> 01:29:31.640
Но тут есть другая проблема.

01:29:31.640 --> 01:29:33.640
Если ты серьезно занимаешься датой аналитики, но ты

01:29:33.640 --> 01:29:36.640
не загрузишь в модель большое количество данных,

01:29:36.640 --> 01:29:38.640
то опять-таки ты будешь ограничен контекстом.

01:29:38.640 --> 01:29:40.640
Поэтому в этом смысле для структурированных данных

01:29:40.640 --> 01:29:42.640
лучше всего работает конечно вот такой подход,

01:29:42.640 --> 01:29:45.640
что просто дать образец данных, убедиться, что модель

01:29:45.640 --> 01:29:48.640
их поняла и попросить написать код на питоне.

01:29:48.640 --> 01:29:52.640
Работает отлично, я проверял, код работает, все анализируется,

01:29:52.640 --> 01:29:53.640
все шикарно.

01:29:53.640 --> 01:29:57.640
Для не структурированных данных уже интереснее.

01:29:57.640 --> 01:29:59.640
То есть если это, например, особенно качественные данные,

01:29:59.640 --> 01:30:00.640
например, экспертное интервью.

01:30:00.640 --> 01:30:03.640
Вот у меня был кейс, когда у меня было там 10 экспертных

01:30:03.640 --> 01:30:05.640
интервью, и мне нужно было их проанализировать.

01:30:05.640 --> 01:30:07.640
Это работает потрясающе круто.

01:30:07.640 --> 01:30:10.640
То есть для этого просто ты берешь, запихиваешь их

01:30:10.640 --> 01:30:12.640
все в PDF.

01:30:12.640 --> 01:30:14.640
Ну, это самый простой способ.

01:30:14.640 --> 01:30:16.640
Я делал через Embeddings, там более сложно было.

01:30:16.640 --> 01:30:18.640
Но условно ты запихиваешь их в PDF, загружаешь на этот

01:30:18.640 --> 01:30:23.640
сервис, askmypdf, и, соответственно, ты разговариваешь с этим

01:30:23.640 --> 01:30:25.640
интервью, как буквально на естественном языке,

01:30:25.640 --> 01:30:27.640
вот тот самый лингвистический интерфейс.

01:30:27.640 --> 01:30:37.640
Поэтому сейчас...

01:30:37.640 --> 01:30:44.640
Сейчас уже решение есть, буквально через несколько недель или месяц появится еще более customer-friendly решение,

01:30:44.640 --> 01:30:53.640
которое позволит большие и большие тексты загружать в модель без лангчейна и каких-то танцев с бетон.

01:30:53.640 --> 01:31:00.640
Поэтому с инструктированными данными можно работать внутри ChatGPT и других решений типа AskPDF.

01:31:00.640 --> 01:31:05.640
Есть AskMyPDF, это плагин, а есть AskPDF, который прям отдельный сервис.

01:31:05.640 --> 01:31:08.640
Очень рекомендую и тот, и другой, оба довольно неплохо работают.

01:31:08.640 --> 01:31:18.640
И вот в AskPDF скоро появится версия на 100 000 токенов, причем совершенно какие-то там смешные деньги, типа 10 долларов.

01:31:18.640 --> 01:31:20.640
И туда уже можно загружать вообще огромный текст.

01:31:20.640 --> 01:31:28.640
Кроме того, есть Клод. Клод, конечно, он уступает GPT, надо признать, но он тоже довольно неплохо работает.

01:31:28.640 --> 01:31:35.640
Если у тебя есть возможность купить подписку на POE, опять-таки поделюсь с вами этим сервисом,

01:31:35.640 --> 01:31:40.640
можно попробовать поработать с Клодом. У Клода контекст типа 100 000 токенов.

01:31:40.640 --> 01:31:46.640
То есть это, сколько там, ну это типа уже серьезно, это сотни страниц, если на английском.

01:31:46.640 --> 01:31:51.640
Поэтому да, суммируя, для структурированных данных лучше работает бетон,

01:31:51.640 --> 01:31:55.640
и я думаю всегда будет лучше работать с бетоном, потому что слишком большой контекст.

01:31:55.640 --> 01:32:00.640
Для не структурированных данных лучше работает модель, но особенно для качественных данных,

01:32:00.640 --> 01:32:04.640
а не для количественных. И на эту тему уже есть хорошее решение,

01:32:04.640 --> 01:32:08.640
а буквально в течение нескольких недель появится еще лучше.

01:32:08.640 --> 01:32:14.640
Так, Виктор спрашивает, можно поэкспериментировать с параметром language matching true-false и посмотреть разницу?

01:32:14.640 --> 01:32:18.640
Да, там есть какие-то параметры. Витя, если ты сможешь про это рассказать, я буду рад,

01:32:18.640 --> 01:32:20.640
потому что я, честно говоря, с этим вообще не разбирался.

01:32:20.640 --> 01:32:24.640
У меня просто все на английском, поэтому мне просто вообще эта тема для меня закрыта.

01:32:24.640 --> 01:32:27.640
В смысле, она мне не интересна, я что-то читал на эту тему,

01:32:27.640 --> 01:32:33.640
но поскольку я работаю только с английским, в этом смысле не могу сказать.

01:32:33.640 --> 01:32:37.640
Как совет поэкспериментировать с language matching? Да, можно попробовать.

01:32:37.640 --> 01:32:42.640
Дипленинг и курс, Руби пишет, это просто реплика.

01:32:42.640 --> 01:32:47.640
Так, гипотеза летц, что веса модели направляются в сторону роли инструктора.

01:32:47.640 --> 01:32:51.640
Ну да, гипотез может быть много, может быть преподаватель, может быть еще что-то.

01:32:51.640 --> 01:32:54.640
В целом летц — это что-то такое, да?

01:32:54.640 --> 01:32:58.640
Действенно, да, action bias, bias for action.

01:32:58.640 --> 01:33:01.640
Японец может быть много, мы сейчас не знаем.

01:33:01.640 --> 01:33:02.640
Может быть, когда-нибудь узнаем.

01:33:02.640 --> 01:33:04.640
Unplug it now, Данил, пиши.

01:33:04.640 --> 01:33:05.640
Да-да-да.

01:33:05.640 --> 01:33:09.640
Так, на тему апокалипсиса хороший подкаст упринял нас Ютковским,

01:33:09.640 --> 01:33:11.640
после него прям жить не хочется.

01:33:11.640 --> 01:33:12.640
Ну, я могу сказать про Ютковского.

01:33:12.640 --> 01:33:16.640
Честно говоря, Ютковский написал книжку «Принципы рационального мышления»,

01:33:16.640 --> 01:33:19.640
и в своей аргументации он этой книжке не следует.

01:33:19.640 --> 01:33:23.640
Это удивительно, что он на самом деле гениальный чувак, очень талантливый.

01:33:23.640 --> 01:33:27.640
Но он много изучал рациональность, мне всегда это было интересно.

01:33:27.640 --> 01:33:31.640
У него есть вот это сообщество, как называется, less wrong.

01:33:31.640 --> 01:33:35.640
И вот сейчас он перешел на какую-то сторону такого абсолютного AI-думера,

01:33:35.640 --> 01:33:37.640
но при этом аргументы у него очень плохие.

01:33:37.640 --> 01:33:40.640
Ну, то есть, прям вот его аргументы, они довольно слабые,

01:33:40.640 --> 01:33:44.640
потому что они все базируются на большом количестве допущений и предположений,

01:33:44.640 --> 01:33:46.640
и такой сценарий может быть.

01:33:46.640 --> 01:33:50.640
И в этом смысле я немножко не понял его, Ютковского, честно говоря.

01:33:50.640 --> 01:33:53.640
И более того, удивительная история была в том, что Ютковский в какой-то момент,

01:33:53.640 --> 01:33:57.640
поскольку я активно слежу за Твиттером, Ютковский в какой-то момент,

01:33:57.640 --> 01:34:01.640
когда Коля Давыдов, который в «Кремниевой долине» был, помните такой,

01:34:01.640 --> 01:34:05.640
он написал в своем Твиттере, что «слушайте, GPT-4 поменяет вообще все индустрии»,

01:34:05.640 --> 01:34:08.640
к нему в Твиттер пришел Ютковский и предложил ему пари,

01:34:08.640 --> 01:34:11.640
типа «поспорим на 100 тысяч долларов, что так не произойдет».

01:34:11.640 --> 01:34:15.640
И буквально спустя месяц он бегает по всем подкастам и говорит, что AI нас всех убьет.

01:34:15.640 --> 01:34:19.640
Не знаю, для меня это… Некоторые скажут, что люди меняются и растут, развиваются,

01:34:19.640 --> 01:34:23.640
но для меня это такая непоследовательность, она скорее говорит о том, что что-то тут не так.

01:34:23.640 --> 01:34:27.640
Ютковский опять-таки гениальный чувак, но вот что-то, мне кажется, у него есть какая-то…

01:34:27.640 --> 01:34:32.640
что-то с ним не так. Он, кстати, недавно был в Тель-Авиве, выступал.

01:34:32.640 --> 01:34:35.640
Вот, я, к сожалению, не смог попасть.

01:34:35.640 --> 01:34:37.640
Так, на тему апокалипсиса… А, да, это мы прочитали.

01:34:37.640 --> 01:34:42.640
«Pandas AI»… А, «Pandas AI» – это для анализа структурных данных, да, это отличная штука.

01:34:42.640 --> 01:34:46.640
Если вы работаете с питоном, с «Pandas» – это вообще офигенный сервис.

01:34:46.640 --> 01:34:50.640
Так, я не помню сервис-то, библиотека, но, в общем, да.

01:34:50.640 --> 01:34:52.640
Присмотритесь к ним.

01:34:52.640 --> 01:34:56.640
«Может ли chat.gpt помочь в AI с safety research?»

01:34:56.640 --> 01:34:59.640
Конечно, может, да. В этом смысле gpt, как я вам уже сказал,

01:34:59.640 --> 01:35:02.640
он может… у него очень высокие навыки проблем солвенга.

01:35:02.640 --> 01:35:08.640
А, по сути, safety research – это область, которая находится в таком состоянии решения огромных проблем.

01:35:08.640 --> 01:35:11.640
Поэтому я думаю, что это абсолютно разумно использовать модель,

01:35:11.640 --> 01:35:19.920
помощи с этим я знаю что некоторые и все черно так делать если мы доверяем ее ответом и доверяем

01:35:19.920 --> 01:35:29.880
что она не попытается сама себя сохранить свое всемогущество я думаю что в текущей версии

01:35:29.880 --> 01:35:37.560
пока в рядах но да такой такой такой риск тоже стоит учить так виктор спрашивает для анализа

01:35:37.560 --> 01:35:42.120
данных лагин код интерпретер судя по видео гиду кстати дак вот интерпретер очень крутая штука

01:35:42.120 --> 01:35:52.520
попробуйте да я забыл про него но это прям тема шикарный совет да спасибо так ник спрашивает

01:35:52.520 --> 01:35:58.080
есть если все материалы интересующего автора на русском языке например русский профессор какой-то

01:35:58.080 --> 01:36:03.480
медиа не то его же программируют лучше на русском языке ты между пром действительно да и не будет

01:36:03.480 --> 01:36:09.400
переводить тексты с ним на английский обратно ведь материалы также на желаемом языке я не знаю

01:36:09.400 --> 01:36:14.120
поэкспериментирует я честно не могу сказать потому что как я уже сказал с другими языками просто

01:36:14.120 --> 01:36:21.240
никогда не работают вот реально все что делаю все делаю с английским ну в твоем твоем суждении

01:36:21.240 --> 01:36:25.360
мне кажется очень здравая логика то есть я вот так вот если ты мне сказал я бы скорее с тобой

01:36:25.360 --> 01:36:30.120
согласился похоже туда похоже что имеет смысл писать на русском вот но опять-таки поскольку я

01:36:30.120 --> 01:36:35.760
не знаю я скажу что попробуй на раз а куда-то скинь шоте ссылки но у нас будет же в полуапрато

01:36:35.760 --> 01:36:40.720
мы сделаем фолла просто как в прошлый раз в ноушни соберем большое количество ссылок и со всеми

01:36:40.720 --> 01:36:48.520
поделимся так было бы интересно послушать про имбеденц лекцию послушать а ну про имбеденц

01:36:48.520 --> 01:36:53.200
можем отдельно большая тема вообще про работу с долговременной памяти очень интересной темы

01:36:53.200 --> 01:37:01.080
автономный агент вот но это давайте сегодня это уже нам тяжело будет так есть же лмки

01:37:01.080 --> 01:37:07.520
которые можно подключать как телеграм бота к рабочему чатику и не разориться задачи простые

01:37:07.520 --> 01:37:14.280
типа саму релогу да конечно есть конечно есть они есть на хаген фейс и вы можете их просто

01:37:14.280 --> 01:37:21.320
разместить в своем каком-то еще до и жихранилище если вы много этим занимаетесь то есть если

01:37:21.320 --> 01:37:27.800
у вас большие объемы то это можно делать вот другой вопрос что если это рабочий чат

01:37:27.800 --> 01:37:30.800
Телеграме, я не знаю, какие там у вас объемы.

01:37:30.800 --> 01:37:36.300
То есть в целом запросы к GPT-3.5 очень дешевые.

01:37:36.300 --> 01:37:40.800
То есть там какие-нибудь несколько, я бы сказал,

01:37:40.800 --> 01:37:42.800
несколько тысяч страниц, все равно вы там,

01:37:42.800 --> 01:37:45.800
ну, вряд ли вы выйдете там за 20 долларов.

01:37:45.800 --> 01:37:48.300
Мне так кажется, да, я пытаюсь прикинуть.

01:37:48.300 --> 01:37:50.300
Поэтому, наверное, это имеет смысл делать,

01:37:50.300 --> 01:37:52.800
только если у вас там прям гигантский объем.

01:37:52.800 --> 01:37:54.800
Потому что GPT-3.5 очень дешевая,

01:37:54.800 --> 01:37:56.800
GPT-4 стоит, конечно, в первый раз дороже.

01:37:56.800 --> 01:37:59.800
Поэтому я бы предложил вам посмотреть, кстати,

01:37:59.800 --> 01:38:02.800
может быть даже, то есть там есть разные,

01:38:02.800 --> 01:38:05.800
разные по типу модели, и вот там есть одна,

01:38:05.800 --> 01:38:08.800
которая хорошо суммирует и стоит вообще совсем дешево.

01:38:08.800 --> 01:38:11.800
Поэтому может быть имеет смысл все-таки посмотреть OpenAI,

01:38:11.800 --> 01:38:14.800
потому что все-таки такой диплоймент

01:38:14.800 --> 01:38:17.800
своей модели на Azure – это непростое занятие.

01:38:17.800 --> 01:38:19.800
И вопрос, стоит ли такая простая задача,

01:38:19.800 --> 01:38:21.800
такой киллер-фич.

01:38:21.800 --> 01:38:25.800
Может быть стоит попробовать решить эту проблему

01:38:25.800 --> 01:38:31.800
с чатом GPT и спросить, насколько это хорошее решение ваших проблем.

01:38:31.800 --> 01:38:33.800
Такой миотур.

01:38:33.800 --> 01:38:35.800
Так, ну что, я поздравляю нас,

01:38:35.800 --> 01:38:38.800
мы прошли через все вопросы.

01:38:38.800 --> 01:38:42.800
Друзья мои, у нас, мы с вами в эфире сколько?

01:38:42.800 --> 01:38:45.800
Уже? У меня пропал куда-то зум.

01:38:45.800 --> 01:38:48.800
Получается 1,5 часа.

01:38:48.800 --> 01:38:50.800
Да, час 40.

01:38:50.800 --> 01:38:52.800
Я вам обещал показать структурный аутпут.

01:38:52.800 --> 01:38:56.800
Если вы еще живы, если у вас есть силы, напишите плюс,

01:38:56.800 --> 01:38:59.800
и я вам покажу, как работать с структурным аутпутом.

01:38:59.800 --> 01:39:01.800
Если нет, то мы с вами.

01:39:01.800 --> 01:39:05.800
О, что все как плюсы пошли. Вот это у вас энергия.

01:39:05.800 --> 01:39:07.800
Хорошо, хорошо.

01:39:07.800 --> 01:39:10.800
Вау.

01:39:10.800 --> 01:39:11.800
Отлично, отлично.

01:39:11.800 --> 01:39:13.800
Давайте поговорим про структурный аутпут.

01:39:13.800 --> 01:39:16.800
А кто? Хорошо, давайте остановим плюсы,

01:39:16.800 --> 01:39:18.800
давайте используем какой-нибудь другой символ.

01:39:18.800 --> 01:39:20.800
Кто смотрел мой предыдущий эфир,

01:39:20.800 --> 01:39:22.800
наш предыдущий эфир совместный с Даниилом?

01:39:22.800 --> 01:39:24.800
Startup Nation.

01:39:24.800 --> 01:39:27.800
Я знаю, что смотрел.

01:39:27.800 --> 01:39:29.800
Да, напишите «я».

01:39:29.800 --> 01:39:33.800
Я заодно символы предложил.

01:39:33.800 --> 01:39:35.800
Так, не так много людей. Хорошо.

01:39:35.800 --> 01:39:38.800
Давайте тогда немножко вспомним, что я там показал.

01:39:38.800 --> 01:39:47.800
Так.

01:39:47.800 --> 01:39:51.200
Это TANA. TANA – это инструмент управления знания.

01:39:51.200 --> 01:39:55.200
Наверное, самый-самый сейчас продвинутый инструмент управления знания на рынке.

01:39:55.200 --> 01:40:01.400
В TANA есть возможность подключить модель GPT.

01:40:01.400 --> 01:40:05.600
К сожалению, у меня пока нет доступа к API GPT-4.

01:40:05.600 --> 01:40:08.400
И вот когда позавчера приезжал Семальтман к нам в Тель-Авив,

01:40:08.400 --> 01:40:11.800
я хотел прийти к ним и сказать, слушай, ну как-то несерьезно.

01:40:11.800 --> 01:40:18.400
Давайте как-то раздашь всем, потому что тяжело, реально тяжело жить без этого.

01:40:18.400 --> 01:40:21.000
Но я не попал на эту лекцию.

01:40:21.000 --> 01:40:22.200
Кстати, напишите, если вы там были.

01:40:22.200 --> 01:40:27.600
У нас много людей, вполне возможно, что кто-то из вас попал.

01:40:27.600 --> 01:40:29.400
Она, по-моему, есть в записи, кстати.

01:40:29.400 --> 01:40:33.400
Интересно, что ты рассказывал.

01:40:33.400 --> 01:40:34.600
Я пока еще не успел посмотреть.

01:40:34.600 --> 01:40:35.600
Нет, никто не был.

01:40:35.600 --> 01:40:37.000
Ну ладно.

01:40:37.000 --> 01:40:40.800
Ну так вот, поскольку у меня пока есть доступ только к API 3.5,

01:40:40.800 --> 01:40:42.800
я вам покажу, что можно сделать с API 3.5.

01:40:42.800 --> 01:40:45.800
Немножко контекста.

01:40:45.800 --> 01:40:46.800
Что такое TANA?

01:40:46.800 --> 01:40:49.200
TANA – это инструмент систематизации и структурирования знаний.

01:40:49.200 --> 01:40:52.400
То есть, по сути, здесь я храню все свои знания, все свои идеи,

01:40:52.400 --> 01:40:54.800
все свои концепции в очень структурном и системном виде.

01:40:54.800 --> 01:40:59.600
И когда мы берем структуру и систему и подключаем к этому AI,

01:40:59.600 --> 01:41:02.400
мы получаем очень интересные эффекты и очень интересные сценарии.

01:41:02.400 --> 01:41:04.600
Давайте я вам покажу на каких-то простых примерах сначала,

01:41:04.600 --> 01:41:05.800
а потом придем к более сложным.

01:41:05.800 --> 01:41:07.400
Значит, смотрите, простой пример.

01:41:07.400 --> 01:41:11.400
Единственное, что мне нужно будет немного переставить свой сетап.

01:41:11.400 --> 01:41:13.400
Вот так.

01:41:13.400 --> 01:41:15.400
Давайте простой пример.

01:41:15.400 --> 01:41:18.400
Я уже вам рассказывал сегодня, что я стал много заниматься своим здоровьем.

01:41:18.400 --> 01:41:20.800
Обращать на это гораздо больше внимания.

01:41:20.800 --> 01:41:23.400
Видимо, возраст уже не тот.

01:41:23.400 --> 01:41:25.400
И, соответственно, что я делаю?

01:41:25.400 --> 01:41:28.400
Я хочу создать универсальный фреймворк здоровья.

01:41:28.400 --> 01:41:31.400
То есть, из чего стоит мое здоровье?

01:41:31.400 --> 01:41:33.400
И вот видите, здесь все эти компоненты представлены.

01:41:33.400 --> 01:41:35.400
Это уже промежуточная работа.

01:41:35.400 --> 01:41:38.400
У меня есть более развернутый, но для нашего сейчас, для демо,

01:41:38.400 --> 01:41:41.400
это хороший вариант, потому что он еще не доделан.

01:41:41.400 --> 01:41:44.400
Видите, есть, естественно, питание, есть сон.

01:41:44.400 --> 01:41:46.400
Давайте я побольше сделаю, чтобы вам лучше было видно.

01:41:50.400 --> 01:41:53.400
Есть питание, есть упражнения, физическая активность, сон,

01:41:53.400 --> 01:41:56.400
ментальное здоровье, естественно, есть предотвращение заболеваний,

01:41:56.400 --> 01:42:00.400
есть социальные связи, есть фактор среды и есть генетика.

01:42:00.400 --> 01:42:03.400
Вот это то, как я разбил полностью свое здоровье.

01:42:03.400 --> 01:42:05.400
И, соответственно, каждый компонент может...

01:42:05.400 --> 01:42:08.400
То есть моя задача сделать универсальный framework здоровья.

01:42:08.400 --> 01:42:12.400
Что я могу сделать? Я могу, например, пойти в SON и сказать…

01:42:14.400 --> 01:42:17.400
запустить команду breakdown. Потом я вам покажу prompt, естественно.

01:42:18.400 --> 01:42:21.400
Давайте посмотрим, что будет происходить. Видите, какая-то магия происходит.

01:42:21.400 --> 01:42:24.400
Он берет вот этот node, в тане все хранится в виде nodes,

01:42:24.400 --> 01:42:28.400
и превращает его, то есть разбивает его на компоненты.

01:42:28.400 --> 01:42:33.400
Что такое SON? SON – это REM sleep, sleep cycle, sleep stages, sleep deprivation,

01:42:33.400 --> 01:42:37.400
sleep disorder, sleep hygiene. И вау, теперь у меня есть структура моего SON.

01:42:37.400 --> 01:42:41.400
Теперь по этим компонентам я дальше могу думать, чего у меня не хватает.

01:42:41.400 --> 01:42:44.400
Может быть, у меня неправильно выстроены sleep cycles,

01:42:44.400 --> 01:42:47.400
у меня есть колечко Aura, которым я слежу за своим SON.

01:42:47.400 --> 01:42:49.400
Может быть, у меня наступает sleep deprivation,

01:42:49.400 --> 01:42:52.400
может быть, мне стоит подумать про свой study и так далее.

01:42:52.400 --> 01:42:55.400
Давайте посмотрим на prompt, который у нас там есть.

01:42:55.400 --> 01:42:58.400
Это у нас команда breakdown, в тане все выстраивается в виде команд,

01:42:58.400 --> 01:43:02.400
поэтому мы можем взять любую команду и посмотреть, какой у нас prompt.

01:43:02.400 --> 01:43:05.400
Видите, здесь уже начинается такое, что-то типа программирования.

01:43:05.400 --> 01:43:10.400
You are a famous expert on name. В данном случае name – это был sleep.

01:43:10.400 --> 01:43:13.400
You are the famous expert on sleep. Он поставляет сюда sleep.

01:43:13.400 --> 01:43:19.400
Breakdown sleep into components. Run simple list, return simple list without any description.

01:43:19.400 --> 01:43:21.400
Это как раз про формат, что очень важно,

01:43:21.400 --> 01:43:24.400
потому что по дефолту он выдает очень емкое.

01:43:24.400 --> 01:43:29.400
SON – это очень важно. Один компонент в каждой линии.

01:43:29.400 --> 01:43:31.400
Почему это важно? Потому что в тане такой формат.

01:43:31.400 --> 01:43:35.400
То есть моя задача – получить именно лист таны, чтобы он нативно лег в эту структуру.

01:43:35.400 --> 01:43:37.400
Видите, дальше я ему даю пример.

01:43:37.400 --> 01:43:40.400
Nutrition, excess, sleep balance. То есть это как раз тот самый фишон.

01:43:40.400 --> 01:43:44.400
Вот такой достаточно простой prompt, и он нас приводит к такому результату.

01:43:44.400 --> 01:43:48.400
Почему это хорошо? Допустим, я потом это все почищу,

01:43:48.400 --> 01:43:51.400
это, например, мне меньше интереса, sleep deprivation у меня нет,

01:43:51.400 --> 01:43:56.400
sleep disorder у меня тоже нет, sleep stages, sleep cycles у меня – это одно и то же.

01:43:56.400 --> 01:43:59.400
Вот, допустим, эти три компонента мне больше интересны.

01:43:59.400 --> 01:44:01.400
Так что для моего сна вот эти три самые интересные.

01:44:01.400 --> 01:44:10.400
Дальше что я могу сделать? Я могу написать запрос и спросить у покажения все components.

01:44:13.400 --> 01:44:15.400
И видите, он показывает все компоненты.

01:44:15.400 --> 01:44:19.400
Дальше я ему все… ну, это, естественно, их больше из разных доменов.

01:44:19.400 --> 01:44:29.400
Но идея в том, что я могу показать только те компоненты, которые мне больше интересны.

01:44:29.400 --> 01:44:31.400
которые связаны со сном.

01:44:31.400 --> 01:44:33.400
А дальше я могу сделать еще интересную вещь.

01:44:33.400 --> 01:44:35.400
Например, я могу зайти в Sleep Cycles.

01:44:35.400 --> 01:44:38.400
И видите, здесь у меня есть внутри AI Field.

01:44:38.400 --> 01:44:43.400
Здесь роль, и это роль Sleep Cycles во сне в целом.

01:44:43.400 --> 01:44:45.400
И смотрите, какая магия.

01:44:45.400 --> 01:44:48.400
Я нажимаю на AI, что происходит?

01:44:48.400 --> 01:44:51.400
Он мне автоматически показывает,

01:44:51.400 --> 01:44:55.400
какая роль у Sleep Cycles в сне.

01:44:55.400 --> 01:44:59.400
И видите, это все не в формате аутпута,

01:44:59.400 --> 01:45:00.400
а уже в формате структуры.

01:45:00.400 --> 01:45:01.400
То есть дальше я могу с этим работать,

01:45:01.400 --> 01:45:03.400
дальше я могу с этим оперировать.

01:45:03.400 --> 01:45:04.400
Но это простой кейс.

01:45:04.400 --> 01:45:07.400
Давайте возьмем что-нибудь посложнее, поинтереснее.

01:45:07.400 --> 01:45:09.400
Мы сегодня с вами говорили уже про Стивена Вольфрома

01:45:09.400 --> 01:45:10.400
и про Олекса Фридмана.

01:45:10.400 --> 01:45:13.400
Вот недавно у них вышел подкаст вот такой вот.

01:45:13.400 --> 01:45:15.400
Очень, кстати, интересный, совет вам послушать.

01:45:15.400 --> 01:45:16.400
Я прям с удовольствием послушал,

01:45:16.400 --> 01:45:18.400
еще даже продам до конца.

01:45:18.400 --> 01:45:20.400
Как я слушаю подкасты?

01:45:20.400 --> 01:45:21.400
Я слушаю подкасты на ходу.

01:45:21.400 --> 01:45:23.400
У меня есть приложение Snip.

01:45:23.400 --> 01:45:26.400
И если мне понравилась какая-то мысль из подкаста,

01:45:26.400 --> 01:45:28.400
я ее делаю Snip.

01:45:28.400 --> 01:45:31.400
Snip – это буквально вот такой вот кусок текста.

01:45:31.400 --> 01:45:32.400
Видите? Вот так это выглядит.

01:45:32.400 --> 01:45:33.400
Не очень рабочая форма.

01:45:33.400 --> 01:45:35.400
То есть дальше, когда мне с этим нужно разбираться,

01:45:35.400 --> 01:45:37.400
я, наверное, с этим буду страдать.

01:45:37.400 --> 01:45:38.400
Соответственно, что я делаю?

01:45:38.400 --> 01:45:40.400
Во-первых, я хочу как-то этот…

01:45:40.400 --> 01:45:42.400
Я это называю слайс, то есть кусочек подкаста.

01:45:42.400 --> 01:45:44.400
Я, во-первых, хочу его как-то назвать.

01:45:44.400 --> 01:45:46.400
Для этого у меня есть вот такое поле.

01:45:46.400 --> 01:45:48.400
Потом я покажу вам симптомы за этим, естественно.

01:45:48.400 --> 01:45:51.400
Видите, он действительно довольно неплохо сгенерировал название.

01:45:51.400 --> 01:45:53.400
А SGP4 генерит еще лучше, могу сказать.

01:45:53.400 --> 01:45:55.400
Я просто пробовал SGP4 на другом встапе,

01:45:55.400 --> 01:45:57.400
но в смысле у другого человека.

01:45:57.400 --> 01:46:00.400
Да, то есть он сгенерировал нам summary –

01:46:00.400 --> 01:46:02.400
вот это вот кусочек текста.

01:46:02.400 --> 01:46:06.400
И видите, он автоматически назвал этот узел как summary.

01:46:06.400 --> 01:46:08.400
То есть теперь, когда у меня появляются узлы,

01:46:08.400 --> 01:46:10.400
видите, у них уже есть название.

01:46:10.400 --> 01:46:11.400
И это появилось автоматически,

01:46:11.400 --> 01:46:12.400
и мне ничего не нужно делать.

01:46:12.400 --> 01:46:13.400
Я могу запустить сразу все.

01:46:13.400 --> 01:46:16.400
То есть я могу собрать 10 таких слайсов

01:46:16.400 --> 01:46:18.400
и запустить на них всех этот команд.

01:46:18.400 --> 01:46:19.400
Дальше начинается уже интерес.

01:46:19.400 --> 01:46:21.400
Теперь мне нужно как-то с этим работать,

01:46:21.400 --> 01:46:23.400
с этим чанком текста мне нужно его как-то обработать.

01:46:23.400 --> 01:46:25.400
Давайте мы сделаем следующее.

01:46:25.400 --> 01:46:27.400
Давайте мы его как-то структурируем.

01:46:27.400 --> 01:46:30.400
То есть из вот такого вот балка

01:46:30.400 --> 01:46:33.400
мы получим набор просто bullet-point.

01:46:33.400 --> 01:46:35.400
Надеюсь, это сработает.

01:46:38.400 --> 01:46:39.400
Сработало.

01:46:39.400 --> 01:46:41.400
Видите, с этим уже гораздо проще работать.

01:46:41.400 --> 01:46:43.400
То есть когда я делаю ревью тех подкастов, которые я слушаю,

01:46:43.400 --> 01:46:45.400
я, естественно, работаю с bullet-поинтами,

01:46:45.400 --> 01:46:49.400
потому что я только我有 sliced попытки.

01:46:49.400 --> 01:46:57.920
кусками. уже неплохо. давайте теперь сделаем еще интереснее. давайте мы, во-первых, попробуем

01:46:57.920 --> 01:47:03.560
вытащить из этого топики. то есть дальше для того, чтобы поместить этот кусочек в какую-то структуру,

01:47:03.560 --> 01:47:08.520
мне нужно понять на какие топики он отвечает. здесь есть кнопка. разницы между кнопками и полем,

01:47:08.520 --> 01:47:13.480
ее на самом деле нет никакой, это просто разный интерфейс. но по сути оба эти интерфейса просто

01:47:13.480 --> 01:47:18.360
вызывают разные промпты. давайте я вам покажу какой-нибудь промпт для разнообразия. у нас находится

01:47:18.360 --> 01:47:25.440
в отдельной фабрике. вот у нас есть промпт extract topics. давайте посмотрим. здесь, кстати, можно

01:47:25.440 --> 01:47:29.480
ставить температуру, поскольку мы работаем с API. кстати, интересный момент, я вам про это не

01:47:29.480 --> 01:47:35.600
сказал. в chat gpt ставить температуру нельзя, но если вы скажете действую с температурой, например, 0,5,

01:47:35.600 --> 01:47:42.000
chat gpt будет эмулировать эту температуру. то есть он будет действовать так, как будто бы у него

01:47:42.000 --> 01:47:46.480
была выстроена эта температура. это вообще удивительная штука, когда я это узнал, меня это очень сильно поразило.

01:47:46.480 --> 01:47:53.280
по сути он эмулирует свою собственную работу в каких-то условиях математических. в данном

01:47:53.280 --> 01:48:00.400
случае у нас видите все просто. достань topics из syscontent, это параметр, который забирает

01:48:00.400 --> 01:48:06.080
из этого узла весь контент, который находится внутри. то есть вот этот вот балк текст. дай мне

01:48:06.080 --> 01:48:11.480
по крайней мере один topic, но не больше трех. опять-таки верни мне все эти topics в формате листа и

01:48:11.480 --> 01:48:15.680
вот в таком формате. почему в таком формате? потому что там добавляет super tag. super tag и top.

01:48:15.680 --> 01:48:19.880
опять-таки зачем нужно super tag, чтобы потом к этому возвращаться. вот такой простой промп.

01:48:19.880 --> 01:48:26.280
давайте посмотрим, что у нас получилось. мы запускаем здесь эту команду extract topics.

01:48:26.280 --> 01:48:32.040
видите, он добавляет topics ровно в то поле, в которое нужно. она об этом знает в промпте проекта

01:48:32.040 --> 01:48:36.680
прописан. computational system development, natural language processing, formalization. неплохо.

01:48:36.680 --> 01:48:43.560
опять-таки дальше по этим topics я могу все эти кусочки подкастов структурировать и могу

01:48:43.560 --> 01:48:50.760
спрашивать уже покажи мне все чанки подкастов или слайсы подкастов, которые связаны с topic NLP.

01:48:50.760 --> 01:48:57.560
это очень удобно. но это на уровне структуры, просто на уровне систем. интересное начинается уже

01:48:57.560 --> 01:49:03.640
на уровне мышления. опять-таки вот здесь конечно лучше работает gpt4. я такие эксперименты сделал с gpt4,

01:49:03.640 --> 01:49:13.640
но я готовлюсь, потому что у меня будет достаточно времени.

01:49:13.640 --> 01:49:21.860
в капе я не теряю надежду сам я верю в тебя давайте мы сделаем следующее мы попросим вот такой

01:49:21.860 --> 01:49:31.180
вот пром-то очень интересный самый покажу провокейт 08 температура то есть высокая температура

01:49:31.180 --> 01:49:38.480
задай мне про провокативный вопрос который позволит ну там случае обращаюсь к автору смысле как

01:49:38.480 --> 01:49:43.560
автору этого кусочка текста да задай задай провокативный вопрос который позволит автору текста

01:49:43.560 --> 01:49:50.120
взглянуть на этот текст новый способ вау класс да очень креативно и соответственно верни мне эти

01:49:50.120 --> 01:49:55.360
вопросы опять-таки стегом и видите здесь опять-таки пример кинометис work и question из

01:49:55.360 --> 01:50:00.600
this better way но то есть это вот как раз самый фишот чтобы он понял как это обработает лучше без

01:50:00.600 --> 01:50:06.000
этого все-таки он не всегда умеет возвращать это правильный формат давайте попробуем провокейт

01:50:06.000 --> 01:50:18.600
барабанная дробь о получилось видите некоторые вопросы получились очень поверхностный вот

01:50:18.600 --> 01:50:23.600
ада лимитейшн оф чаджи пти систем снова кей такой вопрос я бы мог задать наверное но некоторые

01:50:23.600 --> 01:50:27.680
вопросы очень глубокие интересный например хаокен вьюзки стройка knowledge to improve

01:50:27.680 --> 01:50:33.120
our understanding of the patient assistance это интересно да то есть как вообще в истории человечества

01:50:33.120 --> 01:50:38.400
вольфрам как раз много про это говорит как как мы осознавали как человечество как мы осознавали

01:50:38.400 --> 01:50:45.640
феномен computational и как разные разные системы его по-разному доносили бы разные какие-то

01:50:45.640 --> 01:50:51.120
аспекты это очень интересно это крутой вопрос эти все я уберу потому что мне кажется что они поверхностные

01:50:51.120 --> 01:50:57.600
а вот это я ставлю я хочу подумать на нем дальше следующим шагом опять-таки здесь от не очень

01:50:57.600 --> 01:51:04.000
хорошо работает но я могу просто узнать на тему чего этот кусочек текста а дальше вспоминаем что

01:51:04.000 --> 01:51:09.040
я могу собрать панель спертификат искусственному интеллекту и попросить их оценить насколько

01:51:09.040 --> 01:51:14.240
хорошо я от рефлексироваться то есть это уже больше про обучение про самообучение про размышлений

01:51:14.240 --> 01:51:18.760
это некий какой-то уже другой уровень и в этом смысле мы действительно переходим сейчас в эру

01:51:18.760 --> 01:51:25.040
который называется туз вот тот инструменты мышления то есть она это вот такой инструмент мышления

01:51:25.040 --> 01:51:51.040
тоже больше чем просто среда организации знаний это уже такая штука которая помогает нам лучше думать и лучше работать

01:51:51.040 --> 01:51:58.040
Но опять-таки структура очень важна, потому что весь аутбот модели сейчас находится в таких структурах.

01:51:58.040 --> 01:52:03.040
И еще небольшой ремарк. В TAN можно запрашивать экстреннол источники.

01:52:03.040 --> 01:52:07.040
Можно также обращаться с PDF, книжкам, если они находятся в открытом доступе и так далее.

01:52:07.040 --> 01:52:10.040
Здесь тоже эта следа не герметична.

01:52:10.040 --> 01:52:18.040
Он сначала импортирует кусочек книги в TAN, а дальше вы можете с этим кусочком книги общаться уже через вот такие структуры.

01:52:18.040 --> 01:52:23.040
Так, у нас, наверное, появились еще вопросы.

01:52:23.040 --> 01:52:28.040
Так, сейчас почему-то у меня как-то по-другому чат стал отображаться.

01:52:28.040 --> 01:52:34.040
Так, так, так, так, так. А, на этот вопрос я уже ответил.

01:52:34.040 --> 01:52:38.040
Ты синхронизировал это с Apple Health? Откуда берутся данные?

01:52:38.040 --> 01:52:43.040
Это, видимо, про Aura. Да, да, да, Aura синхронизирует с Apple Health.

01:52:43.040 --> 01:52:48.040
Даниил прислал взрыв мозга.

01:52:48.040 --> 01:52:51.040
На самом деле, там можно делать еще более крутые штуки.

01:52:51.040 --> 01:52:54.040
Я сам еще много чего не знаю, экспериментирую.

01:52:54.040 --> 01:52:59.040
И это главное, меня удивляет, с какой скоростью это все происходит, с какой скоростью приходят обновления.

01:52:59.040 --> 01:53:06.040
И за неделю появляется столько, сколько в обычной индустрии появляется за год.

01:53:06.040 --> 01:53:09.040
То есть скорости очень огромные.

01:53:09.040 --> 01:53:14.040
Так, на запросы, связанные с размышлением, можно будет отдельно пообщаться.

01:53:14.040 --> 01:53:18.040
GPT-4, API, о всякой кустомизации.

01:53:18.040 --> 01:53:20.040
Да, да, да, Ник, это хороший пойм.

01:53:20.040 --> 01:53:25.040
Что более утилитарные задачи к кустомизации лучше отдавать более быстрым, более дешевым моделям,

01:53:25.040 --> 01:53:28.040
а вот про мышление лучше более продвинутым моделям.

01:53:28.040 --> 01:53:31.040
Так, Федор спрашивает про TANU.

01:53:31.040 --> 01:53:33.040
Возможно, у меня есть инвайт, я посмотрю.

01:53:33.040 --> 01:53:37.040
Вообще, можно зарегистрироваться с ним в сообществе, и они тебя пригласят.

01:53:37.040 --> 01:53:41.040
И Ник тоже спрашивает, где взять TANU.

01:53:41.040 --> 01:53:44.040
Да, по сути, ссылку на TANU вам пришлем.

01:53:44.040 --> 01:53:48.040
Она пока работает по инвайдам, но можно будет, я посмотрю, остались ли у меня инвайды.

01:53:48.040 --> 01:53:52.040
Но если что, можно зарегистрироваться в сообществе и получить инвайд.

01:53:52.040 --> 01:53:58.040
Ну что, друзья, кажется, что мы сегодня охватили много тем.

01:53:58.040 --> 01:54:04.040
Скажите, говорите с нами, вообще полезно это было.

01:54:04.040 --> 01:54:06.040
Как вы вообще себя ощущаете?

01:54:06.040 --> 01:54:08.040
Сейчас я добавлю кнопку unmute.

01:54:08.040 --> 01:54:17.160
все может все могут он ютится я от себя скажу что просто у меня вот уже второй раз такое

01:54:17.160 --> 01:54:21.920
ощущение на репутарии когда ты приходишь про какую-то тему думаешь не начато знаю в этой

01:54:21.920 --> 01:54:30.560
семе на жрать типа я вообще не знаю это семе это супер мега полезно и как бы знаешь при всем том

01:54:30.560 --> 01:54:37.720
насколько ну знаешь я иногда думаю мы делаем эти вебинары думаю ну люди же могут просто зайти в

01:54:37.720 --> 01:54:43.000
youtube бить и подвал скопт инженеринг типа нижняя река найдут там что-нибудь как бы да но я понимаю

01:54:43.000 --> 01:54:47.960
что типа ты еще делаешь такую огромную работу там ты сам там сделал самолетом всяких этих там

01:54:47.960 --> 01:54:54.080
научных работ там следишь за всеми твиттерами и прочими там ими и как бы ну это реально

01:54:54.080 --> 01:55:00.680
огромная боль приносит я понимаю что для моего формата как бы изучение этих тем это просто мега

01:55:00.680 --> 01:55:07.600
валю был спасибо большое да спасибо спасибо да но это действительно что по сути моя работа здесь я

01:55:07.600 --> 01:55:11.720
действительно суммирую что-то и пропускаю через свой опыт и просто что-то добавляю да потому что

01:55:11.720 --> 01:55:18.680
оно как бы вот так и работает аж чем больше часто когда ты смотришь какие-то ролики даже по

01:55:18.680 --> 01:55:23.560
адванс пром-инжинирингу там вот пример вот такие как я показал что типа есть три человека типа

01:55:23.560 --> 01:55:28.360
три эксперты они переносит какие-то колпачки ты такой думаешь окей а как я как я это могу применить

01:55:28.360 --> 01:55:34.000
на какие-то свои реальные задачи вот и действительно вот какие-то более более такие жизненные

01:55:34.000 --> 01:55:41.480
примеры жизненный кейс они хорошо помогают структуре какая часть этого выступления

01:55:41.480 --> 01:55:49.840
была хорошая вопрос я не знаю но какая-то часть точно была подготовлена но мне сложно оценить я

01:55:49.840 --> 01:55:54.920
думаю что не очень большая потому что там же в основном про ну то есть это же в основном не

01:55:54.920 --> 01:56:00.920
текст а поскольку это все слайды и нарратив пока больше степнет моя работа

01:56:00.920 --> 01:56:12.080
такой вопрос последний пару минут такой более абстрактный вопрос вот говорят есть

01:56:12.080 --> 01:56:17.720
таких фраз да что кто-то думает что там и там нас их убьет кто-то считает что там там лишит работы

01:56:17.720 --> 01:56:24.640
но если про такие менее катастрофичные точки зрения что есть такая точка зрения что люди

01:56:24.640 --> 01:56:31.240
которые шарят вот во всем этом промпро инженерии и прочим и я и вот они типа захватит как бы

01:56:31.240 --> 01:56:39.720
власть а кто не шарит те нет вот у меня даже на эту мысль есть такая мысль что как бы через

01:56:39.720 --> 01:56:46.520
довольно короткое время все это станет по сути как интернет когда-то да то есть наверное неправильно

01:56:46.520 --> 01:56:51.800
было бы сказать что люди кто умеет пользоваться интернетом типа хотя может быть это и правда

01:56:51.800 --> 01:56:56.360
да что они то типа будут править миром а кто не умеют нет со временем интернет становится комодить

01:56:56.360 --> 01:57:02.840
и все этим пользуются это встроено во все девайсы то есть у тебя там ну нет ничего да что работать

01:57:02.840 --> 01:57:08.040
без интернета и по моим ощущениям как будто бы что там через довольно короткое время это просто

01:57:08.040 --> 01:57:13.120
будет так как сейчас да там photoshop там все эти дополнения реальности да там дописывание

01:57:13.120 --> 01:57:18.680
картины вставляются фича там по одному клику он тебе все делает то есть как бы абсолютно не и

01:57:18.680 --> 01:57:26.520
ай инструмент до встраивается там самая последняя как бы тема изменяем мне кажется что типа

01:57:26.520 --> 01:57:31.920
сравнительно просто будет везде как бы все туловито в твоем айфоне они уже будут это делать и ты

01:57:31.920 --> 01:57:38.560
не может не сможешь не пользоваться как бы и я да я думаю это уже сейчас невозможно в смысле даже

01:57:38.560 --> 01:57:43.680
те алгоритмы социальных сетей которыми пользуемся они уже давно работает на машинном обучении в

01:57:43.680 --> 01:57:48.280
этом смысле тут есть как бы до 2 получается подход что что-то будет внедряться просто и мы будем

01:57:48.280 --> 01:57:52.600
этого не замечать но что-то я думаю мы будем очень сильно замечать потому что ты говоришь про

01:57:52.600 --> 01:57:57.360
решиться работы я могу сказать что вот у меня был контакт с иллюстратором не нужно было сделать

01:57:57.360 --> 01:58:01.440
им проект я просто написал низким иллюстратором и вот это был полгода назад они были супер

01:58:01.440 --> 01:58:06.440
пафосные они такие о это мне интересно за это я не возьмусь сейчас они все написали искали

01:58:06.440 --> 01:58:14.120
ой слушай а может мы сделаем это вот поэтому я думаю что очень серьезный будет такой как сказать

01:58:14.120 --> 01:58:20.240
очень серьезное будет влияние и на рынок профессии и на разные разные индустрии вот про это

01:58:20.240 --> 01:58:24.400
вообще можно сделать отдельную встречу не наделал много мыслей да но классно что ты да подсветил

01:58:24.400 --> 01:58:30.840
что уже многие вещи они будут внедряться как бы бесшовно то есть мы даже не заметим в какой-то

01:58:30.840 --> 01:58:36.440
момент а это перейдет на я этого тоже интересный подход и соответственно большое количество принятых

01:58:36.440 --> 01:58:41.440
решений тоже приходит то есть на самом деле даже сейчас то что мы смотрим на ютубе то что мы

01:58:41.440 --> 01:58:44.120
Например, наш анонс был в Телеграме.

01:58:44.120 --> 01:58:47.440
Телеграмм подразумевает, что какую-то активную позицию,

01:58:47.440 --> 01:58:49.800
субъект, что ты сам выбираешь канал, подписываешься.

01:58:49.800 --> 01:58:52.240
А в Ютубе у тебя есть алгоритм рекомендаций.

01:58:52.240 --> 01:58:54.200
Например, если мы выложим это на Ютуб, какой-нибудь

01:58:54.200 --> 01:58:58.200
человек посмотрит нашу запись просто потому, что

01:58:58.200 --> 01:59:00.680
Ютуб принял за него такое решение, по сути.

01:59:00.680 --> 01:59:03.800
Это тоже интересный сайт-эффект, у которого…

01:59:03.800 --> 01:59:07.680
То есть да, в этом смысле, кто-то написал в чат, что

01:59:07.680 --> 01:59:08.680
страшно.

01:59:08.680 --> 01:59:10.560
Действительно, я могу разделить этот страх, потому что

01:59:10.560 --> 01:59:13.520
масштаб изменений будет гигантский.

01:59:13.520 --> 01:59:14.520
Просто гигантский.

01:59:14.520 --> 01:59:19.200
И чем дальше, если посмотреть, чем дальше будущее, то

01:59:19.200 --> 01:59:21.720
тем сложнее это представить, выстроить какую-то ментальную

01:59:21.720 --> 01:59:22.720
модель будущего.

01:59:22.720 --> 01:59:25.120
Но слушайте, зато так интересно.

01:59:25.120 --> 01:59:29.360
Мы с вами живем в эпоху, когда у нас появилась штука,

01:59:29.360 --> 01:59:32.000
которая умнее нас, когда появился какой-то инструмент,

01:59:32.000 --> 01:59:34.200
который действительно во многих доменах умнее

01:59:34.200 --> 01:59:35.200
нас.

01:59:35.200 --> 01:59:36.640
И он будет становиться еще умнее.

01:59:36.640 --> 01:59:39.440
И это в этом смысле какая-то история, знаете, типа как…

01:59:39.440 --> 01:59:42.760
Ну вот, например, я родился позже, чем человек, когда

01:59:42.760 --> 01:59:44.040
человек на Луну высадился.

01:59:44.040 --> 01:59:47.120
Это было круто, что человек высадился на Луну, и ты

01:59:47.120 --> 01:59:48.760
кажешься, блин, ты это упустил.

01:59:48.760 --> 01:59:53.080
А здесь, по сути, ты живешь в событии, которые такого,

01:59:53.080 --> 01:59:55.040
типа в десятки раз большего масштаба.

01:59:55.040 --> 01:59:57.560
То есть сейчас мы находимся внутри этого события, и

01:59:57.560 --> 02:00:00.280
хорошо бы это тоже как-то осознавать и, не знаю, быть

02:00:00.280 --> 02:00:02.520
типа grateful за это, потому что это очень круто.

02:00:02.520 --> 02:00:04.760
Меня это, с одной стороны, немного пугает, но с другой

02:00:04.760 --> 02:00:06.000
стороны, очень сильно вдохновляет.

02:00:06.000 --> 02:00:10.640
Вот это время, чтобы быть живым.

02:00:10.640 --> 02:00:13.840
Да, да, да, точно.

02:00:13.840 --> 02:00:14.840
Круто.

02:00:14.840 --> 02:00:17.600
Вы спрашивали, где можно подписаться.

02:00:17.600 --> 02:00:21.520
Вот я вывел специально все, где меня можно найти.

02:00:21.520 --> 02:00:25.680
Ну и в Телеграме тоже, в канале.

02:00:25.680 --> 02:00:27.680
Когда мы выложим…

02:00:27.680 --> 02:00:32.440
Да, да, да, я все започту, да, с видосиком и со всеми

02:00:32.440 --> 02:00:33.440
ссылками на ссылки.

02:00:33.440 --> 02:00:36.200
Да, и там можно написать еще вопросы, если у вас

02:00:36.200 --> 02:00:39.160
появятся, я с радостью текстом отвечу, ну, в смысле, в Телеграме

02:00:39.160 --> 02:00:40.160
отвечу сообщениями.

02:00:40.160 --> 02:00:44.680
Супер, будем заканчивать.

02:00:44.680 --> 02:00:46.120
Мы уложились два часа.

02:00:46.120 --> 02:00:49.240
Всем спасибо, остаемся на связи.

02:00:49.240 --> 02:00:52.800
Андрею большое спасибо и пока-пока.

02:00:52.800 --> 02:00:54.200
Спасибо, до новых встреч.

02:00:54.200 --> 02:00:55.200
Пока-пока.

02:00:55.200 --> 02:00:56.200
Спасибо большое.

02:00:56.200 --> 02:00:57.200
Спасибо.

02:00:57.200 --> 02:00:58.200
Пока-пока.

02:00:58.200 --> 02:00:58.700
Пока.
